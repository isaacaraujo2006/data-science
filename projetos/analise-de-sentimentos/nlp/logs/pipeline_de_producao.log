2024-11-25 13:05:28,366 - INFO - Carregando o dataset bruto.
2024-11-25 13:05:28,439 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 13:05:28,440 - INFO - Renomeando colunas.
2024-11-25 13:05:28,482 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 13:05:28,519 - INFO - Processando bloco 1 de 2
2024-11-25 13:05:28,519 - INFO - Pré-processando os dados.
2024-11-25 13:05:29,443 - INFO - Normalizando os textos.
2024-11-25 13:06:09,556 - INFO - Tokenizando os textos.
2024-11-25 13:06:09,558 - ERROR - Erro ao tokenizar os dados: 'Series' object has no attribute 'map_partitions'
2024-11-25 13:06:09,563 - ERROR - Erro ao processar os dados em blocos: 'Series' object has no attribute 'map_partitions'
2024-11-25 13:06:09,565 - ERROR - Erro durante a execução do pipeline de produção: 'Series' object has no attribute 'map_partitions'
2024-11-25 13:06:09,568 - INFO - Carregando o dataset bruto.
2024-11-25 13:06:09,601 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 13:06:09,603 - INFO - Renomeando colunas.
2024-11-25 13:06:09,642 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 13:06:09,685 - INFO - Processando bloco 1 de 2
2024-11-25 13:06:09,686 - INFO - Pré-processando os dados.
2024-11-25 13:06:10,838 - INFO - Normalizando os textos.
2024-11-25 13:06:54,418 - INFO - Tokenizando os textos.
2024-11-25 13:06:54,419 - ERROR - Erro ao tokenizar os dados: 'Series' object has no attribute 'map_partitions'
2024-11-25 13:06:54,419 - ERROR - Erro ao processar os dados em blocos: 'Series' object has no attribute 'map_partitions'
2024-11-25 13:06:54,420 - ERROR - Erro durante a execução do pipeline de produção: 'Series' object has no attribute 'map_partitions'
2024-11-25 13:25:35,053 - INFO - Carregando o dataset bruto.
2024-11-25 13:25:35,125 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 13:25:35,125 - INFO - Renomeando colunas.
2024-11-25 13:25:35,172 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 13:25:35,204 - INFO - Processando bloco 1 de 2
2024-11-25 13:25:35,205 - INFO - Pré-processando os dados.
2024-11-25 13:25:35,957 - INFO - Normalizando os textos.
2024-11-25 13:26:05,128 - INFO - Tokenizando os textos.
2024-11-25 13:26:05,130 - ERROR - Erro ao tokenizar os dados: 'Series' object has no attribute 'map_partitions'
2024-11-25 13:26:05,131 - ERROR - Erro ao processar os dados em blocos: 'Series' object has no attribute 'map_partitions'
2024-11-25 13:26:05,132 - ERROR - Erro durante a execução do pipeline de produção: 'Series' object has no attribute 'map_partitions'
2024-11-25 13:35:54,616 - INFO - Carregando o dataset bruto.
2024-11-25 13:35:54,706 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 13:35:54,706 - INFO - Renomeando colunas.
2024-11-25 13:35:54,752 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 13:35:54,794 - INFO - Processando bloco 1 de 2
2024-11-25 13:35:54,795 - INFO - Pré-processando os dados.
2024-11-25 13:35:55,687 - INFO - Normalizando os textos.
2024-11-25 13:36:33,602 - INFO - Tokenizando os textos.
2024-11-25 13:36:33,604 - ERROR - Erro ao tokenizar os dados: 'DataFrame' object has no attribute 'map_partitions'
2024-11-25 13:36:33,606 - ERROR - Erro ao processar os dados em blocos: 'DataFrame' object has no attribute 'map_partitions'
2024-11-25 13:36:33,607 - ERROR - Erro durante a execução do pipeline de produção: 'DataFrame' object has no attribute 'map_partitions'
2024-11-25 13:42:40,349 - INFO - Carregando o dataset bruto.
2024-11-25 13:42:40,412 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 13:42:40,413 - INFO - Renomeando colunas.
2024-11-25 13:42:40,447 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 13:42:40,472 - INFO - Processando bloco 1 de 2
2024-11-25 13:42:40,472 - INFO - Pré-processando os dados.
2024-11-25 13:42:41,337 - INFO - Normalizando os textos.
2024-11-25 13:43:19,717 - INFO - Tokenizando os textos.
2024-11-25 13:43:19,719 - ERROR - Erro ao tokenizar os dados: tokenizar_texto() got an unexpected keyword argument 'meta'
2024-11-25 13:43:19,721 - ERROR - Erro ao processar os dados em blocos: tokenizar_texto() got an unexpected keyword argument 'meta'
2024-11-25 13:43:19,721 - ERROR - Erro durante a execução do pipeline de produção: tokenizar_texto() got an unexpected keyword argument 'meta'
2024-11-25 13:47:35,521 - INFO - Carregando o dataset bruto.
2024-11-25 13:47:35,604 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 13:47:35,605 - INFO - Renomeando colunas.
2024-11-25 13:47:35,665 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 13:47:35,708 - INFO - Processando bloco 1 de 2
2024-11-25 13:47:35,709 - INFO - Pré-processando os dados.
2024-11-25 13:47:36,632 - INFO - Normalizando os textos.
2024-11-25 13:48:14,488 - INFO - Tokenizando os textos.
2024-11-25 13:48:14,489 - ERROR - Erro ao tokenizar os dados: 'Series' object has no attribute 'map_partitions'
2024-11-25 13:48:14,491 - ERROR - Erro ao processar os dados em blocos: 'Series' object has no attribute 'map_partitions'
2024-11-25 13:48:14,492 - ERROR - Erro durante a execução do pipeline de produção: 'Series' object has no attribute 'map_partitions'
2024-11-25 13:51:05,561 - INFO - Carregando o dataset bruto.
2024-11-25 13:51:05,652 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 13:51:05,653 - INFO - Renomeando colunas.
2024-11-25 13:51:05,711 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 13:51:05,752 - INFO - Processando bloco 1 de 2
2024-11-25 13:51:05,753 - INFO - Pré-processando os dados.
2024-11-25 13:51:06,653 - INFO - Normalizando os textos.
2024-11-25 13:51:46,661 - INFO - Tokenizando os textos.
2024-11-25 13:51:46,664 - ERROR - Erro ao tokenizar os dados: tokenizar_texto() got an unexpected keyword argument 'meta'
2024-11-25 13:51:46,665 - ERROR - Erro ao processar os dados em blocos: tokenizar_texto() got an unexpected keyword argument 'meta'
2024-11-25 13:51:46,665 - ERROR - Erro durante a execução do pipeline de produção: tokenizar_texto() got an unexpected keyword argument 'meta'
2024-11-25 13:54:24,595 - INFO - Carregando o dataset bruto.
2024-11-25 13:54:24,669 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 13:54:24,670 - INFO - Renomeando colunas.
2024-11-25 13:54:24,714 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 13:54:24,751 - INFO - Processando bloco 1 de 2
2024-11-25 13:54:24,751 - INFO - Pré-processando os dados.
2024-11-25 13:54:25,671 - INFO - Normalizando os textos.
2024-11-25 13:55:05,854 - INFO - Tokenizando os textos.
2024-11-25 13:56:14,791 - INFO - Criando bigramas.
2024-11-25 13:56:15,454 - INFO - Removendo stopwords.
2024-11-25 13:56:15,456 - ERROR - Erro ao remover stopwords: <lambda>() got an unexpected keyword argument 'meta'
2024-11-25 13:56:15,456 - ERROR - Erro ao processar os dados em blocos: <lambda>() got an unexpected keyword argument 'meta'
2024-11-25 13:56:15,456 - ERROR - Erro durante a execução do pipeline de produção: <lambda>() got an unexpected keyword argument 'meta'
2024-11-25 14:53:04,374 - INFO - Carregando o dataset bruto.
2024-11-25 14:53:04,424 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 14:53:04,424 - INFO - Renomeando colunas.
2024-11-25 14:53:04,450 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 14:53:04,479 - INFO - Processando bloco 1 de 2
2024-11-25 14:53:04,480 - INFO - Pré-processando os dados.
2024-11-25 14:53:04,970 - INFO - Normalizando os textos.
2024-11-25 14:53:26,771 - INFO - Tokenizando os textos.
2024-11-25 14:54:18,601 - INFO - Criando bigramas.
2024-11-25 14:54:19,268 - INFO - Removendo stopwords.
2024-11-25 14:54:19,289 - INFO - Aplicando stemming.
2024-11-25 14:54:19,856 - INFO - Aplicando lematização.
2024-11-25 14:55:03,505 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 14:55:03,505 - INFO - Total de linhas antes da remoção: 5000
2024-11-25 14:55:03,518 - INFO - Total de linhas após a remoção: 4968
2024-11-25 14:55:03,518 - INFO - Número de linhas excluídas: 32
2024-11-25 14:55:03,519 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-25 14:55:03,520 - ERROR - Erro ao classificar sentimentos: classificar_sentimento_vader() got an unexpected keyword argument 'meta'
2024-11-25 14:55:03,521 - ERROR - Erro ao processar os dados em blocos: classificar_sentimento_vader() got an unexpected keyword argument 'meta'
2024-11-25 14:55:03,522 - ERROR - Erro durante a execução do pipeline de produção: classificar_sentimento_vader() got an unexpected keyword argument 'meta'
2024-11-25 15:01:42,189 - INFO - Carregando o dataset bruto.
2024-11-25 15:01:42,237 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 15:01:42,238 - INFO - Renomeando colunas.
2024-11-25 15:01:42,265 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 15:01:42,297 - INFO - Processando bloco 1 de 2
2024-11-25 15:01:42,298 - INFO - Pré-processando os dados.
2024-11-25 15:01:42,794 - INFO - Normalizando os textos.
2024-11-25 15:02:05,004 - INFO - Tokenizando os textos.
2024-11-25 15:02:58,627 - INFO - Criando bigramas.
2024-11-25 15:02:59,375 - INFO - Removendo stopwords.
2024-11-25 15:02:59,403 - INFO - Aplicando stemming.
2024-11-25 15:02:59,988 - INFO - Aplicando lematização.
2024-11-25 15:03:45,223 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 15:03:45,224 - INFO - Total de linhas antes da remoção: 5000
2024-11-25 15:03:45,232 - INFO - Total de linhas após a remoção: 4968
2024-11-25 15:03:45,233 - INFO - Número de linhas excluídas: 32
2024-11-25 15:03:45,236 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-25 15:07:09,994 - INFO - Codificando sentimentos.
2024-11-25 15:07:09,995 - ERROR - Erro ao codificar sentimentos: 'Series' object has no attribute 'map_partitions'
2024-11-25 15:07:09,996 - ERROR - Erro ao processar os dados em blocos: 'Series' object has no attribute 'map_partitions'
2024-11-25 15:07:09,996 - ERROR - Erro durante a execução do pipeline de produção: 'Series' object has no attribute 'map_partitions'
2024-11-25 15:13:55,623 - INFO - Carregando o dataset bruto.
2024-11-25 15:13:55,668 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 15:13:55,669 - INFO - Renomeando colunas.
2024-11-25 15:13:55,696 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 15:13:55,723 - INFO - Processando bloco 1 de 2
2024-11-25 15:13:55,724 - INFO - Pré-processando os dados.
2024-11-25 15:13:56,412 - INFO - Normalizando os textos.
2024-11-25 15:14:19,549 - INFO - Tokenizando os textos.
2024-11-25 15:15:14,956 - INFO - Criando bigramas.
2024-11-25 15:15:15,714 - INFO - Removendo stopwords.
2024-11-25 15:15:15,748 - INFO - Aplicando stemming.
2024-11-25 15:15:16,300 - INFO - Aplicando lematização.
2024-11-25 15:16:00,374 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 15:16:00,374 - INFO - Total de linhas antes da remoção: 5000
2024-11-25 15:16:00,378 - INFO - Total de linhas após a remoção: 4968
2024-11-25 15:16:00,378 - INFO - Número de linhas excluídas: 32
2024-11-25 15:16:00,380 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-25 15:18:39,142 - INFO - Codificando sentimentos.
2024-11-25 15:18:39,143 - ERROR - Erro ao codificar sentimentos: y should be a 1d array, got an array of shape () instead.
2024-11-25 15:18:39,144 - ERROR - Erro ao processar os dados em blocos: y should be a 1d array, got an array of shape () instead.
2024-11-25 15:18:39,144 - ERROR - Erro durante a execução do pipeline de produção: y should be a 1d array, got an array of shape () instead.
2024-11-25 15:24:18,372 - INFO - Carregando o dataset bruto.
2024-11-25 15:24:18,398 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 15:24:18,398 - INFO - Renomeando colunas.
2024-11-25 15:24:18,418 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 15:24:18,434 - INFO - Processando bloco 1 de 2
2024-11-25 15:24:18,435 - INFO - Pré-processando os dados.
2024-11-25 15:24:18,849 - INFO - Normalizando os textos.
2024-11-25 15:24:36,436 - INFO - Tokenizando os textos.
2024-11-25 15:25:30,560 - INFO - Criando bigramas.
2024-11-25 15:25:31,258 - INFO - Removendo stopwords.
2024-11-25 15:25:31,299 - INFO - Aplicando stemming.
2024-11-25 15:25:31,877 - INFO - Aplicando lematização.
2024-11-25 15:26:26,679 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 15:26:26,680 - INFO - Total de linhas antes da remoção: 5000
2024-11-25 15:26:26,692 - INFO - Total de linhas após a remoção: 4968
2024-11-25 15:26:26,694 - INFO - Número de linhas excluídas: 32
2024-11-25 15:26:26,696 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-25 15:29:15,093 - INFO - Codificando sentimentos.
2024-11-25 15:29:15,094 - ERROR - Erro ao codificar sentimentos: 'Series' object has no attribute 'map_partitions'
2024-11-25 15:29:15,094 - ERROR - Erro ao processar os dados em blocos: 'Series' object has no attribute 'map_partitions'
2024-11-25 15:29:15,094 - ERROR - Erro durante a execução do pipeline de produção: 'Series' object has no attribute 'map_partitions'
2024-11-25 15:38:41,325 - INFO - Carregando o dataset bruto.
2024-11-25 15:38:41,364 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 15:38:41,364 - INFO - Renomeando colunas.
2024-11-25 15:38:41,394 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 15:38:41,421 - INFO - Processando bloco 1 de 2
2024-11-25 15:38:41,422 - INFO - Pré-processando os dados.
2024-11-25 15:38:41,947 - INFO - Normalizando os textos.
2024-11-25 15:39:03,431 - INFO - Tokenizando os textos.
2024-11-25 15:39:51,721 - INFO - Criando bigramas.
2024-11-25 15:39:52,349 - INFO - Removendo stopwords.
2024-11-25 15:39:52,377 - INFO - Aplicando stemming.
2024-11-25 15:39:53,012 - INFO - Aplicando lematização.
2024-11-25 15:40:33,789 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 15:40:33,789 - INFO - Total de linhas antes da remoção: 5000
2024-11-25 15:40:33,796 - INFO - Total de linhas após a remoção: 4968
2024-11-25 15:40:33,797 - INFO - Número de linhas excluídas: 32
2024-11-25 15:40:33,798 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-25 15:43:43,917 - INFO - Codificando sentimentos.
2024-11-25 15:43:44,119 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 15:43:44,120 - INFO - Total de linhas antes da remoção: 4968
2024-11-25 15:43:44,128 - INFO - Total de linhas após a remoção: 4968
2024-11-25 15:43:44,128 - INFO - Número de linhas excluídas: 0
2024-11-25 15:43:44,131 - INFO - Aplicando TF-IDF.
2024-11-25 15:43:44,132 - ERROR - Erro ao aplicar TF-IDF: 'Series' object has no attribute 'compute'
2024-11-25 15:43:44,132 - ERROR - Erro ao processar os dados em blocos: 'Series' object has no attribute 'compute'
2024-11-25 15:43:44,133 - ERROR - Erro durante a execução do pipeline de produção: 'Series' object has no attribute 'compute'
2024-11-25 15:52:39,615 - INFO - Carregando o dataset bruto.
2024-11-25 15:52:39,665 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 15:52:39,667 - INFO - Renomeando colunas.
2024-11-25 15:52:39,695 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 15:52:39,718 - INFO - Processando bloco 1 de 2
2024-11-25 15:52:39,718 - INFO - Pré-processando os dados.
2024-11-25 15:52:40,397 - INFO - Normalizando os textos.
2024-11-25 15:53:07,742 - INFO - Tokenizando os textos.
2024-11-25 15:54:11,605 - INFO - Criando bigramas.
2024-11-25 15:54:12,465 - INFO - Removendo stopwords.
2024-11-25 15:54:12,499 - INFO - Aplicando stemming.
2024-11-25 15:54:13,224 - INFO - Aplicando lematização.
2024-11-25 15:55:10,333 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 15:55:10,334 - INFO - Total de linhas antes da remoção: 5000
2024-11-25 15:55:10,346 - INFO - Total de linhas após a remoção: 4968
2024-11-25 15:55:10,346 - INFO - Número de linhas excluídas: 32
2024-11-25 15:55:10,347 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-25 15:58:35,055 - INFO - Codificando sentimentos.
2024-11-25 15:58:35,260 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 15:58:35,260 - INFO - Total de linhas antes da remoção: 4968
2024-11-25 15:58:35,270 - INFO - Total de linhas após a remoção: 4968
2024-11-25 15:58:35,270 - INFO - Número de linhas excluídas: 0
2024-11-25 15:58:35,271 - INFO - Aplicando TF-IDF.
2024-11-25 15:58:35,272 - ERROR - Erro ao aplicar TF-IDF: 'Series' object has no attribute 'compute'
2024-11-25 15:58:35,272 - ERROR - Erro ao processar os dados em blocos: 'Series' object has no attribute 'compute'
2024-11-25 15:58:35,273 - ERROR - Erro durante a execução do pipeline de produção: 'Series' object has no attribute 'compute'
2024-11-25 16:05:21,085 - INFO - Carregando o dataset bruto.
2024-11-25 16:05:21,129 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 16:05:21,130 - INFO - Renomeando colunas.
2024-11-25 16:05:21,150 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 16:05:21,171 - INFO - Processando bloco 1 de 2
2024-11-25 16:05:21,172 - INFO - Pré-processando os dados.
2024-11-25 16:05:21,676 - INFO - Normalizando os textos.
2024-11-25 16:05:43,311 - INFO - Tokenizando os textos.
2024-11-25 16:06:33,109 - INFO - Criando bigramas.
2024-11-25 16:06:33,757 - INFO - Removendo stopwords.
2024-11-25 16:06:33,780 - INFO - Aplicando stemming.
2024-11-25 16:06:34,323 - INFO - Aplicando lematização.
2024-11-25 16:07:15,271 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 16:07:15,272 - INFO - Total de linhas antes da remoção: 5000
2024-11-25 16:07:15,276 - INFO - Total de linhas após a remoção: 4968
2024-11-25 16:07:15,276 - INFO - Número de linhas excluídas: 32
2024-11-25 16:07:15,277 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-25 16:10:34,735 - INFO - Codificando sentimentos.
2024-11-25 16:10:34,942 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 16:10:34,944 - INFO - Total de linhas antes da remoção: 4968
2024-11-25 16:10:34,953 - INFO - Total de linhas após a remoção: 4968
2024-11-25 16:10:34,953 - INFO - Número de linhas excluídas: 0
2024-11-25 16:10:34,955 - INFO - Aplicando TF-IDF.
2024-11-25 16:10:34,955 - ERROR - Erro ao aplicar TF-IDF: 'Series' object has no attribute 'compute'
2024-11-25 16:10:34,955 - ERROR - Erro ao processar os dados em blocos: 'Series' object has no attribute 'compute'
2024-11-25 16:10:34,956 - ERROR - Erro durante a execução do pipeline de produção: 'Series' object has no attribute 'compute'
2024-11-25 16:12:20,696 - INFO - Carregando o dataset bruto.
2024-11-25 16:12:20,741 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 16:12:20,741 - INFO - Renomeando colunas.
2024-11-25 16:12:20,767 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 16:12:20,787 - INFO - Processando bloco 1 de 2
2024-11-25 16:12:20,788 - INFO - Pré-processando os dados.
2024-11-25 16:12:21,305 - INFO - Normalizando os textos.
2024-11-25 16:12:42,316 - INFO - Tokenizando os textos.
2024-11-25 16:13:31,100 - INFO - Criando bigramas.
2024-11-25 16:13:31,739 - INFO - Removendo stopwords.
2024-11-25 16:13:31,765 - INFO - Aplicando stemming.
2024-11-25 16:13:32,383 - INFO - Aplicando lematização.
2024-11-25 16:14:14,212 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 16:14:14,212 - INFO - Total de linhas antes da remoção: 5000
2024-11-25 16:14:14,222 - INFO - Total de linhas após a remoção: 4968
2024-11-25 16:14:14,223 - INFO - Número de linhas excluídas: 32
2024-11-25 16:14:14,225 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-25 16:17:35,363 - INFO - Codificando sentimentos.
2024-11-25 16:17:35,555 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 16:17:35,556 - INFO - Total de linhas antes da remoção: 4968
2024-11-25 16:17:35,569 - INFO - Total de linhas após a remoção: 4968
2024-11-25 16:17:35,570 - INFO - Número de linhas excluídas: 0
2024-11-25 16:17:35,571 - INFO - Aplicando TF-IDF.
2024-11-25 16:17:35,573 - ERROR - Erro ao aplicar TF-IDF: 'numpy.ndarray' object has no attribute 'compute'
2024-11-25 16:17:35,573 - ERROR - Erro ao processar os dados em blocos: 'numpy.ndarray' object has no attribute 'compute'
2024-11-25 16:17:35,575 - ERROR - Erro durante a execução do pipeline de produção: 'numpy.ndarray' object has no attribute 'compute'
2024-11-25 16:20:36,797 - INFO - Carregando o dataset bruto.
2024-11-25 16:20:36,842 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 16:20:36,842 - INFO - Renomeando colunas.
2024-11-25 16:20:36,868 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 16:20:36,888 - INFO - Processando bloco 1 de 2
2024-11-25 16:20:36,889 - INFO - Pré-processando os dados.
2024-11-25 16:20:37,376 - INFO - Normalizando os textos.
2024-11-25 16:20:59,049 - INFO - Tokenizando os textos.
2024-11-25 16:21:48,162 - INFO - Criando bigramas.
2024-11-25 16:21:48,829 - INFO - Removendo stopwords.
2024-11-25 16:21:48,862 - INFO - Aplicando stemming.
2024-11-25 16:21:49,405 - INFO - Aplicando lematização.
2024-11-25 16:22:30,461 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 16:22:30,462 - INFO - Total de linhas antes da remoção: 5000
2024-11-25 16:22:30,474 - INFO - Total de linhas após a remoção: 4968
2024-11-25 16:22:30,474 - INFO - Número de linhas excluídas: 32
2024-11-25 16:22:30,476 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-25 16:25:49,821 - INFO - Codificando sentimentos.
2024-11-25 16:25:50,015 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 16:25:50,015 - INFO - Total de linhas antes da remoção: 4968
2024-11-25 16:25:50,024 - INFO - Total de linhas após a remoção: 4968
2024-11-25 16:25:50,024 - INFO - Número de linhas excluídas: 0
2024-11-25 16:25:50,025 - INFO - Aplicando TF-IDF.
2024-11-25 16:27:42,705 - INFO - Carregando o dataset bruto.
2024-11-25 16:27:42,742 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 16:27:42,743 - INFO - Renomeando colunas.
2024-11-25 16:27:42,774 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 16:27:42,814 - INFO - Processando bloco 1 de 2
2024-11-25 16:27:42,815 - INFO - Pré-processando os dados.
2024-11-25 16:27:43,457 - INFO - Normalizando os textos.
2024-11-25 16:28:09,069 - INFO - Tokenizando os textos.
2024-11-25 16:29:11,539 - INFO - Criando bigramas.
2024-11-25 16:29:12,333 - INFO - Removendo stopwords.
2024-11-25 16:29:12,355 - INFO - Aplicando stemming.
2024-11-25 16:29:13,021 - INFO - Aplicando lematização.
2024-11-25 16:30:10,008 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 16:30:10,008 - INFO - Total de linhas antes da remoção: 5000
2024-11-25 16:30:10,014 - INFO - Total de linhas após a remoção: 4968
2024-11-25 16:30:10,015 - INFO - Número de linhas excluídas: 32
2024-11-25 16:30:10,017 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-25 16:33:43,619 - INFO - Codificando sentimentos.
2024-11-25 16:33:43,827 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 16:33:43,828 - INFO - Total de linhas antes da remoção: 4968
2024-11-25 16:33:43,834 - INFO - Total de linhas após a remoção: 4968
2024-11-25 16:33:43,834 - INFO - Número de linhas excluídas: 0
2024-11-25 16:33:43,835 - INFO - Aplicando TF-IDF.
2024-11-25 16:35:52,916 - INFO - Carregando o dataset bruto.
2024-11-25 16:35:52,967 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 16:35:52,967 - INFO - Renomeando colunas.
2024-11-25 16:35:52,996 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 16:35:53,024 - INFO - Processando bloco 1 de 2
2024-11-25 16:35:53,024 - INFO - Pré-processando os dados.
2024-11-25 16:35:53,607 - INFO - Normalizando os textos.
2024-11-25 16:36:14,536 - INFO - Tokenizando os textos.
2024-11-25 16:37:02,225 - INFO - Criando bigramas.
2024-11-25 16:37:02,839 - INFO - Removendo stopwords.
2024-11-25 16:37:02,863 - INFO - Aplicando stemming.
2024-11-25 16:37:03,421 - INFO - Aplicando lematização.
2024-11-25 16:37:43,271 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 16:37:43,273 - INFO - Total de linhas antes da remoção: 5000
2024-11-25 16:37:43,278 - INFO - Total de linhas após a remoção: 4968
2024-11-25 16:37:43,278 - INFO - Número de linhas excluídas: 32
2024-11-25 16:37:43,280 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-25 16:41:02,510 - INFO - Codificando sentimentos.
2024-11-25 16:41:02,699 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 16:41:02,699 - INFO - Total de linhas antes da remoção: 4968
2024-11-25 16:41:02,711 - INFO - Total de linhas após a remoção: 4968
2024-11-25 16:41:02,711 - INFO - Número de linhas excluídas: 0
2024-11-25 16:41:02,712 - INFO - Aplicando TF-IDF.
2024-11-25 16:41:11,449 - INFO - Bloco 1 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\temp\bloco_1.parquet
2024-11-25 16:41:11,521 - INFO - Processando bloco 2 de 2
2024-11-25 16:41:11,521 - INFO - Pré-processando os dados.
2024-11-25 16:41:11,614 - INFO - Normalizando os textos.
2024-11-25 16:41:15,860 - INFO - Tokenizando os textos.
2024-11-25 16:41:26,606 - INFO - Criando bigramas.
2024-11-25 16:41:26,740 - INFO - Removendo stopwords.
2024-11-25 16:41:26,748 - INFO - Aplicando stemming.
2024-11-25 16:41:26,891 - INFO - Aplicando lematização.
2024-11-25 16:41:36,272 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 16:41:36,272 - INFO - Total de linhas antes da remoção: 1000
2024-11-25 16:41:36,277 - INFO - Total de linhas após a remoção: 998
2024-11-25 16:41:36,278 - INFO - Número de linhas excluídas: 2
2024-11-25 16:41:36,279 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-25 16:42:15,342 - INFO - Codificando sentimentos.
2024-11-25 16:42:15,384 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 16:42:15,384 - INFO - Total de linhas antes da remoção: 998
2024-11-25 16:42:15,387 - INFO - Total de linhas após a remoção: 998
2024-11-25 16:42:15,387 - INFO - Número de linhas excluídas: 0
2024-11-25 16:42:15,388 - INFO - Aplicando TF-IDF.
2024-11-25 16:42:16,094 - INFO - Bloco 2 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\temp\bloco_2.parquet
2024-11-25 16:42:16,095 - INFO - Todos os blocos processados e salvos com sucesso.
2024-11-25 16:42:16,123 - INFO - Pré-processando os dados.
2024-11-25 16:42:16,137 - INFO - Normalizando os textos.
2024-11-25 16:42:18,285 - INFO - Tokenizando os textos.
2024-11-25 16:42:18,484 - INFO - Criando bigramas.
2024-11-25 16:42:18,490 - INFO - Removendo stopwords.
2024-11-25 16:42:18,515 - INFO - Aplicando stemming.
2024-11-25 16:42:18,537 - INFO - Aplicando lematização.
2024-11-25 16:42:18,738 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 16:44:18,570 - INFO - Total de linhas antes da remoção: 5966
2024-11-25 16:48:28,944 - INFO - Total de linhas após a remoção: 5966
2024-11-25 16:48:28,945 - INFO - Número de linhas excluídas: 0
2024-11-25 16:48:28,945 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-25 16:48:35,045 - INFO - Codificando sentimentos.
2024-11-25 16:48:35,055 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 16:54:48,336 - INFO - Total de linhas antes da remoção: 5966
2024-11-25 17:06:51,057 - INFO - Total de linhas após a remoção: 5966
2024-11-25 17:06:51,058 - INFO - Número de linhas excluídas: 0
2024-11-25 17:06:51,060 - ERROR - Erro durante a execução do pipeline de produção: 'Array' object has no attribute 'tolist'
2024-11-25 17:17:42,636 - INFO - Carregando o dataset bruto.
2024-11-25 17:17:42,690 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 17:17:42,690 - INFO - Renomeando colunas.
2024-11-25 17:17:42,728 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 17:17:42,761 - INFO - Processando bloco 1 de 2
2024-11-25 17:17:42,761 - INFO - Pré-processando os dados.
2024-11-25 17:17:42,762 - ERROR - Erro ao preprocessar os dados: map() got an unexpected keyword argument 'meta'
2024-11-25 17:17:42,762 - ERROR - Erro ao processar os dados em blocos: map() got an unexpected keyword argument 'meta'
2024-11-25 17:17:42,762 - ERROR - Erro durante a execução do pipeline de produção: map() got an unexpected keyword argument 'meta'
2024-11-25 17:27:01,001 - INFO - Carregando o dataset bruto.
2024-11-25 17:27:01,045 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 17:27:01,045 - INFO - Renomeando colunas.
2024-11-25 17:27:01,065 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 17:27:01,089 - INFO - Processando bloco 1 de 2
2024-11-25 17:27:01,089 - INFO - Pré-processando os dados.
2024-11-25 17:27:01,595 - INFO - Normalizando os textos.
2024-11-25 17:27:23,410 - INFO - Tokenizando os textos.
2024-11-25 17:27:23,410 - ERROR - Erro ao tokenizar os dados: tokenizar_texto() got an unexpected keyword argument 'meta'
2024-11-25 17:27:23,411 - ERROR - Erro ao processar os dados em blocos: tokenizar_texto() got an unexpected keyword argument 'meta'
2024-11-25 17:27:23,411 - ERROR - Erro durante a execução do pipeline de produção: tokenizar_texto() got an unexpected keyword argument 'meta'
2024-11-25 17:27:55,174 - INFO - Carregando o dataset bruto.
2024-11-25 17:27:55,204 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 17:27:55,204 - INFO - Renomeando colunas.
2024-11-25 17:27:55,226 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 17:27:55,244 - INFO - Processando bloco 1 de 2
2024-11-25 17:27:55,246 - INFO - Pré-processando os dados.
2024-11-25 17:27:55,643 - INFO - Normalizando os textos.
2024-11-25 17:28:12,809 - INFO - Tokenizando os textos.
2024-11-25 17:28:12,810 - ERROR - Erro ao tokenizar os dados: tokenizar_texto() got an unexpected keyword argument 'meta'
2024-11-25 17:28:12,811 - ERROR - Erro ao processar os dados em blocos: tokenizar_texto() got an unexpected keyword argument 'meta'
2024-11-25 17:28:12,811 - ERROR - Erro durante a execução do pipeline de produção: tokenizar_texto() got an unexpected keyword argument 'meta'
2024-11-25 17:29:47,827 - INFO - Carregando o dataset bruto.
2024-11-25 17:29:47,875 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 17:29:47,875 - INFO - Renomeando colunas.
2024-11-25 17:29:47,909 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 17:29:47,939 - INFO - Processando bloco 1 de 2
2024-11-25 17:29:47,940 - INFO - Pré-processando os dados.
2024-11-25 17:29:48,442 - INFO - Normalizando os textos.
2024-11-25 17:30:08,550 - INFO - Tokenizando os textos.
2024-11-25 17:30:08,551 - ERROR - Erro ao tokenizar os dados: tokenizar_texto() got an unexpected keyword argument 'meta'
2024-11-25 17:30:08,552 - ERROR - Erro ao processar os dados em blocos: tokenizar_texto() got an unexpected keyword argument 'meta'
2024-11-25 17:30:08,552 - ERROR - Erro durante a execução do pipeline de produção: tokenizar_texto() got an unexpected keyword argument 'meta'
2024-11-25 17:38:27,762 - INFO - Carregando o dataset bruto.
2024-11-25 17:38:27,806 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 17:38:27,807 - INFO - Renomeando colunas.
2024-11-25 17:38:27,832 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 17:38:27,851 - INFO - Processando bloco 1 de 2
2024-11-25 17:38:27,851 - INFO - Pré-processando os dados.
2024-11-25 17:38:28,359 - INFO - Normalizando os textos.
2024-11-25 17:38:49,268 - INFO - Tokenizando os textos.
2024-11-25 17:39:38,001 - INFO - Criando bigramas.
2024-11-25 17:39:38,657 - INFO - Removendo stopwords.
2024-11-25 17:39:38,680 - INFO - Aplicando stemming.
2024-11-25 17:39:39,214 - INFO - Aplicando lematização.
2024-11-25 17:40:19,166 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 17:40:19,167 - INFO - Total de linhas antes da remoção: 5000
2024-11-25 17:40:19,177 - INFO - Total de linhas após a remoção: 4968
2024-11-25 17:40:19,178 - INFO - Número de linhas excluídas: 32
2024-11-25 17:40:19,180 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-25 17:43:18,375 - INFO - Codificando sentimentos.
2024-11-25 17:43:18,562 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 17:43:18,563 - INFO - Total de linhas antes da remoção: 4968
2024-11-25 17:43:18,576 - INFO - Total de linhas após a remoção: 4968
2024-11-25 17:43:18,576 - INFO - Número de linhas excluídas: 0
2024-11-25 17:43:18,577 - INFO - Aplicando TF-IDF.
2024-11-25 17:43:18,578 - ERROR - Erro ao aplicar TF-IDF: 'Series' object has no attribute 'compute'
2024-11-25 17:43:18,578 - ERROR - Erro ao processar os dados em blocos: 'Series' object has no attribute 'compute'
2024-11-25 17:43:18,578 - ERROR - Erro durante a execução do pipeline de produção: 'Series' object has no attribute 'compute'
2024-11-25 17:44:53,970 - INFO - Carregando o dataset bruto.
2024-11-25 17:44:54,005 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 17:44:54,006 - INFO - Renomeando colunas.
2024-11-25 17:44:54,025 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 17:44:54,043 - INFO - Processando bloco 1 de 2
2024-11-25 17:44:54,044 - INFO - Pré-processando os dados.
2024-11-25 17:44:54,495 - INFO - Normalizando os textos.
2024-11-25 17:45:12,560 - INFO - Tokenizando os textos.
2024-11-25 17:45:53,994 - INFO - Criando bigramas.
2024-11-25 17:45:54,573 - INFO - Removendo stopwords.
2024-11-25 17:45:54,601 - INFO - Aplicando stemming.
2024-11-25 17:45:55,239 - INFO - Aplicando lematização.
2024-11-25 17:46:29,983 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 17:46:29,984 - INFO - Total de linhas antes da remoção: 5000
2024-11-25 17:46:29,988 - INFO - Total de linhas após a remoção: 4968
2024-11-25 17:46:29,989 - INFO - Número de linhas excluídas: 32
2024-11-25 17:46:29,990 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-25 17:49:45,642 - INFO - Codificando sentimentos.
2024-11-25 17:49:45,825 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 17:49:45,826 - INFO - Total de linhas antes da remoção: 4968
2024-11-25 17:49:45,835 - INFO - Total de linhas após a remoção: 4968
2024-11-25 17:49:45,835 - INFO - Número de linhas excluídas: 0
2024-11-25 17:49:45,836 - INFO - Aplicando TF-IDF.
2024-11-25 17:49:52,264 - INFO - Bloco 1 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\temp\bloco_1.parquet
2024-11-25 17:49:52,305 - INFO - Processando bloco 2 de 2
2024-11-25 17:49:52,305 - INFO - Pré-processando os dados.
2024-11-25 17:49:52,403 - INFO - Normalizando os textos.
2024-11-25 17:49:55,988 - INFO - Tokenizando os textos.
2024-11-25 17:50:04,106 - INFO - Criando bigramas.
2024-11-25 17:50:04,233 - INFO - Removendo stopwords.
2024-11-25 17:50:04,238 - INFO - Aplicando stemming.
2024-11-25 17:50:04,339 - INFO - Aplicando lematização.
2024-11-25 17:50:11,125 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 17:50:11,126 - INFO - Total de linhas antes da remoção: 1000
2024-11-25 17:50:11,131 - INFO - Total de linhas após a remoção: 998
2024-11-25 17:50:11,132 - INFO - Número de linhas excluídas: 2
2024-11-25 17:50:11,132 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-25 17:50:53,479 - INFO - Codificando sentimentos.
2024-11-25 17:50:53,514 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 17:50:53,514 - INFO - Total de linhas antes da remoção: 998
2024-11-25 17:50:53,516 - INFO - Total de linhas após a remoção: 998
2024-11-25 17:50:53,516 - INFO - Número de linhas excluídas: 0
2024-11-25 17:50:53,517 - INFO - Aplicando TF-IDF.
2024-11-25 17:50:54,051 - INFO - Bloco 2 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\temp\bloco_2.parquet
2024-11-25 17:50:54,052 - INFO - Todos os blocos processados e salvos com sucesso.
2024-11-25 17:50:54,069 - INFO - Pré-processando os dados.
2024-11-25 17:50:54,085 - INFO - Normalizando os textos.
2024-11-25 17:50:56,018 - INFO - Tokenizando os textos.
2024-11-25 17:50:56,218 - INFO - Criando bigramas.
2024-11-25 17:50:56,226 - INFO - Removendo stopwords.
2024-11-25 17:50:56,239 - INFO - Aplicando stemming.
2024-11-25 17:50:56,252 - INFO - Aplicando lematização.
2024-11-25 17:50:56,424 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 17:52:38,258 - INFO - Total de linhas antes da remoção: 5966
2024-11-25 17:55:48,739 - INFO - Total de linhas após a remoção: 5966
2024-11-25 17:55:48,740 - INFO - Número de linhas excluídas: 0
2024-11-25 17:55:48,740 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-25 17:55:54,526 - INFO - Codificando sentimentos.
2024-11-25 17:55:54,535 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 18:01:27,450 - INFO - Total de linhas antes da remoção: 5966
2024-11-25 18:10:12,664 - INFO - Total de linhas após a remoção: 5966
2024-11-25 18:10:12,665 - INFO - Número de linhas excluídas: 0
2024-11-25 18:10:12,666 - ERROR - Erro durante a execução do pipeline de produção: 'Series' object has no attribute 'tolist'
2024-11-25 18:13:50,219 - INFO - Carregando o dataset bruto.
2024-11-25 18:13:50,258 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 18:13:50,258 - INFO - Renomeando colunas.
2024-11-25 18:13:50,280 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 18:13:50,295 - INFO - Processando bloco 1 de 2
2024-11-25 18:13:50,295 - INFO - Pré-processando os dados.
2024-11-25 18:13:50,874 - INFO - Normalizando os textos.
2024-11-25 18:14:10,500 - INFO - Tokenizando os textos.
2024-11-25 18:14:53,491 - INFO - Criando bigramas.
2024-11-25 18:14:54,082 - INFO - Removendo stopwords.
2024-11-25 18:14:54,106 - INFO - Aplicando stemming.
2024-11-25 18:14:54,637 - INFO - Aplicando lematização.
2024-11-25 18:15:31,206 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 18:15:31,206 - INFO - Total de linhas antes da remoção: 5000
2024-11-25 18:15:31,219 - INFO - Total de linhas após a remoção: 4968
2024-11-25 18:15:31,219 - INFO - Número de linhas excluídas: 32
2024-11-25 18:15:31,220 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-25 18:18:50,992 - INFO - Codificando sentimentos.
2024-11-25 18:18:51,167 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 18:18:51,167 - INFO - Total de linhas antes da remoção: 4968
2024-11-25 18:18:51,171 - INFO - Total de linhas após a remoção: 4968
2024-11-25 18:18:51,172 - INFO - Número de linhas excluídas: 0
2024-11-25 18:18:51,173 - INFO - Aplicando TF-IDF.
2024-11-25 18:18:51,173 - ERROR - Erro ao aplicar TF-IDF: 'Series' object has no attribute 'compute'
2024-11-25 18:18:51,174 - ERROR - Erro ao processar os dados em blocos: 'Series' object has no attribute 'compute'
2024-11-25 18:18:51,174 - ERROR - Erro durante a execução do pipeline de produção: 'Series' object has no attribute 'compute'
2024-11-25 18:21:00,420 - INFO - Carregando o dataset bruto.
2024-11-25 18:21:00,460 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 18:21:00,461 - INFO - Renomeando colunas.
2024-11-25 18:21:00,480 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 18:21:00,502 - INFO - Processando bloco 1 de 2
2024-11-25 18:21:00,503 - INFO - Pré-processando os dados.
2024-11-25 18:21:00,995 - INFO - Normalizando os textos.
2024-11-25 18:21:20,044 - INFO - Tokenizando os textos.
2024-11-25 18:22:03,183 - INFO - Criando bigramas.
2024-11-25 18:22:03,765 - INFO - Removendo stopwords.
2024-11-25 18:22:03,788 - INFO - Aplicando stemming.
2024-11-25 18:22:04,294 - INFO - Aplicando lematização.
2024-11-25 18:22:40,530 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 18:22:40,530 - INFO - Total de linhas antes da remoção: 5000
2024-11-25 18:22:40,541 - INFO - Total de linhas após a remoção: 4968
2024-11-25 18:22:40,542 - INFO - Número de linhas excluídas: 32
2024-11-25 18:22:40,543 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-25 18:26:00,220 - INFO - Codificando sentimentos.
2024-11-25 18:26:00,393 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 18:26:00,394 - INFO - Total de linhas antes da remoção: 4968
2024-11-25 18:26:00,401 - INFO - Total de linhas após a remoção: 4968
2024-11-25 18:26:00,402 - INFO - Número de linhas excluídas: 0
2024-11-25 18:26:00,403 - INFO - Aplicando TF-IDF.
2024-11-25 18:26:07,000 - INFO - Bloco 1 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\temp\bloco_1.parquet
2024-11-25 18:26:07,043 - INFO - Processando bloco 2 de 2
2024-11-25 18:26:07,044 - INFO - Pré-processando os dados.
2024-11-25 18:26:07,139 - INFO - Normalizando os textos.
2024-11-25 18:26:10,966 - INFO - Tokenizando os textos.
2024-11-25 18:26:19,141 - INFO - Criando bigramas.
2024-11-25 18:26:19,275 - INFO - Removendo stopwords.
2024-11-25 18:26:19,281 - INFO - Aplicando stemming.
2024-11-25 18:26:19,402 - INFO - Aplicando lematização.
2024-11-25 18:26:26,378 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 18:26:26,381 - INFO - Total de linhas antes da remoção: 1000
2024-11-25 18:26:26,384 - INFO - Total de linhas após a remoção: 998
2024-11-25 18:26:26,385 - INFO - Número de linhas excluídas: 2
2024-11-25 18:26:26,385 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-25 18:27:03,690 - INFO - Codificando sentimentos.
2024-11-25 18:27:03,725 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 18:27:03,725 - INFO - Total de linhas antes da remoção: 998
2024-11-25 18:27:03,729 - INFO - Total de linhas após a remoção: 998
2024-11-25 18:27:03,730 - INFO - Número de linhas excluídas: 0
2024-11-25 18:27:03,730 - INFO - Aplicando TF-IDF.
2024-11-25 18:27:04,284 - INFO - Bloco 2 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\temp\bloco_2.parquet
2024-11-25 18:27:04,284 - INFO - Todos os blocos processados e salvos com sucesso.
2024-11-25 18:27:04,297 - INFO - Pré-processando os dados.
2024-11-25 18:27:04,306 - INFO - Normalizando os textos.
2024-11-25 18:27:06,186 - INFO - Tokenizando os textos.
2024-11-25 18:27:06,381 - INFO - Criando bigramas.
2024-11-25 18:27:06,393 - INFO - Removendo stopwords.
2024-11-25 18:27:06,410 - INFO - Aplicando stemming.
2024-11-25 18:27:06,425 - INFO - Aplicando lematização.
2024-11-25 18:27:06,622 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 18:28:55,238 - INFO - Total de linhas antes da remoção: 5966
2024-11-25 18:32:11,210 - INFO - Total de linhas após a remoção: 5966
2024-11-25 18:32:11,211 - INFO - Número de linhas excluídas: 0
2024-11-25 18:32:11,212 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-25 18:32:16,309 - INFO - Codificando sentimentos.
2024-11-25 18:32:16,318 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 18:36:31,368 - INFO - Total de linhas antes da remoção: 5966
2024-11-25 18:43:21,905 - INFO - Total de linhas após a remoção: 5966
2024-11-25 18:43:21,906 - INFO - Número de linhas excluídas: 0
2024-11-25 18:48:28,526 - ERROR - Erro durante a execução do pipeline de produção: Column assignment doesn't support type list
2024-11-25 18:50:09,559 - INFO - Carregando o dataset bruto.
2024-11-25 18:50:09,584 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 18:50:09,585 - INFO - Renomeando colunas.
2024-11-25 18:50:09,598 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 18:50:09,612 - INFO - Processando bloco 1 de 2
2024-11-25 18:50:09,612 - INFO - Pré-processando os dados.
2024-11-25 18:50:09,970 - INFO - Normalizando os textos.
2024-11-25 18:50:29,193 - INFO - Tokenizando os textos.
2024-11-25 18:51:00,321 - INFO - Criando bigramas.
2024-11-25 18:51:00,785 - INFO - Removendo stopwords.
2024-11-25 18:51:00,802 - INFO - Aplicando stemming.
2024-11-25 18:51:01,181 - INFO - Aplicando lematização.
2024-11-25 18:51:29,243 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 18:51:29,244 - INFO - Total de linhas antes da remoção: 5000
2024-11-25 18:51:29,256 - INFO - Total de linhas após a remoção: 4968
2024-11-25 18:51:29,258 - INFO - Número de linhas excluídas: 32
2024-11-25 18:51:29,259 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-25 18:54:46,604 - INFO - Codificando sentimentos.
2024-11-25 18:54:46,769 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 18:54:46,769 - INFO - Total de linhas antes da remoção: 4968
2024-11-25 18:54:46,775 - INFO - Total de linhas após a remoção: 4968
2024-11-25 18:54:46,776 - INFO - Número de linhas excluídas: 0
2024-11-25 18:54:46,778 - INFO - Aplicando TF-IDF.
2024-11-25 18:54:46,779 - ERROR - Erro ao aplicar TF-IDF: 'Series' object has no attribute 'compute'
2024-11-25 18:54:46,780 - ERROR - Erro ao processar os dados em blocos: 'Series' object has no attribute 'compute'
2024-11-25 18:54:46,780 - ERROR - Erro durante a execução do pipeline de produção: 'Series' object has no attribute 'compute'
2024-11-25 19:03:00,179 - ERROR - Erro durante a execução do pipeline de produção: [WinError 2] O sistema não pode encontrar o arquivo especificado: 'D:/Github/data-science/projetos/analise-de-sentimentos/nlp/data/raw/dataset.csv'
2024-11-25 19:04:14,693 - ERROR - Erro durante a execução do pipeline de produção: 'utf-8' codec can't decode byte 0xe0 in position 36: invalid continuation byte
2024-11-25 19:07:50,404 - ERROR - Erro durante a execução do pipeline de produção: [Errno 13] Permission denied: 'D:/Github/data-science/projetos/analise-de-sentimentos/nlp/data/raw'
2024-11-25 19:09:42,122 - ERROR - Erro durante a execução do pipeline de produção: [Errno 13] Permission denied: 'D:/Github/data-science/projetos/analise-de-sentimentos/nlp/data/raw'
2024-11-25 19:11:31,057 - INFO - Carregando o dataset bruto.
2024-11-25 19:11:31,083 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 19:11:31,083 - INFO - Renomeando colunas.
2024-11-25 19:11:31,097 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 19:11:31,110 - INFO - Processando bloco 1 de 2
2024-11-25 19:11:31,110 - INFO - Pré-processando os dados.
2024-11-25 19:11:31,459 - INFO - Normalizando os textos.
2024-11-25 19:11:44,962 - INFO - Tokenizando os textos.
2024-11-25 19:12:12,651 - INFO - Criando bigramas.
2024-11-25 19:12:13,093 - INFO - Removendo stopwords.
2024-11-25 19:12:13,108 - INFO - Aplicando stemming.
2024-11-25 19:12:13,491 - INFO - Aplicando lematização.
2024-11-25 19:12:35,270 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 19:12:35,270 - INFO - Total de linhas antes da remoção: 5000
2024-11-25 19:12:35,274 - INFO - Total de linhas após a remoção: 4968
2024-11-25 19:12:35,275 - INFO - Número de linhas excluídas: 32
2024-11-25 19:12:35,276 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-25 19:14:47,254 - INFO - Carregando o dataset bruto.
2024-11-25 19:14:47,280 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 19:14:47,280 - INFO - Renomeando colunas.
2024-11-25 19:14:47,296 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 19:14:47,310 - INFO - Processando bloco 1 de 2
2024-11-25 19:14:47,310 - INFO - Pré-processando os dados.
2024-11-25 19:14:47,663 - INFO - Normalizando os textos.
2024-11-25 19:15:00,482 - INFO - Tokenizando os textos.
2024-11-25 19:15:25,276 - INFO - Criando bigramas.
2024-11-25 19:15:25,711 - INFO - Removendo stopwords.
2024-11-25 19:15:25,726 - INFO - Aplicando stemming.
2024-11-25 19:15:26,112 - INFO - Aplicando lematização.
2024-11-25 19:15:46,571 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 19:15:46,571 - INFO - Total de linhas antes da remoção: 5000
2024-11-25 19:15:46,575 - INFO - Total de linhas após a remoção: 4968
2024-11-25 19:15:46,576 - INFO - Número de linhas excluídas: 32
2024-11-25 19:15:46,576 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-25 19:17:29,462 - INFO - Codificando sentimentos.
2024-11-25 19:17:29,598 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 19:17:29,598 - INFO - Total de linhas antes da remoção: 4968
2024-11-25 19:17:29,603 - INFO - Total de linhas após a remoção: 4968
2024-11-25 19:17:29,603 - INFO - Número de linhas excluídas: 0
2024-11-25 19:17:29,604 - INFO - Aplicando TF-IDF.
2024-11-25 19:17:33,643 - INFO - Bloco 1 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\temp\bloco_1.parquet
2024-11-25 19:17:33,670 - INFO - Processando bloco 2 de 2
2024-11-25 19:17:33,671 - INFO - Pré-processando os dados.
2024-11-25 19:17:33,744 - INFO - Normalizando os textos.
2024-11-25 19:17:36,346 - INFO - Tokenizando os textos.
2024-11-25 19:17:41,188 - INFO - Criando bigramas.
2024-11-25 19:17:41,276 - INFO - Removendo stopwords.
2024-11-25 19:17:41,279 - INFO - Aplicando stemming.
2024-11-25 19:17:41,370 - INFO - Aplicando lematização.
2024-11-25 19:17:45,443 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 19:17:45,444 - INFO - Total de linhas antes da remoção: 1000
2024-11-25 19:17:45,446 - INFO - Total de linhas após a remoção: 998
2024-11-25 19:17:45,446 - INFO - Número de linhas excluídas: 2
2024-11-25 19:17:45,447 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-25 19:18:06,071 - INFO - Codificando sentimentos.
2024-11-25 19:18:06,098 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 19:18:06,099 - INFO - Total de linhas antes da remoção: 998
2024-11-25 19:18:06,101 - INFO - Total de linhas após a remoção: 998
2024-11-25 19:18:06,101 - INFO - Número de linhas excluídas: 0
2024-11-25 19:18:06,101 - INFO - Aplicando TF-IDF.
2024-11-25 19:18:06,474 - INFO - Bloco 2 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\temp\bloco_2.parquet
2024-11-25 19:18:06,475 - INFO - Todos os blocos processados e salvos com sucesso.
2024-11-25 19:18:06,485 - INFO - Pré-processando os dados.
2024-11-25 19:18:06,492 - INFO - Normalizando os textos.
2024-11-25 19:18:07,766 - INFO - Tokenizando os textos.
2024-11-25 19:18:07,893 - INFO - Criando bigramas.
2024-11-25 19:18:07,897 - INFO - Removendo stopwords.
2024-11-25 19:18:07,909 - INFO - Aplicando stemming.
2024-11-25 19:18:07,922 - INFO - Aplicando lematização.
2024-11-25 19:18:08,038 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 19:19:12,562 - INFO - Total de linhas antes da remoção: 5966
2024-11-25 19:21:39,776 - INFO - Total de linhas após a remoção: 5966
2024-11-25 19:21:39,777 - INFO - Número de linhas excluídas: 0
2024-11-25 19:21:39,777 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-25 19:21:45,382 - INFO - Codificando sentimentos.
2024-11-25 19:21:45,391 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 19:26:57,998 - INFO - Total de linhas antes da remoção: 5966
2024-11-25 19:35:48,631 - INFO - Total de linhas após a remoção: 5966
2024-11-25 19:35:48,632 - INFO - Número de linhas excluídas: 0
2024-11-25 19:39:36,846 - INFO - Carregando o dataset bruto.
2024-11-25 19:39:36,880 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 19:39:36,880 - INFO - Renomeando colunas.
2024-11-25 19:39:36,900 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 19:39:36,916 - INFO - Processando bloco 1 de 2
2024-11-25 19:39:36,917 - INFO - Pré-processando os dados.
2024-11-25 19:39:36,917 - ERROR - Erro ao preprocessar os dados: 'Series' object has no attribute 'map_partitions'
2024-11-25 19:39:36,917 - ERROR - Erro ao processar os dados em blocos: 'Series' object has no attribute 'map_partitions'
2024-11-25 19:39:36,917 - ERROR - Erro durante a execução do pipeline de produção: 'Series' object has no attribute 'map_partitions'
2024-11-25 19:43:03,448 - INFO - Carregando o dataset bruto.
2024-11-25 19:43:03,514 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 19:43:03,515 - INFO - Renomeando colunas.
2024-11-25 19:43:03,562 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 19:43:03,603 - INFO - Processando bloco 1 de 2
2024-11-25 19:43:03,604 - INFO - Pré-processando os dados.
2024-11-25 19:43:03,605 - ERROR - Erro ao preprocessar os dados: limpar_texto() got an unexpected keyword argument 'meta'
2024-11-25 19:43:03,606 - ERROR - Erro ao processar os dados em blocos: limpar_texto() got an unexpected keyword argument 'meta'
2024-11-25 19:43:03,607 - ERROR - Erro durante a execução do pipeline de produção: limpar_texto() got an unexpected keyword argument 'meta'
2024-11-25 19:44:25,033 - INFO - Carregando o dataset bruto.
2024-11-25 19:44:25,053 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 19:44:25,054 - INFO - Renomeando colunas.
2024-11-25 19:44:25,068 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 19:44:25,083 - INFO - Processando bloco 1 de 2
2024-11-25 19:44:25,083 - INFO - Pré-processando os dados.
2024-11-25 19:44:25,085 - ERROR - Erro ao preprocessar os dados: limpar_texto() got an unexpected keyword argument 'meta'
2024-11-25 19:44:25,085 - ERROR - Erro ao processar os dados em blocos: limpar_texto() got an unexpected keyword argument 'meta'
2024-11-25 19:44:25,085 - ERROR - Erro durante a execução do pipeline de produção: limpar_texto() got an unexpected keyword argument 'meta'
2024-11-25 19:46:12,318 - INFO - Carregando o dataset bruto.
2024-11-25 19:46:12,340 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 19:46:12,340 - INFO - Renomeando colunas.
2024-11-25 19:46:12,356 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 19:46:12,368 - INFO - Processando bloco 1 de 2
2024-11-25 19:46:12,368 - INFO - Pré-processando os dados.
2024-11-25 19:46:12,369 - ERROR - Erro ao preprocessar os dados: limpar_texto() got an unexpected keyword argument 'meta'
2024-11-25 19:46:12,369 - ERROR - Erro ao processar os dados em blocos: limpar_texto() got an unexpected keyword argument 'meta'
2024-11-25 19:46:12,370 - ERROR - Erro durante a execução do pipeline de produção: limpar_texto() got an unexpected keyword argument 'meta'
2024-11-25 19:51:47,984 - INFO - Carregando o dataset bruto.
2024-11-25 19:51:48,012 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 19:51:48,012 - INFO - Renomeando colunas.
2024-11-25 19:51:48,027 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 19:51:48,039 - INFO - Processando bloco 1 de 2
2024-11-25 19:51:48,040 - INFO - Pré-processando os dados.
2024-11-25 19:51:48,389 - INFO - Normalizando os textos.
2024-11-25 19:52:01,893 - INFO - Tokenizando os textos.
2024-11-25 19:52:28,513 - INFO - Criando bigramas.
2024-11-25 19:52:28,969 - INFO - Removendo stopwords.
2024-11-25 19:52:28,987 - INFO - Aplicando stemming.
2024-11-25 19:52:29,369 - INFO - Aplicando lematização.
2024-11-25 19:52:55,447 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 19:52:55,453 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-25 19:52:55,454 - ERROR - Erro ao classificar sentimentos: classificar_sentimento_vader() got an unexpected keyword argument 'meta'
2024-11-25 19:52:55,455 - ERROR - Erro ao processar os dados em blocos: classificar_sentimento_vader() got an unexpected keyword argument 'meta'
2024-11-25 19:52:55,455 - ERROR - Erro durante a execução do pipeline de produção: classificar_sentimento_vader() got an unexpected keyword argument 'meta'
2024-11-25 19:56:54,871 - INFO - Carregando o dataset bruto.
2024-11-25 19:56:54,895 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 19:56:54,895 - INFO - Renomeando colunas.
2024-11-25 19:56:54,897 - INFO - Pré-processando os dados.
2024-11-25 19:56:54,904 - INFO - Normalizando os textos.
2024-11-25 19:56:56,109 - INFO - Tokenizando os textos.
2024-11-25 19:56:56,213 - INFO - Criando bigramas.
2024-11-25 19:56:56,218 - INFO - Removendo stopwords.
2024-11-25 19:56:56,227 - INFO - Aplicando stemming.
2024-11-25 19:56:56,237 - INFO - Aplicando lematização.
2024-11-25 19:56:56,338 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 19:56:56,342 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-25 19:57:00,528 - INFO - Codificando sentimentos.
2024-11-25 19:57:00,532 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 19:57:00,534 - INFO - Aplicando TF-IDF.
2024-11-25 20:00:08,800 - ERROR - Erro ao aplicar TF-IDF: Column assignment doesn't support type list
2024-11-25 20:00:08,801 - ERROR - Erro durante a execução do pipeline de produção: Column assignment doesn't support type list
2024-11-25 20:22:52,799 - INFO - Carregando o dataset bruto.
2024-11-25 20:22:52,822 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 20:22:52,823 - INFO - Renomeando colunas.
2024-11-25 20:22:52,824 - INFO - Pré-processando os dados.
2024-11-25 20:22:52,830 - INFO - Normalizando os textos.
2024-11-25 20:22:54,042 - INFO - Tokenizando os textos.
2024-11-25 20:22:54,150 - INFO - Criando bigramas.
2024-11-25 20:22:54,154 - INFO - Removendo stopwords.
2024-11-25 20:22:54,161 - INFO - Aplicando stemming.
2024-11-25 20:22:54,168 - INFO - Aplicando lematização.
2024-11-25 20:22:54,266 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 20:22:54,272 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-25 20:22:58,558 - INFO - Codificando sentimentos.
2024-11-25 20:22:58,562 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 20:22:58,564 - INFO - Aplicando TF-IDF.
2024-11-25 20:26:09,306 - ERROR - Erro ao aplicar TF-IDF: name 'pd' is not defined
2024-11-25 20:26:09,307 - ERROR - Erro durante a execução do pipeline de produção: name 'pd' is not defined
2024-11-25 20:27:39,716 - INFO - Carregando o dataset bruto.
2024-11-25 20:27:39,741 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 20:27:39,741 - INFO - Renomeando colunas.
2024-11-25 20:27:39,743 - INFO - Pré-processando os dados.
2024-11-25 20:27:39,751 - INFO - Normalizando os textos.
2024-11-25 20:27:40,976 - INFO - Tokenizando os textos.
2024-11-25 20:27:41,076 - INFO - Criando bigramas.
2024-11-25 20:27:41,080 - INFO - Removendo stopwords.
2024-11-25 20:27:41,086 - INFO - Aplicando stemming.
2024-11-25 20:27:41,095 - INFO - Aplicando lematização.
2024-11-25 20:27:41,196 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 20:27:41,201 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-25 20:27:45,402 - INFO - Codificando sentimentos.
2024-11-25 20:27:45,405 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 20:27:45,407 - INFO - Aplicando TF-IDF.
2024-11-25 20:32:48,100 - ERROR - Erro ao aplicar TF-IDF: Not all divisions are known, can't align partitions. Please use `set_index` to set the index.
2024-11-25 20:32:48,101 - ERROR - Erro durante a execução do pipeline de produção: Not all divisions are known, can't align partitions. Please use `set_index` to set the index.
2024-11-25 20:39:36,633 - INFO - Carregando o dataset bruto.
2024-11-25 20:39:36,674 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 20:39:36,675 - INFO - Renomeando colunas.
2024-11-25 20:39:36,676 - INFO - Pré-processando os dados.
2024-11-25 20:39:36,684 - INFO - Normalizando os textos.
2024-11-25 20:39:38,468 - INFO - Tokenizando os textos.
2024-11-25 20:39:38,630 - INFO - Criando bigramas.
2024-11-25 20:39:38,639 - INFO - Removendo stopwords.
2024-11-25 20:39:38,660 - INFO - Aplicando stemming.
2024-11-25 20:39:38,679 - INFO - Aplicando lematização.
2024-11-25 20:39:38,819 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 20:39:38,823 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-25 20:39:44,284 - INFO - Codificando sentimentos.
2024-11-25 20:39:44,289 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 20:39:44,292 - INFO - Aplicando TF-IDF.
2024-11-25 20:44:38,150 - ERROR - Erro ao aplicar TF-IDF: 'Series' object has no attribute 'set_index'
2024-11-25 20:44:38,151 - ERROR - Erro durante a execução do pipeline de produção: 'Series' object has no attribute 'set_index'
2024-11-25 20:48:42,316 - INFO - Carregando o dataset bruto.
2024-11-25 20:48:42,368 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 20:48:42,369 - INFO - Renomeando colunas.
2024-11-25 20:48:42,372 - INFO - Pré-processando os dados.
2024-11-25 20:48:42,381 - INFO - Normalizando os textos.
2024-11-25 20:48:44,035 - INFO - Tokenizando os textos.
2024-11-25 20:48:44,162 - INFO - Criando bigramas.
2024-11-25 20:48:44,165 - INFO - Removendo stopwords.
2024-11-25 20:48:44,178 - INFO - Aplicando stemming.
2024-11-25 20:48:44,187 - INFO - Aplicando lematização.
2024-11-25 20:48:44,359 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 20:48:44,365 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-25 20:48:49,517 - INFO - Codificando sentimentos.
2024-11-25 20:48:49,527 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 20:48:49,530 - INFO - Aplicando TF-IDF.
2024-11-25 20:53:59,077 - INFO - Salvando dataset processado.
2024-11-25 21:04:17,031 - INFO - Número de linhas com NaN em 'sentimento_codificado' antes da exclusão: 0
2024-11-25 21:04:17,043 - INFO - Número de linhas restantes após a remoção de NaNs: 5966
2024-11-25 21:04:21,892 - INFO - Dataset salvo com sucesso.
2024-11-25 21:04:21,909 - INFO - Gerando relatórios.
2024-11-25 21:11:55,040 - INFO - Relatórios gerados com sucesso.
2024-11-25 21:20:51,174 - INFO - Carregando o dataset bruto.
2024-11-25 21:20:51,205 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 21:20:51,205 - INFO - Renomeando colunas.
2024-11-25 21:20:51,224 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 21:20:51,224 - INFO - Total de blocos a serem processados: 2
2024-11-25 21:20:51,242 - INFO - Processando bloco 1 de 2
2024-11-25 21:20:51,242 - INFO - Pré-processando os dados.
2024-11-25 21:20:51,243 - ERROR - Erro ao preprocessar os dados: limpar_texto() got an unexpected keyword argument 'meta'
2024-11-25 21:20:51,243 - ERROR - Erro ao processar os dados em blocos: limpar_texto() got an unexpected keyword argument 'meta'
2024-11-25 21:20:51,243 - ERROR - Erro durante a execução do pipeline de produção: limpar_texto() got an unexpected keyword argument 'meta'
2024-11-25 21:26:56,742 - INFO - Carregando o dataset bruto.
2024-11-25 21:26:56,773 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 21:26:56,774 - INFO - Renomeando colunas.
2024-11-25 21:26:56,799 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 21:26:56,799 - INFO - Total de blocos a serem processados: 2
2024-11-25 21:26:56,812 - INFO - Processando bloco 1 de 2
2024-11-25 21:26:56,813 - INFO - Pré-processando os dados.
2024-11-25 21:26:56,814 - ERROR - Erro ao preprocessar os dados: limpar_texto() got an unexpected keyword argument 'meta'
2024-11-25 21:26:56,814 - ERROR - Erro ao processar os dados em blocos: limpar_texto() got an unexpected keyword argument 'meta'
2024-11-25 21:26:56,814 - ERROR - Erro durante a execução do pipeline de produção: limpar_texto() got an unexpected keyword argument 'meta'
2024-11-25 21:30:17,512 - INFO - Carregando o dataset bruto.
2024-11-25 21:30:17,537 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 21:30:17,537 - INFO - Renomeando colunas.
2024-11-25 21:30:17,554 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 21:30:17,555 - INFO - Total de blocos a serem processados: 2
2024-11-25 21:30:17,566 - INFO - Processando bloco 1 de 2
2024-11-25 21:30:17,568 - INFO - Pré-processando os dados.
2024-11-25 21:30:17,569 - ERROR - Erro ao preprocessar os dados: limpar_texto() got an unexpected keyword argument 'meta'
2024-11-25 21:30:17,569 - ERROR - Erro ao processar os dados em blocos: limpar_texto() got an unexpected keyword argument 'meta'
2024-11-25 21:30:17,570 - ERROR - Erro durante a execução do pipeline de produção: limpar_texto() got an unexpected keyword argument 'meta'
2024-11-25 21:37:32,144 - INFO - Carregando o dataset bruto.
2024-11-25 21:37:32,170 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 21:37:32,171 - INFO - Renomeando colunas.
2024-11-25 21:37:32,185 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 21:37:32,185 - INFO - Total de blocos a serem processados: 2
2024-11-25 21:37:32,199 - INFO - Processando bloco 1 de 2
2024-11-25 21:37:32,200 - INFO - Pré-processando os dados.
2024-11-25 21:37:32,200 - ERROR - Erro ao preprocessar os dados: limpar_texto() got an unexpected keyword argument 'meta'
2024-11-25 21:37:32,201 - ERROR - Erro ao processar os dados em blocos: limpar_texto() got an unexpected keyword argument 'meta'
2024-11-25 21:37:32,201 - ERROR - Erro durante a execução do pipeline de produção: limpar_texto() got an unexpected keyword argument 'meta'
2024-11-25 21:42:43,758 - INFO - Carregando o dataset bruto.
2024-11-25 21:42:43,781 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 21:42:43,782 - INFO - Renomeando colunas.
2024-11-25 21:42:43,795 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 21:42:43,795 - INFO - Total de blocos a serem processados: 2
2024-11-25 21:42:43,807 - INFO - Processando bloco 1 de 2
2024-11-25 21:42:43,807 - INFO - Pré-processando os dados.
2024-11-25 21:42:44,138 - INFO - Normalizando os textos.
2024-11-25 21:42:56,800 - INFO - Tokenizando os textos.
2024-11-25 21:43:32,330 - INFO - Criando bigramas.
2024-11-25 21:43:32,869 - INFO - Removendo stopwords.
2024-11-25 21:43:32,890 - INFO - Aplicando stemming.
2024-11-25 21:43:33,393 - INFO - Aplicando lematização.
2024-11-25 21:44:04,779 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 21:44:04,784 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-25 21:49:52,923 - INFO - Codificando sentimentos.
2024-11-25 21:49:53,132 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 21:49:53,135 - INFO - Aplicando TF-IDF.
2024-11-25 21:49:53,136 - ERROR - Erro ao aplicar TF-IDF: 'Series' object has no attribute 'compute'
2024-11-25 21:49:53,136 - ERROR - Erro ao processar os dados em blocos: 'Series' object has no attribute 'compute'
2024-11-25 21:49:53,136 - ERROR - Erro durante a execução do pipeline de produção: 'Series' object has no attribute 'compute'
2024-11-25 22:13:26,339 - INFO - Carregando o dataset bruto.
2024-11-25 22:13:26,371 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 22:13:26,372 - INFO - Renomeando colunas.
2024-11-25 22:13:26,387 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 22:13:26,389 - INFO - Total de blocos a serem processados: 2
2024-11-25 22:13:26,406 - INFO - Processando bloco 1 de 2
2024-11-25 22:13:26,406 - INFO - Pré-processando os dados.
2024-11-25 22:13:26,849 - INFO - Normalizando os textos.
2024-11-25 22:13:45,403 - INFO - Tokenizando os textos.
2024-11-25 22:14:24,854 - INFO - Criando bigramas.
2024-11-25 22:14:25,458 - INFO - Removendo stopwords.
2024-11-25 22:14:25,477 - INFO - Aplicando stemming.
2024-11-25 22:14:26,007 - INFO - Aplicando lematização.
2024-11-25 22:14:58,979 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 22:14:58,985 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-25 22:21:20,585 - INFO - Codificando sentimentos.
2024-11-25 22:21:20,836 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 22:21:20,851 - INFO - Aplicando TF-IDF.
2024-11-25 22:21:20,852 - ERROR - Erro ao aplicar TF-IDF: 'Series' object has no attribute 'compute'
2024-11-25 22:21:20,852 - ERROR - Erro ao processar os dados em blocos: 'Series' object has no attribute 'compute'
2024-11-25 22:21:20,853 - ERROR - Erro durante a execução do pipeline de produção: 'Series' object has no attribute 'compute'
2024-11-25 22:23:53,687 - INFO - Carregando o dataset bruto.
2024-11-25 22:23:53,723 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 22:23:53,723 - INFO - Renomeando colunas.
2024-11-25 22:23:53,743 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 22:23:53,744 - INFO - Total de blocos a serem processados: 2
2024-11-25 22:23:53,760 - INFO - Processando bloco 1 de 2
2024-11-25 22:23:53,761 - INFO - Pré-processando os dados.
2024-11-25 22:23:54,261 - INFO - Normalizando os textos.
2024-11-25 22:24:12,034 - INFO - Tokenizando os textos.
2024-11-25 22:24:51,500 - INFO - Criando bigramas.
2024-11-25 22:24:52,118 - INFO - Removendo stopwords.
2024-11-25 22:24:52,145 - INFO - Aplicando stemming.
2024-11-25 22:24:52,705 - INFO - Aplicando lematização.
2024-11-25 22:25:18,918 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 22:25:18,925 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-25 22:29:30,727 - INFO - Codificando sentimentos.
2024-11-25 22:29:30,862 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 22:29:30,862 - INFO - Aplicando TF-IDF.
2024-11-25 22:29:31,010 - ERROR - Erro ao aplicar TF-IDF: name 'pd' is not defined
2024-11-25 22:29:31,010 - ERROR - Erro ao processar os dados em blocos: name 'pd' is not defined
2024-11-25 22:29:31,011 - ERROR - Erro durante a execução do pipeline de produção: name 'pd' is not defined
2024-11-25 22:32:31,320 - INFO - Carregando o dataset bruto.
2024-11-25 22:32:31,370 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 22:32:31,370 - INFO - Renomeando colunas.
2024-11-25 22:32:31,399 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 22:32:31,400 - INFO - Total de blocos a serem processados: 2
2024-11-25 22:32:31,432 - INFO - Processando bloco 1 de 2
2024-11-25 22:32:31,432 - INFO - Pré-processando os dados.
2024-11-25 22:32:31,931 - INFO - Normalizando os textos.
2024-11-25 22:32:56,506 - INFO - Tokenizando os textos.
2024-11-25 22:33:49,891 - INFO - Criando bigramas.
2024-11-25 22:33:50,572 - INFO - Removendo stopwords.
2024-11-25 22:33:50,617 - INFO - Aplicando stemming.
2024-11-25 22:33:51,256 - INFO - Aplicando lematização.
2024-11-25 22:34:35,179 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 22:34:35,186 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-25 22:41:33,639 - INFO - Codificando sentimentos.
2024-11-25 22:41:33,816 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 22:41:33,822 - INFO - Aplicando TF-IDF.
2024-11-25 22:41:40,378 - ERROR - Erro ao aplicar TF-IDF: 'DataFrame' object has no attribute 'npartitions'
2024-11-25 22:41:40,378 - ERROR - Erro ao processar os dados em blocos: 'DataFrame' object has no attribute 'npartitions'
2024-11-25 22:41:40,378 - ERROR - Erro durante a execução do pipeline de produção: 'DataFrame' object has no attribute 'npartitions'
2024-11-25 22:46:45,184 - INFO - Carregando o dataset bruto.
2024-11-25 22:46:45,226 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 22:46:45,227 - INFO - Renomeando colunas.
2024-11-25 22:46:45,252 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 22:46:45,253 - INFO - Total de blocos a serem processados: 2
2024-11-25 22:46:45,266 - INFO - Processando bloco 1 de 2
2024-11-25 22:46:45,267 - INFO - Pré-processando os dados.
2024-11-25 22:46:45,267 - ERROR - Erro ao preprocessar os dados: limpar_texto() got an unexpected keyword argument 'meta'
2024-11-25 22:46:45,269 - ERROR - Erro ao processar os dados em blocos: limpar_texto() got an unexpected keyword argument 'meta'
2024-11-25 22:46:45,269 - ERROR - Erro durante a execução do pipeline de produção: limpar_texto() got an unexpected keyword argument 'meta'
2024-11-25 22:51:47,202 - INFO - Carregando o dataset bruto.
2024-11-25 22:51:47,231 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 22:51:47,231 - INFO - Renomeando colunas.
2024-11-25 22:51:47,247 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 22:51:47,247 - INFO - Total de blocos a serem processados: 2
2024-11-25 22:51:47,261 - INFO - Processando bloco 1 de 2
2024-11-25 22:51:47,261 - INFO - Pré-processando os dados.
2024-11-25 22:51:47,706 - INFO - Normalizando os textos.
2024-11-25 22:52:07,711 - INFO - Tokenizando os textos.
2024-11-25 22:52:45,392 - INFO - Criando bigramas.
2024-11-25 22:52:45,942 - INFO - Removendo stopwords.
2024-11-25 22:52:45,967 - INFO - Aplicando stemming.
2024-11-25 22:52:46,483 - INFO - Aplicando lematização.
2024-11-25 22:53:18,470 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 22:53:18,491 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-25 22:59:41,291 - ERROR - Erro ao classificar sentimentos: <lambda>() got an unexpected keyword argument 'meta'
2024-11-25 22:59:41,291 - ERROR - Erro ao processar os dados em blocos: <lambda>() got an unexpected keyword argument 'meta'
2024-11-25 22:59:41,299 - ERROR - Erro durante a execução do pipeline de produção: <lambda>() got an unexpected keyword argument 'meta'
2024-11-25 23:08:50,706 - INFO - Carregando o dataset bruto.
2024-11-25 23:08:50,744 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 23:08:50,744 - INFO - Renomeando colunas.
2024-11-25 23:08:50,773 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 23:08:50,773 - INFO - Total de blocos a serem processados: 2
2024-11-25 23:08:50,787 - INFO - Processando bloco 1 de 2
2024-11-25 23:08:50,788 - INFO - Pré-processando os dados.
2024-11-25 23:08:51,239 - INFO - Normalizando os textos.
2024-11-25 23:09:08,955 - INFO - Tokenizando os textos.
2024-11-25 23:09:46,946 - INFO - Criando bigramas.
2024-11-25 23:09:47,520 - INFO - Removendo stopwords.
2024-11-25 23:09:47,537 - INFO - Aplicando stemming.
2024-11-25 23:09:48,037 - INFO - Aplicando lematização.
2024-11-25 23:10:19,761 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 23:10:19,767 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-25 23:16:08,585 - INFO - Codificando sentimentos.
2024-11-25 23:16:08,769 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 23:16:08,775 - INFO - Aplicando TF-IDF.
2024-11-25 23:16:08,775 - ERROR - Erro ao aplicar TF-IDF: 'Series' object has no attribute 'compute'
2024-11-25 23:16:08,775 - ERROR - Erro ao processar os dados em blocos: 'Series' object has no attribute 'compute'
2024-11-25 23:16:08,778 - ERROR - Erro durante a execução do pipeline de produção: 'Series' object has no attribute 'compute'
2024-11-25 23:18:06,855 - INFO - Carregando o dataset bruto.
2024-11-25 23:18:06,890 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-25 23:18:06,890 - INFO - Renomeando colunas.
2024-11-25 23:18:06,913 - INFO - Total de linhas a serem processadas: 6000
2024-11-25 23:18:06,913 - INFO - Total de blocos a serem processados: 2
2024-11-25 23:18:06,945 - INFO - Processando bloco 1 de 2
2024-11-25 23:18:06,946 - INFO - Pré-processando os dados.
2024-11-25 23:18:07,375 - INFO - Normalizando os textos.
2024-11-25 23:18:24,610 - INFO - Tokenizando os textos.
2024-11-25 23:18:50,307 - INFO - Criando bigramas.
2024-11-25 23:18:50,735 - INFO - Removendo stopwords.
2024-11-25 23:18:50,753 - INFO - Aplicando stemming.
2024-11-25 23:18:51,136 - INFO - Aplicando lematização.
2024-11-25 23:19:10,785 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 23:19:10,785 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-25 23:22:19,213 - INFO - Codificando sentimentos.
2024-11-25 23:22:19,349 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 23:22:19,364 - INFO - Aplicando TF-IDF.
2024-11-25 23:22:24,013 - INFO - Bloco 1 salvo em temp_data\bloco_1.parquet
2024-11-25 23:22:24,040 - INFO - Processando bloco 2 de 2
2024-11-25 23:22:24,041 - INFO - Pré-processando os dados.
2024-11-25 23:22:24,096 - INFO - Normalizando os textos.
2024-11-25 23:22:26,646 - INFO - Tokenizando os textos.
2024-11-25 23:22:31,431 - INFO - Criando bigramas.
2024-11-25 23:22:31,514 - INFO - Removendo stopwords.
2024-11-25 23:22:31,530 - INFO - Aplicando stemming.
2024-11-25 23:22:31,597 - INFO - Aplicando lematização.
2024-11-25 23:22:35,530 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 23:22:35,545 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-25 23:23:13,695 - INFO - Codificando sentimentos.
2024-11-25 23:23:13,725 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-25 23:23:13,727 - INFO - Aplicando TF-IDF.
2024-11-25 23:23:14,180 - INFO - Bloco 2 salvo em temp_data\bloco_2.parquet
2024-11-25 23:23:14,180 - INFO - Salvando dataset processado.
2024-11-25 23:23:14,539 - INFO - Número de linhas com NaN em 'sentimento_codificado' antes da exclusão: 0
2024-11-25 23:23:14,544 - INFO - Número de linhas restantes após a remoção de NaNs: 5966
2024-11-25 23:23:18,459 - INFO - Dataset salvo com sucesso.
2024-11-25 23:23:18,483 - INFO - Todos os blocos processados e combinados com sucesso.
2024-11-25 23:23:18,485 - INFO - Gerando relatórios.
2024-11-25 23:23:18,503 - INFO - Relatórios gerados com sucesso.
2024-11-26 13:30:56,746 - INFO - Carregando o dataset bruto.
2024-11-26 13:30:56,814 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-26 13:30:56,814 - INFO - Renomeando colunas.
2024-11-26 13:30:56,844 - INFO - Total de linhas a serem processadas: 6000
2024-11-26 13:30:56,844 - INFO - Total de blocos a serem processados: 2
2024-11-26 13:30:56,865 - INFO - Processando bloco 1 de 2
2024-11-26 13:30:56,865 - INFO - Pré-processando os dados.
2024-11-26 13:30:57,439 - INFO - Normalizando os textos.
2024-11-26 13:31:23,312 - INFO - Tokenizando os textos.
2024-11-26 13:32:29,645 - INFO - Criando bigramas.
2024-11-26 13:32:30,295 - INFO - Removendo stopwords.
2024-11-26 13:32:30,325 - INFO - Aplicando stemming.
2024-11-26 13:32:30,912 - INFO - Aplicando lematização.
2024-11-26 13:33:14,319 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 13:33:14,332 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 13:40:16,545 - INFO - Codificando sentimentos.
2024-11-26 13:40:16,764 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 13:40:16,785 - INFO - Aplicando TF-IDF.
2024-11-26 13:40:30,546 - INFO - Bloco 1 salvo em temp_data\bloco_1.parquet
2024-11-26 13:40:30,629 - INFO - Processando bloco 2 de 2
2024-11-26 13:40:30,629 - INFO - Pré-processando os dados.
2024-11-26 13:40:30,786 - INFO - Normalizando os textos.
2024-11-26 13:40:36,096 - INFO - Tokenizando os textos.
2024-11-26 13:40:50,288 - INFO - Criando bigramas.
2024-11-26 13:40:50,488 - INFO - Removendo stopwords.
2024-11-26 13:40:50,495 - INFO - Aplicando stemming.
2024-11-26 13:40:50,614 - INFO - Aplicando lematização.
2024-11-26 13:40:59,874 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 13:40:59,874 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 13:42:29,962 - INFO - Codificando sentimentos.
2024-11-26 13:42:30,040 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 13:42:30,040 - INFO - Aplicando TF-IDF.
2024-11-26 13:42:30,781 - INFO - Bloco 2 salvo em temp_data\bloco_2.parquet
2024-11-26 13:42:30,797 - INFO - Salvando dataset processado.
2024-11-26 13:42:31,426 - INFO - Número de linhas com NaN em 'sentimento_codificado' antes da exclusão: 0
2024-11-26 13:42:31,445 - INFO - Número de linhas restantes após a remoção de NaNs: 5966
2024-11-26 13:42:37,712 - INFO - Dataset salvo com sucesso.
2024-11-26 13:42:37,761 - INFO - Todos os blocos processados e combinados com sucesso.
2024-11-26 13:42:37,764 - INFO - Gerando relatórios.
2024-11-26 13:42:37,812 - INFO - Relatórios gerados com sucesso.
2024-11-26 14:02:20,693 - INFO - Carregando o dataset bruto.
2024-11-26 14:02:20,848 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-26 14:02:20,849 - INFO - Renomeando colunas.
2024-11-26 14:02:20,895 - INFO - Total de linhas a serem processadas: 6000
2024-11-26 14:02:20,900 - INFO - Total de blocos a serem processados: 2
2024-11-26 14:02:20,943 - INFO - Processando bloco 1 de 2
2024-11-26 14:02:20,954 - INFO - Pré-processando os dados.
2024-11-26 14:02:21,688 - INFO - Normalizando os textos.
2024-11-26 14:02:51,025 - INFO - Tokenizando os textos.
2024-11-26 14:03:53,143 - INFO - Criando bigramas.
2024-11-26 14:03:53,806 - INFO - Removendo stopwords.
2024-11-26 14:03:53,837 - INFO - Aplicando stemming.
2024-11-26 14:03:54,469 - INFO - Aplicando lematização.
2024-11-26 14:04:42,486 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 14:04:42,506 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 14:13:12,247 - INFO - Codificando sentimentos.
2024-11-26 14:13:12,494 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 14:13:12,512 - INFO - Aplicando TF-IDF.
2024-11-26 14:13:12,512 - ERROR - Erro ao aplicar TF-IDF: 'Series' object has no attribute 'compute'
2024-11-26 14:13:12,513 - ERROR - Erro ao processar os dados em blocos: 'Series' object has no attribute 'compute'
2024-11-26 14:13:12,513 - ERROR - Erro durante a execução do pipeline de produção: 'Series' object has no attribute 'compute'
2024-11-26 14:15:40,463 - INFO - Carregando o dataset bruto.
2024-11-26 14:15:40,522 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-26 14:15:40,523 - INFO - Renomeando colunas.
2024-11-26 14:15:40,561 - INFO - Total de linhas a serem processadas: 6000
2024-11-26 14:15:40,563 - INFO - Total de blocos a serem processados: 2
2024-11-26 14:15:40,598 - INFO - Processando bloco 1 de 2
2024-11-26 14:15:40,598 - INFO - Pré-processando os dados.
2024-11-26 14:15:41,352 - INFO - Normalizando os textos.
2024-11-26 14:16:07,776 - INFO - Tokenizando os textos.
2024-11-26 14:17:06,960 - INFO - Criando bigramas.
2024-11-26 14:17:07,821 - INFO - Removendo stopwords.
2024-11-26 14:17:07,848 - INFO - Aplicando stemming.
2024-11-26 14:17:08,517 - INFO - Aplicando lematização.
2024-11-26 14:17:55,927 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 14:17:55,939 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 14:26:03,113 - INFO - Codificando sentimentos.
2024-11-26 14:26:03,399 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 14:26:03,414 - INFO - Aplicando TF-IDF.
2024-11-26 14:26:18,131 - INFO - Bloco 1 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_1.parquet
2024-11-26 14:26:18,211 - INFO - Processando bloco 2 de 2
2024-11-26 14:26:18,212 - INFO - Pré-processando os dados.
2024-11-26 14:26:18,362 - INFO - Normalizando os textos.
2024-11-26 14:26:24,359 - INFO - Tokenizando os textos.
2024-11-26 14:26:38,610 - INFO - Criando bigramas.
2024-11-26 14:26:38,796 - INFO - Removendo stopwords.
2024-11-26 14:26:38,806 - INFO - Aplicando stemming.
2024-11-26 14:26:38,992 - INFO - Aplicando lematização.
2024-11-26 14:26:50,642 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 14:26:50,646 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 14:28:41,443 - INFO - Codificando sentimentos.
2024-11-26 14:28:41,516 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 14:28:41,522 - INFO - Aplicando TF-IDF.
2024-11-26 14:28:42,559 - INFO - Bloco 2 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_2.parquet
2024-11-26 14:28:42,574 - INFO - Salvando dataset processado.
2024-11-26 14:28:43,520 - INFO - Número de linhas com NaN em 'sentimento_codificado' antes da exclusão: 0
2024-11-26 14:28:43,541 - INFO - Número de linhas restantes após a remoção de NaNs: 5966
2024-11-26 14:28:43,562 - INFO - Amostra salva com sucesso.
2024-11-26 14:28:52,715 - INFO - Dataset salvo com sucesso.
2024-11-26 14:28:52,784 - INFO - Todos os blocos processados e combinados com sucesso.
2024-11-26 14:28:52,789 - INFO - Gerando relatórios.
2024-11-26 14:28:52,848 - INFO - Relatórios gerados com sucesso.
2024-11-26 14:40:58,917 - INFO - Carregando o dataset bruto.
2024-11-26 14:40:58,961 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-26 14:40:58,961 - INFO - Renomeando colunas.
2024-11-26 14:40:58,983 - INFO - Total de linhas a serem processadas: 6000
2024-11-26 14:40:58,984 - INFO - Total de blocos a serem processados: 2
2024-11-26 14:40:59,004 - INFO - Processando bloco 1 de 2
2024-11-26 14:40:59,004 - INFO - Pré-processando os dados.
2024-11-26 14:40:59,515 - INFO - Normalizando os textos.
2024-11-26 14:41:16,300 - INFO - Tokenizando os textos.
2024-11-26 14:41:49,640 - INFO - Criando bigramas.
2024-11-26 14:41:50,180 - INFO - Removendo stopwords.
2024-11-26 14:41:50,197 - INFO - Aplicando stemming.
2024-11-26 14:41:50,688 - INFO - Aplicando lematização.
2024-11-26 14:42:16,923 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 14:42:16,927 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 14:46:58,889 - INFO - Codificando sentimentos.
2024-11-26 14:46:59,059 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 14:46:59,067 - INFO - Aplicando TF-IDF.
2024-11-26 14:47:05,354 - INFO - Bloco 1 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_1.parquet
2024-11-26 14:47:05,386 - INFO - Processando bloco 2 de 2
2024-11-26 14:47:05,386 - INFO - Pré-processando os dados.
2024-11-26 14:47:05,483 - INFO - Normalizando os textos.
2024-11-26 14:47:08,568 - INFO - Tokenizando os textos.
2024-11-26 14:47:14,902 - INFO - Criando bigramas.
2024-11-26 14:47:15,008 - INFO - Removendo stopwords.
2024-11-26 14:47:15,012 - INFO - Aplicando stemming.
2024-11-26 14:47:15,098 - INFO - Aplicando lematização.
2024-11-26 14:47:20,464 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 14:47:20,466 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 14:48:19,954 - INFO - Codificando sentimentos.
2024-11-26 14:48:19,996 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 14:48:19,998 - INFO - Aplicando TF-IDF.
2024-11-26 14:48:20,545 - INFO - Bloco 2 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_2.parquet
2024-11-26 14:48:20,562 - INFO - Salvando dataset processado.
2024-11-26 14:48:21,127 - INFO - Número de linhas com NaN em 'sentimento_codificado' antes da exclusão: 0
2024-11-26 14:48:21,134 - INFO - Número de linhas restantes após a remoção de NaNs: 5966
2024-11-26 14:48:21,135 - INFO - Contando sentimentos positivos, neutros e negativos.
2024-11-26 14:48:21,137 - INFO - Sentimentos positivos: 978
2024-11-26 14:48:21,137 - INFO - Sentimentos neutros: 2242
2024-11-26 14:48:21,138 - INFO - Sentimentos negativos: 2746
2024-11-26 14:48:21,142 - INFO - Amostra salva com sucesso.
2024-11-26 14:48:25,893 - INFO - Dataset salvo com sucesso.
2024-11-26 14:48:25,928 - INFO - Todos os blocos processados e combinados com sucesso.
2024-11-26 14:48:25,934 - INFO - Gerando relatórios.
2024-11-26 14:48:25,966 - INFO - Relatórios gerados com sucesso.
2024-11-26 14:52:56,662 - INFO - Carregando o dataset bruto.
2024-11-26 14:52:56,710 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-26 14:52:56,711 - INFO - Renomeando colunas.
2024-11-26 14:52:56,736 - INFO - Total de linhas a serem processadas: 6000
2024-11-26 14:52:56,737 - INFO - Total de blocos a serem processados: 2
2024-11-26 14:52:56,760 - INFO - Processando bloco 1 de 2
2024-11-26 14:52:56,760 - INFO - Pré-processando os dados.
2024-11-26 14:52:57,287 - INFO - Normalizando os textos.
2024-11-26 14:53:14,137 - INFO - Tokenizando os textos.
2024-11-26 14:53:49,564 - INFO - Criando bigramas.
2024-11-26 14:53:50,105 - INFO - Removendo stopwords.
2024-11-26 14:53:50,121 - INFO - Aplicando stemming.
2024-11-26 14:53:50,542 - INFO - Aplicando lematização.
2024-11-26 14:54:17,054 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 14:54:17,059 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 15:00:37,228 - INFO - Codificando sentimentos.
2024-11-26 15:00:37,435 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 15:00:37,443 - INFO - Aplicando TF-IDF.
2024-11-26 15:00:47,979 - INFO - Bloco 1 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_1.parquet
2024-11-26 15:00:48,053 - INFO - Processando bloco 2 de 2
2024-11-26 15:00:48,053 - INFO - Pré-processando os dados.
2024-11-26 15:00:48,203 - INFO - Normalizando os textos.
2024-11-26 15:00:52,820 - INFO - Tokenizando os textos.
2024-11-26 15:01:03,694 - INFO - Criando bigramas.
2024-11-26 15:01:03,831 - INFO - Removendo stopwords.
2024-11-26 15:01:03,841 - INFO - Aplicando stemming.
2024-11-26 15:01:03,977 - INFO - Aplicando lematização.
2024-11-26 15:01:13,610 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 15:01:13,613 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 15:02:49,733 - INFO - Codificando sentimentos.
2024-11-26 15:02:49,792 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 15:02:49,798 - INFO - Aplicando TF-IDF.
2024-11-26 15:02:50,684 - INFO - Bloco 2 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_2.parquet
2024-11-26 15:02:50,700 - INFO - Salvando dataset processado.
2024-11-26 15:02:51,456 - INFO - Número de linhas com NaN em 'sentimento_codificado' antes da exclusão: 0
2024-11-26 15:02:51,475 - INFO - Número de linhas restantes após a remoção de NaNs: 5966
2024-11-26 15:02:51,475 - INFO - Contando sentimentos positivos, neutros e negativos.
2024-11-26 15:02:51,477 - INFO - Sentimentos positivos: 978
2024-11-26 15:02:51,479 - INFO - Sentimentos neutros: 2242
2024-11-26 15:02:51,479 - INFO - Sentimentos negativos: 2746
2024-11-26 15:02:51,488 - INFO - Amostra salva com sucesso.
2024-11-26 15:02:58,036 - INFO - Dataset salvo com sucesso.
2024-11-26 15:02:58,165 - INFO - Todos os blocos processados e combinados com sucesso.
2024-11-26 15:02:58,182 - INFO - Gerando relatórios.
2024-11-26 15:02:58,231 - INFO - Relatórios gerados com sucesso.
2024-11-26 15:05:32,229 - INFO - Carregando o dataset bruto.
2024-11-26 15:05:32,281 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-26 15:05:32,283 - INFO - Renomeando colunas.
2024-11-26 15:05:32,329 - INFO - Total de linhas a serem processadas: 6000
2024-11-26 15:05:32,330 - INFO - Total de blocos a serem processados: 2
2024-11-26 15:05:32,363 - INFO - Processando bloco 1 de 2
2024-11-26 15:05:32,364 - INFO - Pré-processando os dados.
2024-11-26 15:05:33,072 - INFO - Normalizando os textos.
2024-11-26 15:05:56,648 - INFO - Tokenizando os textos.
2024-11-26 15:06:49,962 - INFO - Criando bigramas.
2024-11-26 15:06:50,663 - INFO - Removendo stopwords.
2024-11-26 15:06:50,705 - INFO - Aplicando stemming.
2024-11-26 15:06:51,326 - INFO - Aplicando lematização.
2024-11-26 15:07:37,013 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 15:07:37,022 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 15:15:03,152 - INFO - Codificando sentimentos.
2024-11-26 15:15:03,319 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 15:15:03,325 - INFO - Aplicando TF-IDF.
2024-11-26 15:15:09,018 - INFO - Bloco 1 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_1.parquet
2024-11-26 15:15:09,050 - INFO - Processando bloco 2 de 2
2024-11-26 15:15:09,051 - INFO - Pré-processando os dados.
2024-11-26 15:15:09,132 - INFO - Normalizando os textos.
2024-11-26 15:15:12,119 - INFO - Tokenizando os textos.
2024-11-26 15:15:19,373 - INFO - Criando bigramas.
2024-11-26 15:15:19,605 - INFO - Removendo stopwords.
2024-11-26 15:15:19,644 - INFO - Aplicando stemming.
2024-11-26 15:15:19,798 - INFO - Aplicando lematização.
2024-11-26 15:15:25,526 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 15:15:25,528 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 15:16:32,258 - INFO - Codificando sentimentos.
2024-11-26 15:16:32,305 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 15:16:32,310 - INFO - Aplicando TF-IDF.
2024-11-26 15:16:32,984 - INFO - Bloco 2 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_2.parquet
2024-11-26 15:16:32,998 - INFO - Salvando dataset processado.
2024-11-26 15:16:33,603 - INFO - Número de linhas com NaN em 'sentimento_codificado' antes da exclusão: 0
2024-11-26 15:16:33,632 - INFO - Número de linhas restantes após a remoção de NaNs: 5966
2024-11-26 15:16:33,632 - INFO - Contando sentimentos positivos, neutros e negativos.
2024-11-26 15:16:33,635 - INFO - Sentimentos positivos: 978
2024-11-26 15:16:33,636 - INFO - Sentimentos neutros: 2242
2024-11-26 15:16:33,637 - INFO - Sentimentos negativos: 2746
2024-11-26 15:16:33,654 - INFO - Amostra salva com sucesso.
2024-11-26 15:16:39,556 - INFO - Dataset salvo com sucesso.
2024-11-26 15:16:39,597 - INFO - Todos os blocos processados e combinados com sucesso.
2024-11-26 15:16:39,599 - INFO - Gerando relatórios.
2024-11-26 15:16:39,629 - INFO - Relatórios gerados com sucesso.
2024-11-26 15:19:52,592 - INFO - Carregando o dataset bruto.
2024-11-26 15:19:52,646 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-26 15:19:52,647 - INFO - Renomeando colunas.
2024-11-26 15:19:52,674 - INFO - Total de linhas a serem processadas: 6000
2024-11-26 15:19:52,674 - INFO - Total de blocos a serem processados: 2
2024-11-26 15:19:52,697 - INFO - Processando bloco 1 de 2
2024-11-26 15:19:52,697 - INFO - Pré-processando os dados.
2024-11-26 15:19:53,258 - INFO - Normalizando os textos.
2024-11-26 15:20:11,830 - INFO - Tokenizando os textos.
2024-11-26 15:21:08,904 - INFO - Criando bigramas.
2024-11-26 15:21:10,002 - INFO - Removendo stopwords.
2024-11-26 15:21:10,051 - INFO - Aplicando stemming.
2024-11-26 15:21:10,837 - INFO - Aplicando lematização.
2024-11-26 15:22:14,078 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 15:22:14,094 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 15:32:21,013 - INFO - Codificando sentimentos.
2024-11-26 15:32:21,273 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 15:32:21,281 - INFO - Aplicando TF-IDF.
2024-11-26 15:32:34,076 - INFO - Bloco 1 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_1.parquet
2024-11-26 15:32:34,162 - INFO - Processando bloco 2 de 2
2024-11-26 15:32:34,162 - INFO - Pré-processando os dados.
2024-11-26 15:32:34,327 - INFO - Normalizando os textos.
2024-11-26 15:32:39,859 - INFO - Tokenizando os textos.
2024-11-26 15:32:53,343 - INFO - Criando bigramas.
2024-11-26 15:32:53,507 - INFO - Removendo stopwords.
2024-11-26 15:32:53,514 - INFO - Aplicando stemming.
2024-11-26 15:32:53,648 - INFO - Aplicando lematização.
2024-11-26 15:33:04,981 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 15:33:04,990 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 15:34:48,110 - INFO - Codificando sentimentos.
2024-11-26 15:34:48,177 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 15:34:48,181 - INFO - Aplicando TF-IDF.
2024-11-26 15:34:49,291 - INFO - Bloco 2 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_2.parquet
2024-11-26 15:34:49,306 - INFO - Salvando dataset processado.
2024-11-26 15:34:50,279 - INFO - Número de linhas com NaN em 'sentimento_codificado' antes da exclusão: 0
2024-11-26 15:34:50,302 - INFO - Número de linhas restantes após a remoção de NaNs: 5966
2024-11-26 15:34:50,303 - INFO - Contando sentimentos positivos, neutros e negativos.
2024-11-26 15:34:50,306 - INFO - Sentimentos positivos: 978
2024-11-26 15:34:50,308 - INFO - Sentimentos neutros: 2242
2024-11-26 15:34:50,309 - INFO - Sentimentos negativos: 2746
2024-11-26 15:34:50,323 - INFO - Amostra salva com sucesso.
2024-11-26 15:34:58,924 - INFO - Dataset salvo com sucesso.
2024-11-26 15:34:58,992 - INFO - Todos os blocos processados e combinados com sucesso.
2024-11-26 15:34:58,997 - INFO - Gerando relatórios.
2024-11-26 15:34:59,043 - INFO - Relatórios gerados com sucesso.
2024-11-26 15:37:30,048 - INFO - Carregando o dataset bruto.
2024-11-26 15:37:30,088 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-26 15:37:30,088 - INFO - Renomeando colunas.
2024-11-26 15:37:30,115 - INFO - Total de linhas a serem processadas: 6000
2024-11-26 15:37:30,116 - INFO - Total de blocos a serem processados: 2
2024-11-26 15:37:30,141 - INFO - Processando bloco 1 de 2
2024-11-26 15:37:30,141 - INFO - Pré-processando os dados.
2024-11-26 15:37:30,724 - INFO - Normalizando os textos.
2024-11-26 15:37:49,819 - INFO - Tokenizando os textos.
2024-11-26 15:38:29,278 - INFO - Criando bigramas.
2024-11-26 15:38:29,831 - INFO - Removendo stopwords.
2024-11-26 15:38:29,853 - INFO - Aplicando stemming.
2024-11-26 15:38:30,540 - INFO - Aplicando lematização.
2024-11-26 15:39:25,887 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 15:39:25,902 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 15:49:53,381 - INFO - Codificando sentimentos.
2024-11-26 15:49:53,677 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 15:49:53,701 - INFO - Aplicando TF-IDF.
2024-11-26 15:50:09,474 - INFO - Bloco 1 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_1.parquet
2024-11-26 15:50:09,549 - INFO - Processando bloco 2 de 2
2024-11-26 15:50:09,550 - INFO - Pré-processando os dados.
2024-11-26 15:50:09,704 - INFO - Normalizando os textos.
2024-11-26 15:50:15,960 - INFO - Tokenizando os textos.
2024-11-26 15:50:30,188 - INFO - Criando bigramas.
2024-11-26 15:50:30,383 - INFO - Removendo stopwords.
2024-11-26 15:50:30,391 - INFO - Aplicando stemming.
2024-11-26 15:50:30,543 - INFO - Aplicando lematização.
2024-11-26 15:50:42,836 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 15:50:42,868 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 15:52:32,639 - INFO - Codificando sentimentos.
2024-11-26 15:52:32,690 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 15:52:32,693 - INFO - Aplicando TF-IDF.
2024-11-26 15:52:33,356 - INFO - Bloco 2 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_2.parquet
2024-11-26 15:52:33,371 - INFO - Salvando dataset processado.
2024-11-26 15:52:33,951 - INFO - Número de linhas com NaN em 'sentimento_codificado' antes da exclusão: 0
2024-11-26 15:52:33,968 - INFO - Número de linhas restantes após a remoção de NaNs: 5966
2024-11-26 15:52:33,969 - INFO - Contando sentimentos positivos, neutros e negativos.
2024-11-26 15:52:33,971 - INFO - Sentimentos positivos: 978
2024-11-26 15:52:33,972 - INFO - Sentimentos neutros: 2242
2024-11-26 15:52:33,972 - INFO - Sentimentos negativos: 2746
2024-11-26 15:52:33,984 - INFO - Amostra salva com sucesso.
2024-11-26 15:52:39,083 - INFO - Dataset salvo com sucesso.
2024-11-26 15:52:39,120 - INFO - Todos os blocos processados e combinados com sucesso.
2024-11-26 15:52:39,124 - INFO - Gerando relatórios.
2024-11-26 15:52:39,165 - INFO - Relatórios gerados com sucesso.
2024-11-26 16:27:41,010 - INFO - Carregando o dataset bruto.
2024-11-26 16:27:41,060 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-26 16:27:41,060 - INFO - Renomeando colunas.
2024-11-26 16:27:41,090 - INFO - Total de linhas a serem processadas: 6000
2024-11-26 16:27:41,090 - INFO - Total de blocos a serem processados: 2
2024-11-26 16:27:41,113 - INFO - Processando bloco 1 de 2
2024-11-26 16:27:41,113 - INFO - Pré-processando os dados.
2024-11-26 16:27:41,651 - INFO - Normalizando os textos.
2024-11-26 16:28:00,499 - INFO - Tokenizando os textos.
2024-11-26 16:28:38,488 - INFO - Criando bigramas.
2024-11-26 16:28:39,151 - INFO - Removendo stopwords.
2024-11-26 16:28:39,176 - INFO - Aplicando stemming.
2024-11-26 16:28:39,700 - INFO - Aplicando lematização.
2024-11-26 16:29:10,809 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 16:29:10,818 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 16:35:29,452 - INFO - Codificando sentimentos.
2024-11-26 16:35:29,628 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 16:35:29,633 - INFO - Aplicando TF-IDF.
2024-11-26 16:35:29,635 - ERROR - Erro ao aplicar TF-IDF: name 'TfidfVectorizer' is not defined
2024-11-26 16:35:29,635 - ERROR - Erro ao processar os dados em blocos: name 'TfidfVectorizer' is not defined
2024-11-26 16:35:29,636 - ERROR - Erro durante a execução do pipeline de produção: name 'TfidfVectorizer' is not defined
2024-11-26 16:38:48,106 - INFO - Carregando o dataset bruto.
2024-11-26 16:38:48,138 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-26 16:38:48,138 - INFO - Renomeando colunas.
2024-11-26 16:38:48,156 - INFO - Total de linhas a serem processadas: 6000
2024-11-26 16:38:48,157 - INFO - Total de blocos a serem processados: 2
2024-11-26 16:38:48,177 - INFO - Processando bloco 1 de 2
2024-11-26 16:38:48,178 - INFO - Pré-processando os dados.
2024-11-26 16:38:48,647 - INFO - Normalizando os textos.
2024-11-26 16:39:06,654 - INFO - Tokenizando os textos.
2024-11-26 16:39:46,105 - INFO - Criando bigramas.
2024-11-26 16:39:46,732 - INFO - Removendo stopwords.
2024-11-26 16:39:46,762 - INFO - Aplicando stemming.
2024-11-26 16:39:47,290 - INFO - Aplicando lematização.
2024-11-26 16:40:19,043 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 16:40:19,052 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 16:45:37,522 - INFO - Carregando o dataset bruto.
2024-11-26 16:45:37,558 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-26 16:45:37,559 - INFO - Renomeando colunas.
2024-11-26 16:45:37,586 - INFO - Total de linhas a serem processadas: 6000
2024-11-26 16:45:37,587 - INFO - Total de blocos a serem processados: 2
2024-11-26 16:45:37,604 - INFO - Processando bloco 1 de 2
2024-11-26 16:45:37,604 - INFO - Pré-processando os dados.
2024-11-26 16:45:38,310 - INFO - Normalizando os textos.
2024-11-26 16:45:57,070 - INFO - Tokenizando os textos.
2024-11-26 16:47:14,837 - INFO - Criando bigramas.
2024-11-26 16:47:15,751 - INFO - Removendo stopwords.
2024-11-26 16:47:15,788 - INFO - Aplicando stemming.
2024-11-26 16:47:16,635 - INFO - Aplicando lematização.
2024-11-26 16:48:17,569 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 16:48:17,577 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 16:58:01,355 - INFO - Codificando sentimentos.
2024-11-26 16:58:01,631 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 16:58:01,641 - INFO - Aplicando TF-IDF.
2024-11-26 16:58:01,643 - ERROR - Erro ao aplicar TF-IDF: name 'TfidfVectorizer' is not defined
2024-11-26 16:58:01,643 - ERROR - Erro ao processar os dados em blocos: name 'TfidfVectorizer' is not defined
2024-11-26 16:58:01,643 - ERROR - Erro durante a execução do pipeline de produção: name 'TfidfVectorizer' is not defined
2024-11-26 17:01:43,936 - INFO - Carregando o dataset bruto.
2024-11-26 17:01:43,977 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-26 17:01:43,978 - INFO - Renomeando colunas.
2024-11-26 17:01:44,006 - INFO - Total de linhas a serem processadas: 6000
2024-11-26 17:01:44,006 - INFO - Total de blocos a serem processados: 2
2024-11-26 17:01:44,029 - INFO - Processando bloco 1 de 2
2024-11-26 17:01:44,029 - INFO - Pré-processando os dados.
2024-11-26 17:01:44,513 - INFO - Normalizando os textos.
2024-11-26 17:02:00,516 - INFO - Tokenizando os textos.
2024-11-26 17:02:32,221 - INFO - Criando bigramas.
2024-11-26 17:02:32,742 - INFO - Removendo stopwords.
2024-11-26 17:02:32,757 - INFO - Aplicando stemming.
2024-11-26 17:02:33,236 - INFO - Aplicando lematização.
2024-11-26 17:02:59,497 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 17:02:59,502 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 17:07:35,102 - INFO - Codificando sentimentos.
2024-11-26 17:07:35,270 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 17:07:35,275 - INFO - Aplicando TF-IDF.
2024-11-26 17:07:41,085 - INFO - Bloco 1 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_1.parquet
2024-11-26 17:07:41,123 - INFO - Processando bloco 2 de 2
2024-11-26 17:07:41,123 - INFO - Pré-processando os dados.
2024-11-26 17:07:41,243 - INFO - Normalizando os textos.
2024-11-26 17:07:44,328 - INFO - Tokenizando os textos.
2024-11-26 17:07:50,552 - INFO - Criando bigramas.
2024-11-26 17:07:50,666 - INFO - Removendo stopwords.
2024-11-26 17:07:50,676 - INFO - Aplicando stemming.
2024-11-26 17:07:50,764 - INFO - Aplicando lematização.
2024-11-26 17:07:56,061 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 17:07:56,063 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 17:08:51,201 - INFO - Codificando sentimentos.
2024-11-26 17:08:51,238 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 17:08:51,240 - INFO - Aplicando TF-IDF.
2024-11-26 17:08:51,772 - INFO - Bloco 2 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_2.parquet
2024-11-26 17:08:51,783 - INFO - Salvando dataset processado.
2024-11-26 17:08:52,210 - INFO - Número de linhas com NaN em 'sentimento_codificado' antes da exclusão: 0
2024-11-26 17:08:52,218 - INFO - Número de linhas restantes após a remoção de NaNs: 5966
2024-11-26 17:08:52,219 - INFO - Contando sentimentos positivos, neutros e negativos.
2024-11-26 17:08:52,221 - INFO - Sentimentos positivos: 978
2024-11-26 17:08:52,221 - INFO - Sentimentos neutros: 2242
2024-11-26 17:08:52,221 - INFO - Sentimentos negativos: 2746
2024-11-26 17:08:52,228 - INFO - Amostra salva com sucesso.
2024-11-26 17:08:57,211 - INFO - Dataset salvo com sucesso.
2024-11-26 17:08:57,240 - INFO - Todos os blocos processados e combinados com sucesso.
2024-11-26 17:08:57,243 - INFO - Gerando relatórios.
2024-11-26 17:08:57,271 - INFO - Relatórios gerados com sucesso.
2024-11-26 17:08:57,272 - INFO - Gerando gráficos para análise do dataset.
2024-11-26 17:08:57,480 - ERROR - Erro ao gerar gráficos: Could not interpret input 'sentimento'
2024-11-26 17:08:57,480 - ERROR - Erro durante a execução do pipeline de produção: Could not interpret input 'sentimento'
2024-11-26 17:34:57,055 - INFO - Carregando o dataset bruto.
2024-11-26 17:34:57,135 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-26 17:34:57,135 - INFO - Renomeando colunas.
2024-11-26 17:34:57,179 - INFO - Total de linhas a serem processadas: 6000
2024-11-26 17:34:57,180 - INFO - Total de blocos a serem processados: 2
2024-11-26 17:34:57,212 - INFO - Processando bloco 1 de 2
2024-11-26 17:34:57,212 - INFO - Pré-processando os dados.
2024-11-26 17:34:58,030 - INFO - Normalizando os textos.
2024-11-26 17:35:21,788 - INFO - Tokenizando os textos.
2024-11-26 17:36:05,778 - INFO - Criando bigramas.
2024-11-26 17:36:06,504 - INFO - Removendo stopwords.
2024-11-26 17:36:06,528 - INFO - Aplicando stemming.
2024-11-26 17:36:07,431 - INFO - Aplicando lematização.
2024-11-26 17:36:53,581 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 17:36:53,593 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 17:44:17,937 - INFO - Codificando sentimentos.
2024-11-26 17:44:18,137 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 17:44:18,144 - INFO - Aplicando TF-IDF.
2024-11-26 17:44:25,244 - INFO - Bloco 1 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_1.parquet
2024-11-26 17:44:25,291 - INFO - Processando bloco 2 de 2
2024-11-26 17:44:25,292 - INFO - Pré-processando os dados.
2024-11-26 17:44:25,469 - INFO - Normalizando os textos.
2024-11-26 17:44:28,800 - INFO - Tokenizando os textos.
2024-11-26 17:44:35,798 - INFO - Criando bigramas.
2024-11-26 17:44:35,905 - INFO - Removendo stopwords.
2024-11-26 17:44:35,910 - INFO - Aplicando stemming.
2024-11-26 17:44:36,035 - INFO - Aplicando lematização.
2024-11-26 17:44:41,752 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 17:44:41,757 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 17:45:42,021 - INFO - Codificando sentimentos.
2024-11-26 17:45:42,057 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 17:45:42,061 - INFO - Aplicando TF-IDF.
2024-11-26 17:45:42,608 - INFO - Bloco 2 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_2.parquet
2024-11-26 17:45:42,617 - INFO - Salvando dataset processado.
2024-11-26 17:45:43,079 - INFO - Número de linhas com NaN em 'sentimento_codificado' antes da exclusão: 0
2024-11-26 17:45:43,084 - INFO - Número de linhas restantes após a remoção de NaNs: 5966
2024-11-26 17:45:43,085 - INFO - Contando sentimentos positivos, neutros e negativos.
2024-11-26 17:45:43,087 - INFO - Sentimentos positivos: 978
2024-11-26 17:45:43,088 - INFO - Sentimentos neutros: 2242
2024-11-26 17:45:43,088 - INFO - Sentimentos negativos: 2746
2024-11-26 17:45:43,097 - INFO - Amostra salva com sucesso.
2024-11-26 17:45:48,438 - INFO - Dataset salvo com sucesso.
2024-11-26 17:45:48,485 - INFO - Todos os blocos processados e combinados com sucesso.
2024-11-26 17:45:48,491 - INFO - Gerando relatórios.
2024-11-26 17:45:48,518 - INFO - Relatórios gerados com sucesso.
2024-11-26 17:45:48,519 - INFO - Gerando gráficos para análise do dataset.
2024-11-26 17:45:48,683 - ERROR - Erro ao gerar gráficos: Could not interpret input 'sentimento'
2024-11-26 17:45:48,684 - ERROR - Erro durante a execução do pipeline de produção: Could not interpret input 'sentimento'
2024-11-26 17:54:49,261 - INFO - Carregando o dataset bruto.
2024-11-26 17:54:49,300 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-26 17:54:49,300 - INFO - Renomeando colunas.
2024-11-26 17:54:49,323 - INFO - Total de linhas a serem processadas: 6000
2024-11-26 17:54:49,324 - INFO - Total de blocos a serem processados: 2
2024-11-26 17:54:49,349 - INFO - Processando bloco 1 de 2
2024-11-26 17:54:49,350 - INFO - Pré-processando os dados.
2024-11-26 17:54:49,906 - INFO - Normalizando os textos.
2024-11-26 17:55:13,433 - INFO - Tokenizando os textos.
2024-11-26 17:56:07,778 - INFO - Criando bigramas.
2024-11-26 17:56:08,452 - INFO - Removendo stopwords.
2024-11-26 17:56:08,479 - INFO - Aplicando stemming.
2024-11-26 17:56:09,061 - INFO - Aplicando lematização.
2024-11-26 17:56:55,276 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 17:56:55,285 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 18:04:41,659 - INFO - Codificando sentimentos.
2024-11-26 18:04:41,865 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 18:04:41,879 - INFO - Aplicando TF-IDF.
2024-11-26 18:04:52,369 - INFO - Bloco 1 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_1.parquet
2024-11-26 18:04:52,425 - INFO - Processando bloco 2 de 2
2024-11-26 18:04:52,427 - INFO - Pré-processando os dados.
2024-11-26 18:04:52,547 - INFO - Normalizando os textos.
2024-11-26 18:04:56,983 - INFO - Tokenizando os textos.
2024-11-26 18:05:08,002 - INFO - Criando bigramas.
2024-11-26 18:05:08,145 - INFO - Removendo stopwords.
2024-11-26 18:05:08,155 - INFO - Aplicando stemming.
2024-11-26 18:05:08,270 - INFO - Aplicando lematização.
2024-11-26 18:05:17,401 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 18:05:17,405 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 18:06:59,283 - INFO - Codificando sentimentos.
2024-11-26 18:06:59,342 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 18:06:59,351 - INFO - Aplicando TF-IDF.
2024-11-26 18:07:00,119 - INFO - Bloco 2 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_2.parquet
2024-11-26 18:07:00,138 - INFO - Salvando dataset processado.
2024-11-26 18:07:00,931 - INFO - Número de linhas com NaN em 'sentimento_codificado' antes da exclusão: 0
2024-11-26 18:07:00,948 - INFO - Número de linhas restantes após a remoção de NaNs: 5966
2024-11-26 18:07:00,948 - INFO - Contando sentimentos positivos, neutros e negativos.
2024-11-26 18:07:00,951 - INFO - Sentimentos positivos: 978
2024-11-26 18:07:00,952 - INFO - Sentimentos neutros: 2242
2024-11-26 18:07:00,952 - INFO - Sentimentos negativos: 2746
2024-11-26 18:07:00,973 - INFO - Amostra salva com sucesso.
2024-11-26 18:07:07,224 - INFO - Dataset salvo com sucesso.
2024-11-26 18:07:07,283 - INFO - Todos os blocos processados e combinados com sucesso.
2024-11-26 18:07:07,291 - INFO - Gerando relatórios.
2024-11-26 18:07:07,332 - INFO - Relatórios gerados com sucesso.
2024-11-26 18:07:07,334 - INFO - Gerando gráficos para análise do dataset.
2024-11-26 18:07:07,537 - ERROR - Erro ao gerar gráficos: Could not interpret input 'sentimento'
2024-11-26 18:07:07,538 - ERROR - Erro durante a execução do pipeline de produção: Could not interpret input 'sentimento'
2024-11-26 18:20:32,819 - INFO - Carregando o dataset bruto.
2024-11-26 18:20:32,863 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-26 18:20:32,864 - INFO - Renomeando colunas.
2024-11-26 18:20:32,902 - INFO - Total de linhas a serem processadas: 6000
2024-11-26 18:20:32,902 - INFO - Total de blocos a serem processados: 2
2024-11-26 18:20:32,926 - INFO - Processando bloco 1 de 2
2024-11-26 18:20:32,926 - INFO - Pré-processando os dados.
2024-11-26 18:20:33,552 - INFO - Normalizando os textos.
2024-11-26 18:21:14,623 - INFO - Tokenizando os textos.
2024-11-26 18:23:00,507 - INFO - Criando bigramas.
2024-11-26 18:23:01,653 - INFO - Removendo stopwords.
2024-11-26 18:23:01,688 - INFO - Aplicando stemming.
2024-11-26 18:23:02,600 - INFO - Aplicando lematização.
2024-11-26 18:24:23,994 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 18:24:24,021 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 18:34:13,493 - INFO - Codificando sentimentos.
2024-11-26 18:34:13,749 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 18:34:13,758 - INFO - Aplicando TF-IDF.
2024-11-26 18:34:27,641 - INFO - Bloco 1 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_1.parquet
2024-11-26 18:34:27,725 - INFO - Processando bloco 2 de 2
2024-11-26 18:34:27,725 - INFO - Pré-processando os dados.
2024-11-26 18:34:27,882 - INFO - Normalizando os textos.
2024-11-26 18:34:33,882 - INFO - Tokenizando os textos.
2024-11-26 18:34:46,331 - INFO - Criando bigramas.
2024-11-26 18:34:46,495 - INFO - Removendo stopwords.
2024-11-26 18:34:46,506 - INFO - Aplicando stemming.
2024-11-26 18:34:46,622 - INFO - Aplicando lematização.
2024-11-26 18:34:56,842 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 18:34:56,848 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 18:36:38,829 - INFO - Codificando sentimentos.
2024-11-26 18:36:38,889 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 18:36:38,896 - INFO - Aplicando TF-IDF.
2024-11-26 18:36:39,697 - INFO - Bloco 2 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_2.parquet
2024-11-26 18:36:39,717 - INFO - Salvando dataset processado.
2024-11-26 18:36:40,438 - INFO - Número de linhas com NaN em 'sentimento_codificado' antes da exclusão: 0
2024-11-26 18:36:40,455 - INFO - Número de linhas restantes após a remoção de NaNs: 5966
2024-11-26 18:36:40,456 - INFO - Contando sentimentos positivos, neutros e negativos.
2024-11-26 18:36:40,459 - INFO - Sentimentos positivos: 978
2024-11-26 18:36:40,460 - INFO - Sentimentos neutros: 2242
2024-11-26 18:36:40,460 - INFO - Sentimentos negativos: 2746
2024-11-26 18:36:40,472 - INFO - Amostra salva com sucesso.
2024-11-26 18:36:47,065 - INFO - Dataset salvo com sucesso.
2024-11-26 18:36:47,129 - INFO - Todos os blocos processados e combinados com sucesso.
2024-11-26 18:36:47,137 - INFO - Gerando relatórios.
2024-11-26 18:36:47,203 - INFO - Relatórios gerados com sucesso.
2024-11-26 18:36:47,205 - INFO - Contando sentimentos positivos, neutros e negativos.
2024-11-26 18:36:47,206 - ERROR - Erro ao contar sentimentos: 'sentimento'
2024-11-26 18:36:47,207 - ERROR - Erro durante a execução do pipeline de produção: 'sentimento'
2024-11-26 18:40:21,899 - INFO - Carregando o dataset bruto.
2024-11-26 18:40:21,937 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-26 18:40:21,937 - INFO - Renomeando colunas.
2024-11-26 18:40:21,963 - INFO - Total de linhas a serem processadas: 6000
2024-11-26 18:40:21,963 - INFO - Total de blocos a serem processados: 2
2024-11-26 18:40:21,988 - INFO - Processando bloco 1 de 2
2024-11-26 18:40:21,988 - INFO - Pré-processando os dados.
2024-11-26 18:40:22,488 - INFO - Normalizando os textos.
2024-11-26 18:40:38,617 - INFO - Tokenizando os textos.
2024-11-26 18:41:46,625 - INFO - Criando bigramas.
2024-11-26 18:41:48,767 - INFO - Removendo stopwords.
2024-11-26 18:41:48,862 - INFO - Aplicando stemming.
2024-11-26 18:41:50,093 - INFO - Aplicando lematização.
2024-11-26 18:42:55,417 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 18:42:55,431 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 18:50:48,537 - INFO - Codificando sentimentos.
2024-11-26 18:50:48,747 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 18:50:48,755 - INFO - Aplicando TF-IDF.
2024-11-26 18:50:58,095 - INFO - Bloco 1 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_1.parquet
2024-11-26 18:50:58,155 - INFO - Processando bloco 2 de 2
2024-11-26 18:50:58,157 - INFO - Pré-processando os dados.
2024-11-26 18:50:58,264 - INFO - Normalizando os textos.
2024-11-26 18:51:02,630 - INFO - Tokenizando os textos.
2024-11-26 18:51:12,740 - INFO - Criando bigramas.
2024-11-26 18:51:12,879 - INFO - Removendo stopwords.
2024-11-26 18:51:12,884 - INFO - Aplicando stemming.
2024-11-26 18:51:12,998 - INFO - Aplicando lematização.
2024-11-26 18:51:21,662 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 18:51:21,666 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 18:52:51,201 - INFO - Codificando sentimentos.
2024-11-26 18:52:51,249 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 18:52:51,254 - INFO - Aplicando TF-IDF.
2024-11-26 18:52:52,070 - INFO - Bloco 2 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_2.parquet
2024-11-26 18:52:52,083 - INFO - Salvando dataset processado.
2024-11-26 18:52:52,763 - INFO - Número de linhas com NaN em 'sentimento_codificado' antes da exclusão: 0
2024-11-26 18:52:52,777 - INFO - Número de linhas restantes após a remoção de NaNs: 5966
2024-11-26 18:52:52,779 - INFO - Contando sentimentos positivos, neutros e negativos.
2024-11-26 18:52:52,784 - INFO - Sentimentos positivos: 978
2024-11-26 18:52:52,784 - INFO - Sentimentos neutros: 2242
2024-11-26 18:52:52,785 - INFO - Sentimentos negativos: 2746
2024-11-26 18:52:52,797 - INFO - Amostra salva com sucesso.
2024-11-26 18:52:58,965 - INFO - Dataset salvo com sucesso.
2024-11-26 18:52:59,013 - INFO - Todos os blocos processados e combinados com sucesso.
2024-11-26 18:52:59,020 - INFO - Gerando gráficos para análise do dataset.
2024-11-26 18:52:59,044 - ERROR - Erro ao gerar gráficos: A coluna 'sentimento' está ausente ou vazia.
2024-11-26 18:52:59,045 - ERROR - Erro durante a execução do pipeline de produção: A coluna 'sentimento' está ausente ou vazia.
2024-11-26 19:01:05,234 - INFO - Carregando o dataset bruto.
2024-11-26 19:01:05,265 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-26 19:01:05,266 - INFO - Renomeando colunas.
2024-11-26 19:01:05,286 - INFO - Total de linhas a serem processadas: 6000
2024-11-26 19:01:05,286 - INFO - Total de blocos a serem processados: 2
2024-11-26 19:01:05,305 - INFO - Processando bloco 1 de 2
2024-11-26 19:01:05,305 - INFO - Pré-processando os dados.
2024-11-26 19:01:05,694 - INFO - Normalizando os textos.
2024-11-26 19:01:21,079 - INFO - Tokenizando os textos.
2024-11-26 19:01:53,677 - INFO - Criando bigramas.
2024-11-26 19:01:54,191 - INFO - Removendo stopwords.
2024-11-26 19:01:54,207 - INFO - Aplicando stemming.
2024-11-26 19:01:54,632 - INFO - Aplicando lematização.
2024-11-26 19:02:21,334 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 19:02:21,342 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 19:07:21,784 - INFO - Codificando sentimentos.
2024-11-26 19:07:21,996 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 19:07:22,007 - INFO - Aplicando TF-IDF.
2024-11-26 19:07:31,739 - INFO - Bloco 1 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_1.parquet
2024-11-26 19:07:31,809 - INFO - Processando bloco 2 de 2
2024-11-26 19:07:31,809 - INFO - Pré-processando os dados.
2024-11-26 19:07:31,921 - INFO - Normalizando os textos.
2024-11-26 19:07:36,397 - INFO - Tokenizando os textos.
2024-11-26 19:07:46,634 - INFO - Criando bigramas.
2024-11-26 19:07:46,783 - INFO - Removendo stopwords.
2024-11-26 19:07:46,794 - INFO - Aplicando stemming.
2024-11-26 19:07:46,916 - INFO - Aplicando lematização.
2024-11-26 19:07:55,673 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 19:07:55,677 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 19:09:29,329 - INFO - Codificando sentimentos.
2024-11-26 19:09:29,380 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 19:09:29,388 - INFO - Aplicando TF-IDF.
2024-11-26 19:09:30,114 - INFO - Bloco 2 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_2.parquet
2024-11-26 19:09:30,127 - INFO - Salvando dataset processado.
2024-11-26 19:09:30,820 - INFO - Número de linhas com NaN em 'sentimento_codificado' antes da exclusão: 0
2024-11-26 19:09:30,833 - INFO - Número de linhas restantes após a remoção de NaNs: 5966
2024-11-26 19:09:30,834 - INFO - Contando sentimentos positivos, neutros e negativos.
2024-11-26 19:09:30,836 - INFO - Sentimentos positivos: 978
2024-11-26 19:09:30,837 - INFO - Sentimentos neutros: 2242
2024-11-26 19:09:30,838 - INFO - Sentimentos negativos: 2746
2024-11-26 19:09:30,846 - INFO - Amostra salva com sucesso.
2024-11-26 19:09:37,094 - INFO - Dataset salvo com sucesso.
2024-11-26 19:09:37,139 - INFO - Todos os blocos processados e combinados com sucesso.
2024-11-26 19:09:37,144 - ERROR - Erro durante a execução do pipeline de produção: A coluna 'sentimento' está ausente ou vazia após o processamento.
2024-11-26 19:12:49,681 - INFO - Carregando o dataset bruto.
2024-11-26 19:12:49,707 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-26 19:12:49,708 - INFO - Renomeando colunas.
2024-11-26 19:12:49,727 - INFO - Total de linhas a serem processadas: 6000
2024-11-26 19:12:49,727 - INFO - Total de blocos a serem processados: 2
2024-11-26 19:12:49,751 - INFO - Processando bloco 1 de 2
2024-11-26 19:12:49,751 - INFO - Pré-processando os dados.
2024-11-26 19:12:50,149 - INFO - Normalizando os textos.
2024-11-26 19:13:07,667 - INFO - Tokenizando os textos.
2024-11-26 19:14:01,837 - INFO - Criando bigramas.
2024-11-26 19:14:02,494 - INFO - Removendo stopwords.
2024-11-26 19:14:02,524 - INFO - Aplicando stemming.
2024-11-26 19:14:03,102 - INFO - Aplicando lematização.
2024-11-26 19:14:47,350 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 19:14:47,367 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 19:20:33,193 - INFO - Sentimentos após classificação no bloco 1: {'negativo': 2293, 'neutro': 1854, 'positivo': 821}
2024-11-26 19:20:33,193 - INFO - Codificando sentimentos.
2024-11-26 19:20:33,372 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 19:20:33,378 - INFO - Aplicando TF-IDF.
2024-11-26 19:20:38,995 - INFO - Bloco 1 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_1.parquet
2024-11-26 19:20:39,032 - INFO - Processando bloco 2 de 2
2024-11-26 19:20:39,033 - INFO - Pré-processando os dados.
2024-11-26 19:20:39,127 - INFO - Normalizando os textos.
2024-11-26 19:20:42,186 - INFO - Tokenizando os textos.
2024-11-26 19:20:48,611 - INFO - Criando bigramas.
2024-11-26 19:20:48,707 - INFO - Removendo stopwords.
2024-11-26 19:20:48,711 - INFO - Aplicando stemming.
2024-11-26 19:20:48,804 - INFO - Aplicando lematização.
2024-11-26 19:20:54,118 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 19:20:54,120 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 19:21:49,024 - INFO - Sentimentos após classificação no bloco 2: {'negativo': 453, 'neutro': 388, 'positivo': 157}
2024-11-26 19:21:49,025 - INFO - Codificando sentimentos.
2024-11-26 19:21:49,060 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 19:21:49,064 - INFO - Aplicando TF-IDF.
2024-11-26 19:21:49,579 - INFO - Bloco 2 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_2.parquet
2024-11-26 19:21:49,591 - ERROR - Erro ao processar os dados em blocos: Trying to convert dd.Scalar<series-..., dtype=bool> to a boolean value. Because Dask objects are lazily evaluated, they cannot be converted to a boolean value or used in boolean conditions like if statements. Try calling .compute() to force computation prior to converting to a boolean value or using in a conditional statement.
2024-11-26 19:21:49,592 - ERROR - Erro durante a execução do pipeline de produção: Trying to convert dd.Scalar<series-..., dtype=bool> to a boolean value. Because Dask objects are lazily evaluated, they cannot be converted to a boolean value or used in boolean conditions like if statements. Try calling .compute() to force computation prior to converting to a boolean value or using in a conditional statement.
2024-11-26 19:28:37,525 - INFO - Carregando o dataset bruto.
2024-11-26 19:28:37,579 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-26 19:28:37,580 - INFO - Renomeando colunas.
2024-11-26 19:28:37,607 - INFO - Total de linhas a serem processadas: 6000
2024-11-26 19:28:37,607 - INFO - Total de blocos a serem processados: 2
2024-11-26 19:28:37,637 - INFO - Processando bloco 1 de 2
2024-11-26 19:28:37,638 - INFO - Pré-processando os dados.
2024-11-26 19:28:38,219 - INFO - Normalizando os textos.
2024-11-26 19:29:02,097 - INFO - Tokenizando os textos.
2024-11-26 19:29:54,194 - INFO - Criando bigramas.
2024-11-26 19:29:54,912 - INFO - Removendo stopwords.
2024-11-26 19:29:54,933 - INFO - Aplicando stemming.
2024-11-26 19:29:55,503 - INFO - Aplicando lematização.
2024-11-26 19:30:39,064 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 19:30:39,071 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 19:37:14,486 - INFO - Carregando o dataset bruto.
2024-11-26 19:37:14,514 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-26 19:37:14,514 - INFO - Renomeando colunas.
2024-11-26 19:37:14,535 - INFO - Total de linhas a serem processadas: 6000
2024-11-26 19:37:14,536 - INFO - Total de blocos a serem processados: 2
2024-11-26 19:37:14,556 - INFO - Processando bloco 1 de 2
2024-11-26 19:37:14,558 - INFO - Pré-processando os dados.
2024-11-26 19:37:14,965 - INFO - Normalizando os textos.
2024-11-26 19:37:31,853 - INFO - Tokenizando os textos.
2024-11-26 19:38:05,320 - INFO - Criando bigramas.
2024-11-26 19:38:05,863 - INFO - Removendo stopwords.
2024-11-26 19:38:05,879 - INFO - Aplicando stemming.
2024-11-26 19:38:06,352 - INFO - Aplicando lematização.
2024-11-26 19:38:33,655 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 19:38:33,660 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 19:43:24,281 - INFO - Codificando sentimentos.
2024-11-26 19:43:24,457 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 19:43:24,466 - INFO - Aplicando TF-IDF.
2024-11-26 19:43:32,235 - INFO - Bloco 1 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_1.parquet
2024-11-26 19:43:32,268 - INFO - Processando bloco 2 de 2
2024-11-26 19:43:32,268 - INFO - Pré-processando os dados.
2024-11-26 19:43:32,359 - INFO - Normalizando os textos.
2024-11-26 19:43:35,491 - INFO - Tokenizando os textos.
2024-11-26 19:43:42,083 - INFO - Criando bigramas.
2024-11-26 19:43:42,196 - INFO - Removendo stopwords.
2024-11-26 19:43:42,200 - INFO - Aplicando stemming.
2024-11-26 19:43:42,288 - INFO - Aplicando lematização.
2024-11-26 19:43:47,652 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 19:43:47,654 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 19:44:53,698 - INFO - Codificando sentimentos.
2024-11-26 19:44:53,738 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 19:44:53,741 - INFO - Aplicando TF-IDF.
2024-11-26 19:44:54,274 - INFO - Bloco 2 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_2.parquet
2024-11-26 19:44:54,284 - INFO - Salvando dataset processado.
2024-11-26 19:44:54,815 - INFO - Número de linhas com NaN em 'sentimento_codificado' antes da exclusão: 0
2024-11-26 19:44:54,823 - INFO - Número de linhas restantes após a remoção de NaNs: 5966
2024-11-26 19:44:54,825 - INFO - Contando sentimentos positivos, neutros e negativos.
2024-11-26 19:44:54,828 - INFO - Sentimentos positivos: 978
2024-11-26 19:44:54,829 - INFO - Sentimentos neutros: 2242
2024-11-26 19:44:54,829 - INFO - Sentimentos negativos: 2746
2024-11-26 19:44:54,835 - INFO - Amostra salva com sucesso.
2024-11-26 19:44:59,612 - INFO - Dataset salvo com sucesso.
2024-11-26 19:44:59,642 - INFO - Todos os blocos processados e combinados com sucesso.
2024-11-26 19:44:59,645 - INFO - Carregando o dataset processado salvo.
2024-11-26 19:45:00,328 - INFO - Dataset processado carregado com sucesso.
2024-11-26 19:45:00,329 - INFO - Gerando gráficos para análise do dataset.
2024-11-26 19:45:18,546 - ERROR - Erro ao gerar gráficos: Input contains NaN, infinity or a value too large for dtype('float64').
2024-11-26 19:45:18,547 - ERROR - Erro durante a execução do pipeline de produção: Input contains NaN, infinity or a value too large for dtype('float64').
2024-11-26 20:15:09,940 - INFO - Carregando o dataset bruto.
2024-11-26 20:15:10,008 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-26 20:15:10,008 - INFO - Renomeando colunas.
2024-11-26 20:15:10,010 - INFO - Etapa 1 concluída com sucesso.
2024-11-26 20:15:10,033 - INFO - Pré-processando os dados.
2024-11-26 20:15:10,053 - INFO - Etapa 2 concluída com sucesso.
2024-11-26 20:15:10,054 - INFO - Normalizando os textos.
2024-11-26 20:15:10,059 - INFO - Etapa 3 concluída com sucesso.
2024-11-26 20:15:14,756 - INFO - Tokenizando os textos.
2024-11-26 20:15:15,694 - INFO - Criando bigramas.
2024-11-26 20:15:15,707 - INFO - Etapa 4 concluída com sucesso.
2024-11-26 20:15:15,707 - INFO - Removendo stopwords.
2024-11-26 20:15:15,717 - INFO - Etapa 5 concluída com sucesso.
2024-11-26 20:15:15,717 - INFO - Aplicando stemming.
2024-11-26 20:15:15,725 - INFO - Aplicando lematização.
2024-11-26 20:15:16,686 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 20:15:16,689 - INFO - Etapa 6 concluída com sucesso.
2024-11-26 20:15:22,820 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 20:15:36,601 - INFO - Etapa 7 concluída com sucesso.
2024-11-26 20:32:50,879 - INFO - Carregando o dataset bruto.
2024-11-26 20:32:50,936 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-26 20:32:50,937 - INFO - Renomeando colunas.
2024-11-26 20:32:50,938 - INFO - Etapa 1 concluída com sucesso.
2024-11-26 20:32:50,955 - INFO - Pré-processando os dados.
2024-11-26 20:32:50,970 - INFO - Etapa 2 concluída com sucesso.
2024-11-26 20:32:50,971 - INFO - Normalizando os textos.
2024-11-26 20:32:50,975 - INFO - Etapa 3 concluída com sucesso.
2024-11-26 20:32:54,934 - INFO - Tokenizando os textos.
2024-11-26 20:32:55,897 - INFO - Criando bigramas.
2024-11-26 20:32:55,913 - INFO - Etapa 4 concluída com sucesso.
2024-11-26 20:32:55,914 - INFO - Removendo stopwords.
2024-11-26 20:32:55,925 - INFO - Etapa 5 concluída com sucesso.
2024-11-26 20:32:55,926 - INFO - Aplicando stemming.
2024-11-26 20:32:55,933 - INFO - Aplicando lematização.
2024-11-26 20:32:56,812 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 20:32:56,816 - INFO - Etapa 6 concluída com sucesso.
2024-11-26 20:33:02,301 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 20:33:15,403 - INFO - Etapa 7 concluída com sucesso.
2024-11-26 20:33:15,404 - INFO - Codificando sentimentos.
2024-11-26 20:33:15,418 - INFO - Etapa 8 concluída com sucesso.
2024-11-26 20:33:15,419 - INFO - Aplicando TF-IDF.
2024-11-26 20:33:15,420 - ERROR - Erro ao aplicar TF-IDF: 'Series' object has no attribute 'tolist'
2024-11-26 20:33:15,420 - ERROR - Erro durante a execução da Etapa 9: 'Series' object has no attribute 'tolist'
2024-11-26 20:38:51,777 - INFO - Carregando o dataset bruto.
2024-11-26 20:38:51,809 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-26 20:38:51,810 - INFO - Renomeando colunas.
2024-11-26 20:38:51,835 - INFO - Total de linhas a serem processadas: 6000
2024-11-26 20:38:51,836 - INFO - Total de blocos a serem processados: 2
2024-11-26 20:38:51,855 - INFO - Processando bloco 1 de 2
2024-11-26 20:38:51,855 - INFO - Pré-processando os dados.
2024-11-26 20:38:52,236 - INFO - Normalizando os textos.
2024-11-26 20:39:08,124 - INFO - Tokenizando os textos.
2024-11-26 20:39:39,063 - INFO - Criando bigramas.
2024-11-26 20:39:39,566 - INFO - Removendo stopwords.
2024-11-26 20:39:39,588 - INFO - Aplicando stemming.
2024-11-26 20:39:40,015 - INFO - Aplicando lematização.
2024-11-26 20:40:05,191 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 20:40:05,191 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 20:45:12,159 - INFO - Codificando sentimentos.
2024-11-26 20:45:12,348 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 20:45:12,348 - INFO - Aplicando TF-IDF.
2024-11-26 20:45:18,566 - INFO - Bloco 1 salvo em temp_data\bloco_1.parquet
2024-11-26 20:45:18,605 - INFO - Processando bloco 2 de 2
2024-11-26 20:45:18,605 - INFO - Pré-processando os dados.
2024-11-26 20:45:18,691 - INFO - Normalizando os textos.
2024-11-26 20:45:21,850 - INFO - Tokenizando os textos.
2024-11-26 20:45:28,497 - INFO - Criando bigramas.
2024-11-26 20:45:28,599 - INFO - Removendo stopwords.
2024-11-26 20:45:28,618 - INFO - Aplicando stemming.
2024-11-26 20:45:28,727 - INFO - Aplicando lematização.
2024-11-26 20:45:33,984 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 20:45:33,986 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 20:46:27,622 - INFO - Codificando sentimentos.
2024-11-26 20:46:27,661 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 20:46:27,663 - INFO - Aplicando TF-IDF.
2024-11-26 20:46:28,193 - INFO - Bloco 2 salvo em temp_data\bloco_2.parquet
2024-11-26 20:46:28,215 - INFO - Salvando dataset processado.
2024-11-26 20:46:28,664 - INFO - Número de linhas com NaN em 'sentimento_codificado' antes da exclusão: 0
2024-11-26 20:46:28,672 - INFO - Número de linhas restantes após a remoção de NaNs: 5966
2024-11-26 20:46:33,229 - INFO - Dataset salvo com sucesso.
2024-11-26 20:46:33,270 - INFO - Todos os blocos processados e combinados com sucesso.
2024-11-26 20:46:33,273 - INFO - Gerando relatórios.
2024-11-26 20:46:33,279 - INFO - Relatórios gerados com sucesso.
2024-11-26 20:53:51,067 - INFO - Carregando o dataset bruto.
2024-11-26 20:53:51,130 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-26 20:53:51,130 - INFO - Renomeando colunas.
2024-11-26 20:53:51,176 - INFO - Total de linhas a serem processadas: 6000
2024-11-26 20:53:51,176 - INFO - Total de blocos a serem processados: 2
2024-11-26 20:53:51,212 - INFO - Processando bloco 1 de 2
2024-11-26 20:53:51,212 - INFO - Pré-processando os dados.
2024-11-26 20:53:51,926 - INFO - Normalizando os textos.
2024-11-26 20:54:18,735 - INFO - Tokenizando os textos.
2024-11-26 20:55:22,357 - INFO - Criando bigramas.
2024-11-26 20:55:23,253 - INFO - Removendo stopwords.
2024-11-26 20:55:23,280 - INFO - Aplicando stemming.
2024-11-26 20:55:23,982 - INFO - Aplicando lematização.
2024-11-26 20:56:17,145 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 20:56:17,161 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 21:05:51,004 - INFO - Codificando sentimentos.
2024-11-26 21:05:51,207 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 21:05:51,219 - INFO - Aplicando TF-IDF.
2024-11-26 21:06:04,567 - INFO - Bloco 1 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_1.parquet
2024-11-26 21:06:04,622 - INFO - Processando bloco 2 de 2
2024-11-26 21:06:04,625 - INFO - Pré-processando os dados.
2024-11-26 21:06:04,773 - INFO - Normalizando os textos.
2024-11-26 21:06:10,322 - INFO - Tokenizando os textos.
2024-11-26 21:06:22,676 - INFO - Criando bigramas.
2024-11-26 21:06:22,863 - INFO - Removendo stopwords.
2024-11-26 21:06:22,869 - INFO - Aplicando stemming.
2024-11-26 21:06:23,025 - INFO - Aplicando lematização.
2024-11-26 21:06:33,935 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 21:06:33,940 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 21:08:14,139 - INFO - Codificando sentimentos.
2024-11-26 21:08:14,202 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 21:08:14,210 - INFO - Aplicando TF-IDF.
2024-11-26 21:08:15,136 - INFO - Bloco 2 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_2.parquet
2024-11-26 21:08:15,152 - INFO - Salvando dataset processado.
2024-11-26 21:08:15,860 - INFO - Número de linhas com NaN em 'sentimento_codificado' antes da exclusão: 0
2024-11-26 21:08:15,871 - INFO - Número de linhas restantes após a remoção de NaNs: 5966
2024-11-26 21:08:15,872 - INFO - Contando sentimentos positivos, neutros e negativos.
2024-11-26 21:08:15,876 - INFO - Sentimentos positivos: 978
2024-11-26 21:08:15,878 - INFO - Sentimentos neutros: 2242
2024-11-26 21:08:15,879 - INFO - Sentimentos negativos: 2746
2024-11-26 21:08:15,891 - INFO - Amostra salva com sucesso.
2024-11-26 21:08:23,229 - INFO - Dataset salvo com sucesso.
2024-11-26 21:08:23,293 - INFO - Todos os blocos processados e combinados com sucesso.
2024-11-26 21:08:23,298 - INFO - Gerando relatórios.
2024-11-26 21:08:23,334 - INFO - Relatórios gerados com sucesso.
2024-11-26 22:07:28,928 - INFO - Carregando o dataset bruto.
2024-11-26 22:07:28,949 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-26 22:07:28,949 - INFO - Renomeando colunas.
2024-11-26 22:07:28,976 - INFO - Total de linhas a serem processadas: 6000
2024-11-26 22:07:28,976 - INFO - Total de blocos a serem processados: 2
2024-11-26 22:07:28,994 - INFO - Processando bloco 1 de 2
2024-11-26 22:07:28,994 - INFO - Pré-processando os dados.
2024-11-26 22:07:29,376 - INFO - Normalizando os textos.
2024-11-26 22:07:44,168 - INFO - Tokenizando os textos.
2024-11-26 22:08:13,428 - INFO - Criando bigramas.
2024-11-26 22:08:13,960 - INFO - Removendo stopwords.
2024-11-26 22:08:13,986 - INFO - Aplicando stemming.
2024-11-26 22:08:14,437 - INFO - Aplicando lematização.
2024-11-26 22:08:38,610 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 22:08:38,610 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 22:13:46,501 - INFO - Codificando sentimentos.
2024-11-26 22:13:46,671 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 22:13:46,671 - INFO - Aplicando TF-IDF.
2024-11-26 22:13:52,204 - INFO - Bloco 1 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_1.parquet
2024-11-26 22:13:52,241 - INFO - Processando bloco 2 de 2
2024-11-26 22:13:52,241 - INFO - Pré-processando os dados.
2024-11-26 22:13:52,348 - INFO - Normalizando os textos.
2024-11-26 22:13:55,404 - INFO - Tokenizando os textos.
2024-11-26 22:14:01,489 - INFO - Criando bigramas.
2024-11-26 22:14:01,606 - INFO - Removendo stopwords.
2024-11-26 22:14:01,606 - INFO - Aplicando stemming.
2024-11-26 22:14:01,686 - INFO - Aplicando lematização.
2024-11-26 22:14:06,719 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 22:14:06,719 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 22:14:58,935 - INFO - Codificando sentimentos.
2024-11-26 22:14:58,981 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 22:14:58,984 - INFO - Aplicando TF-IDF.
2024-11-26 22:14:59,456 - INFO - Bloco 2 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_2.parquet
2024-11-26 22:14:59,456 - INFO - Salvando dataset processado.
2024-11-26 22:14:59,859 - INFO - Número de linhas com NaN em 'sentimento_codificado' antes da exclusão: 0
2024-11-26 22:14:59,875 - INFO - Número de linhas restantes após a remoção de NaNs: 5966
2024-11-26 22:14:59,876 - INFO - Contando sentimentos positivos, neutros e negativos.
2024-11-26 22:14:59,877 - INFO - Sentimentos positivos: 978
2024-11-26 22:14:59,878 - INFO - Sentimentos neutros: 2242
2024-11-26 22:14:59,878 - INFO - Sentimentos negativos: 2746
2024-11-26 22:14:59,879 - ERROR - Erro ao salvar os dados: "['sentimnto_bert'] not in index"
2024-11-26 22:14:59,880 - ERROR - Erro ao processar os dados em blocos: "['sentimnto_bert'] not in index"
2024-11-26 22:14:59,880 - ERROR - Erro durante a execução do pipeline de produção: "['sentimnto_bert'] not in index"
2024-11-26 22:15:57,503 - INFO - Carregando o dataset bruto.
2024-11-26 22:15:57,540 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-26 22:15:57,541 - INFO - Renomeando colunas.
2024-11-26 22:15:57,557 - INFO - Total de linhas a serem processadas: 6000
2024-11-26 22:15:57,557 - INFO - Total de blocos a serem processados: 2
2024-11-26 22:15:57,573 - INFO - Processando bloco 1 de 2
2024-11-26 22:15:57,574 - INFO - Pré-processando os dados.
2024-11-26 22:15:57,967 - INFO - Normalizando os textos.
2024-11-26 22:16:13,234 - INFO - Tokenizando os textos.
2024-11-26 22:16:43,847 - INFO - Criando bigramas.
2024-11-26 22:16:44,367 - INFO - Removendo stopwords.
2024-11-26 22:16:44,389 - INFO - Aplicando stemming.
2024-11-26 22:16:44,834 - INFO - Aplicando lematização.
2024-11-26 22:17:10,132 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 22:17:10,132 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 22:21:22,431 - INFO - Codificando sentimentos.
2024-11-26 22:21:22,589 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 22:21:22,594 - INFO - Aplicando TF-IDF.
2024-11-26 22:21:28,009 - INFO - Bloco 1 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_1.parquet
2024-11-26 22:21:28,054 - INFO - Processando bloco 2 de 2
2024-11-26 22:21:28,054 - INFO - Pré-processando os dados.
2024-11-26 22:21:28,128 - INFO - Normalizando os textos.
2024-11-26 22:21:31,176 - INFO - Tokenizando os textos.
2024-11-26 22:21:37,177 - INFO - Criando bigramas.
2024-11-26 22:21:37,278 - INFO - Removendo stopwords.
2024-11-26 22:21:37,278 - INFO - Aplicando stemming.
2024-11-26 22:21:37,382 - INFO - Aplicando lematização.
2024-11-26 22:21:42,452 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 22:21:42,455 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-26 22:22:32,677 - INFO - Codificando sentimentos.
2024-11-26 22:22:32,713 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-26 22:22:32,713 - INFO - Aplicando TF-IDF.
2024-11-26 22:22:33,228 - INFO - Bloco 2 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_2.parquet
2024-11-26 22:22:33,236 - INFO - Salvando dataset processado.
2024-11-26 22:22:33,654 - INFO - Número de linhas com NaN em 'sentimento_codificado' antes da exclusão: 0
2024-11-26 22:22:33,659 - INFO - Número de linhas restantes após a remoção de NaNs: 5966
2024-11-26 22:22:33,660 - INFO - Contando sentimentos positivos, neutros e negativos.
2024-11-26 22:22:33,662 - INFO - Sentimentos positivos: 978
2024-11-26 22:22:33,663 - INFO - Sentimentos neutros: 2242
2024-11-26 22:22:33,664 - INFO - Sentimentos negativos: 2746
2024-11-26 22:22:33,666 - INFO - Amostra salva com sucesso.
2024-11-26 22:22:38,208 - INFO - Dataset salvo com sucesso.
2024-11-26 22:22:38,247 - INFO - Todos os blocos processados e combinados com sucesso.
2024-11-26 22:22:38,253 - INFO - Gerando relatórios.
2024-11-26 22:22:38,273 - INFO - Relatórios gerados com sucesso.
2024-11-27 18:53:15,242 - INFO - Carregando o dataset bruto.
2024-11-27 18:53:15,316 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-27 18:53:15,316 - INFO - Renomeando colunas.
2024-11-27 18:53:15,339 - INFO - Total de linhas a serem processadas: 6000
2024-11-27 18:53:15,339 - INFO - Total de blocos a serem processados: 2
2024-11-27 18:53:15,353 - INFO - Processando bloco 1 de 2
2024-11-27 18:53:15,353 - INFO - Pré-processando os dados.
2024-11-27 18:53:15,742 - INFO - Normalizando os textos.
2024-11-27 18:53:29,382 - INFO - Tokenizando os textos.
2024-11-27 18:53:56,342 - INFO - Criando bigramas.
2024-11-27 18:53:56,789 - INFO - Removendo stopwords.
2024-11-27 18:53:56,805 - INFO - Aplicando stemming.
2024-11-27 18:53:57,220 - INFO - Aplicando lematização.
2024-11-27 18:54:19,823 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-27 18:54:19,823 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-27 18:58:12,436 - INFO - Codificando sentimentos.
2024-11-27 18:58:12,587 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-27 18:58:12,672 - INFO - Bloco 1 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_1.parquet
2024-11-27 18:58:12,691 - INFO - Processando bloco 2 de 2
2024-11-27 18:58:12,691 - INFO - Pré-processando os dados.
2024-11-27 18:58:12,767 - INFO - Normalizando os textos.
2024-11-27 18:58:15,731 - INFO - Tokenizando os textos.
2024-11-27 18:58:21,189 - INFO - Criando bigramas.
2024-11-27 18:58:21,288 - INFO - Removendo stopwords.
2024-11-27 18:58:21,291 - INFO - Aplicando stemming.
2024-11-27 18:58:21,372 - INFO - Aplicando lematização.
2024-11-27 18:58:25,759 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-27 18:58:25,762 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-27 18:59:18,635 - INFO - Codificando sentimentos.
2024-11-27 18:59:18,668 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-27 18:59:18,693 - INFO - Bloco 2 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_2.parquet
2024-11-27 18:59:18,709 - INFO - Salvando dataset processado.
2024-11-27 18:59:18,796 - INFO - Número de linhas com NaN em 'sentimento_codificado' antes da exclusão: 0
2024-11-27 18:59:18,801 - INFO - Número de linhas restantes após a remoção de NaNs: 5966
2024-11-27 18:59:18,801 - INFO - Contando sentimentos positivos, neutros e negativos.
2024-11-27 18:59:18,804 - INFO - Sentimentos positivos: 978
2024-11-27 18:59:18,804 - INFO - Sentimentos neutros: 2242
2024-11-27 18:59:18,804 - INFO - Sentimentos negativos: 2746
2024-11-27 18:59:18,815 - INFO - Amostra salva com sucesso.
2024-11-27 18:59:19,846 - INFO - Dataset salvo com sucesso.
2024-11-27 18:59:19,849 - INFO - Todos os blocos processados e combinados com sucesso.
2024-11-27 18:59:19,851 - INFO - Gerando relatórios.
2024-11-27 18:59:19,874 - INFO - Relatórios gerados com sucesso.
2024-11-27 19:10:02,885 - INFO - Carregando o dataset bruto.
2024-11-27 19:10:02,912 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-27 19:10:02,912 - INFO - Renomeando colunas.
2024-11-27 19:10:02,927 - INFO - Total de linhas a serem processadas: 6000
2024-11-27 19:10:02,927 - INFO - Total de blocos a serem processados: 2
2024-11-27 19:10:02,959 - INFO - Processando bloco 1 de 2
2024-11-27 19:10:02,966 - INFO - Pré-processando os dados.
2024-11-27 19:10:03,355 - INFO - Normalizando os textos.
2024-11-27 19:10:18,129 - INFO - Tokenizando os textos.
2024-11-27 19:10:42,841 - INFO - Criando bigramas.
2024-11-27 19:10:43,300 - INFO - Removendo stopwords.
2024-11-27 19:10:43,315 - INFO - Aplicando stemming.
2024-11-27 19:10:43,697 - INFO - Aplicando lematização.
2024-11-27 19:11:06,961 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-27 19:11:06,967 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-27 19:17:26,335 - INFO - Codificando sentimentos.
2024-11-27 19:17:26,336 - ERROR - Erro ao codificar sentimentos: name 'LabelEncoder' is not defined
2024-11-27 19:17:26,336 - ERROR - Erro ao processar os dados em blocos: name 'LabelEncoder' is not defined
2024-11-27 19:17:26,336 - ERROR - Erro durante a execução do pipeline de produção: name 'LabelEncoder' is not defined
2024-11-27 19:18:37,433 - INFO - Carregando o dataset bruto.
2024-11-27 19:18:37,466 - INFO - Dataset carregado com sucesso com 6000 linhas.
2024-11-27 19:18:37,467 - INFO - Renomeando colunas.
2024-11-27 19:18:37,492 - INFO - Total de linhas a serem processadas: 6000
2024-11-27 19:18:37,493 - INFO - Total de blocos a serem processados: 2
2024-11-27 19:18:37,515 - INFO - Processando bloco 1 de 2
2024-11-27 19:18:37,515 - INFO - Pré-processando os dados.
2024-11-27 19:18:37,970 - INFO - Normalizando os textos.
2024-11-27 19:18:56,979 - INFO - Tokenizando os textos.
2024-11-27 19:19:40,651 - INFO - Criando bigramas.
2024-11-27 19:19:41,254 - INFO - Removendo stopwords.
2024-11-27 19:19:41,275 - INFO - Aplicando stemming.
2024-11-27 19:19:41,797 - INFO - Aplicando lematização.
2024-11-27 19:20:17,283 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-27 19:20:17,291 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-27 19:26:41,181 - INFO - Codificando sentimentos.
2024-11-27 19:26:41,183 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-27 19:26:41,306 - INFO - Bloco 1 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_1.parquet
2024-11-27 19:26:41,340 - INFO - Processando bloco 2 de 2
2024-11-27 19:26:41,341 - INFO - Pré-processando os dados.
2024-11-27 19:26:41,428 - INFO - Normalizando os textos.
2024-11-27 19:26:44,940 - INFO - Tokenizando os textos.
2024-11-27 19:26:52,684 - INFO - Criando bigramas.
2024-11-27 19:26:52,799 - INFO - Removendo stopwords.
2024-11-27 19:26:52,810 - INFO - Aplicando stemming.
2024-11-27 19:26:52,911 - INFO - Aplicando lematização.
2024-11-27 19:26:59,871 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-27 19:26:59,874 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-27 19:27:40,770 - INFO - Codificando sentimentos.
2024-11-27 19:27:40,771 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-27 19:27:40,790 - INFO - Bloco 2 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_2.parquet
2024-11-27 19:27:40,801 - INFO - Salvando dataset processado.
2024-11-27 19:27:40,879 - INFO - Número de linhas com NaN em 'sentimento_codificado' antes da exclusão: 0
2024-11-27 19:27:40,882 - INFO - Número de linhas restantes após a remoção de NaNs: 5966
2024-11-27 19:27:40,882 - INFO - Contando sentimentos positivos, neutros e negativos.
2024-11-27 19:27:40,884 - INFO - Sentimentos positivos: 978
2024-11-27 19:27:40,885 - INFO - Sentimentos neutros: 2242
2024-11-27 19:27:40,885 - INFO - Sentimentos negativos: 2746
2024-11-27 19:27:40,891 - INFO - Amostra salva com sucesso.
2024-11-27 19:27:41,848 - INFO - Dataset salvo com sucesso.
2024-11-27 19:27:41,852 - INFO - Todos os blocos processados e combinados com sucesso.
2024-11-27 19:27:41,854 - INFO - Gerando relatórios.
2024-11-27 19:27:41,872 - INFO - Relatórios gerados com sucesso.
2024-11-30 07:07:53,852 - INFO - Carregando o dataset bruto.
2024-11-30 07:07:53,889 - INFO - Dataset carregado com sucesso com 2000 linhas.
2024-11-30 07:07:53,890 - INFO - Renomeando colunas.
2024-11-30 07:07:53,893 - INFO - Total de linhas a serem processadas: 2000
2024-11-30 07:07:53,893 - INFO - Total de blocos a serem processados: 1
2024-11-30 07:07:53,914 - INFO - Processando bloco 1 de 1
2024-11-30 07:07:53,914 - INFO - Pré-processando os dados.
2024-11-30 07:07:53,923 - ERROR - Erro ao preprocessar os dados: name 'remover_caracteres_repetidos' is not defined
2024-11-30 07:07:53,924 - ERROR - Erro ao processar os dados em blocos: name 'remover_caracteres_repetidos' is not defined
2024-11-30 07:07:53,924 - ERROR - Erro durante a execução do pipeline de produção: name 'remover_caracteres_repetidos' is not defined
2024-11-30 07:12:02,084 - INFO - Carregando o dataset bruto.
2024-11-30 07:12:02,102 - INFO - Dataset carregado com sucesso com 2000 linhas.
2024-11-30 07:12:02,102 - INFO - Renomeando colunas.
2024-11-30 07:12:02,117 - INFO - Total de linhas a serem processadas: 2000
2024-11-30 07:12:02,118 - INFO - Total de blocos a serem processados: 1
2024-11-30 07:12:02,125 - INFO - Processando bloco 1 de 1
2024-11-30 07:12:02,125 - INFO - Pré-processando os dados.
2024-11-30 07:12:02,132 - ERROR - Erro ao preprocessar os dados: name 'remover_palavras_estrangeiras' is not defined
2024-11-30 07:12:02,132 - ERROR - Erro ao processar os dados em blocos: name 'remover_palavras_estrangeiras' is not defined
2024-11-30 07:12:02,133 - ERROR - Erro durante a execução do pipeline de produção: name 'remover_palavras_estrangeiras' is not defined
2024-11-30 07:14:04,294 - INFO - Carregando o dataset bruto.
2024-11-30 07:14:04,317 - INFO - Dataset carregado com sucesso com 2000 linhas.
2024-11-30 07:14:04,317 - INFO - Renomeando colunas.
2024-11-30 07:14:04,323 - INFO - Total de linhas a serem processadas: 2000
2024-11-30 07:14:04,323 - INFO - Total de blocos a serem processados: 1
2024-11-30 07:14:04,334 - INFO - Processando bloco 1 de 1
2024-11-30 07:14:04,335 - INFO - Pré-processando os dados.
2024-11-30 07:14:04,338 - ERROR - Erro ao preprocessar os dados: name 'LangDetectException' is not defined
2024-11-30 07:14:04,338 - ERROR - Erro ao processar os dados em blocos: name 'LangDetectException' is not defined
2024-11-30 07:14:04,338 - ERROR - Erro durante a execução do pipeline de produção: name 'LangDetectException' is not defined
2024-11-30 07:19:09,418 - INFO - Carregando o dataset bruto.
2024-11-30 07:19:09,440 - INFO - Dataset carregado com sucesso com 2000 linhas.
2024-11-30 07:19:09,440 - INFO - Renomeando colunas.
2024-11-30 07:19:09,459 - INFO - Total de linhas a serem processadas: 2000
2024-11-30 07:19:09,459 - INFO - Total de blocos a serem processados: 1
2024-11-30 07:19:09,467 - INFO - Processando bloco 1 de 1
2024-11-30 07:19:09,467 - INFO - Pré-processando os dados.
2024-11-30 07:19:19,513 - INFO - Normalizando os textos.
2024-11-30 07:19:23,906 - INFO - Tokenizando os textos.
2024-11-30 07:19:33,343 - INFO - Criando bigramas.
2024-11-30 07:19:33,521 - INFO - Removendo stopwords.
2024-11-30 07:19:33,536 - INFO - Aplicando stemming.
2024-11-30 07:19:33,667 - INFO - Aplicando lematização.
2024-11-30 07:19:40,984 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-30 07:19:40,984 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-30 07:20:51,986 - INFO - Codificando sentimentos.
2024-11-30 07:20:51,986 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-30 07:20:52,026 - INFO - Bloco 1 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_1.parquet
2024-11-30 07:20:52,040 - INFO - Salvando dataset processado.
2024-11-30 07:20:52,060 - INFO - Número de linhas com NaN em 'sentimento_codificado' antes da exclusão: 0
2024-11-30 07:20:52,066 - INFO - Número de linhas restantes após a remoção de NaNs: 1811
2024-11-30 07:20:52,066 - INFO - Contando sentimentos positivos, neutros e negativos.
2024-11-30 07:20:52,067 - INFO - Sentimentos positivos: 274
2024-11-30 07:20:52,068 - INFO - Sentimentos neutros: 648
2024-11-30 07:20:52,068 - INFO - Sentimentos negativos: 889
2024-11-30 07:20:52,075 - INFO - Amostra salva com sucesso.
2024-11-30 07:20:52,370 - INFO - Dataset salvo com sucesso.
2024-11-30 07:20:52,370 - INFO - Todos os blocos processados e combinados com sucesso.
2024-11-30 07:20:52,370 - INFO - Gerando relatórios.
2024-11-30 07:20:52,390 - INFO - Relatórios gerados com sucesso.
2024-11-30 08:48:08,096 - INFO - Carregando o dataset bruto.
2024-11-30 08:48:08,146 - INFO - Dataset carregado com sucesso com 2000 linhas.
2024-11-30 08:48:08,147 - INFO - Pré-processando os dados.
2024-11-30 08:48:08,314 - ERROR - Erro durante a execução do pipeline de produção: 'sentimento_codificado'
2024-11-30 09:01:44,295 - INFO - Carregando o dataset bruto.
2024-11-30 09:01:44,351 - INFO - Dataset carregado com sucesso com 2000 linhas.
2024-11-30 09:01:44,352 - ERROR - Erro ao carregar os dados: "A coluna 'sentimento_codificado' não está presente no DataFrame."
2024-11-30 09:01:44,352 - ERROR - Erro durante a execução do pipeline de produção: "A coluna 'sentimento_codificado' não está presente no DataFrame."
2024-11-30 09:03:09,360 - INFO - Carregando o dataset bruto.
2024-11-30 09:03:09,430 - INFO - Dataset carregado com sucesso com 1811 linhas.
2024-11-30 09:03:09,431 - ERROR - Erro ao carregar os dados: Length mismatch: Expected axis has 15 elements, new values have 6 elements
2024-11-30 09:03:09,432 - ERROR - Erro durante a execução do pipeline de produção: Length mismatch: Expected axis has 15 elements, new values have 6 elements
2024-11-30 09:36:17,319 - INFO - Carregando o dataset bruto.
2024-11-30 09:36:17,376 - INFO - Dataset carregado com sucesso com 1811 linhas.
2024-11-30 09:36:17,376 - ERROR - Erro ao carregar os dados: Length mismatch: Expected axis has 15 elements, new values have 6 elements
2024-11-30 09:36:17,376 - ERROR - Erro durante a execução do pipeline de produção: Length mismatch: Expected axis has 15 elements, new values have 6 elements
2024-11-30 09:37:17,018 - INFO - Carregando o dataset bruto.
2024-11-30 09:37:17,073 - INFO - Dataset carregado com sucesso com 1811 linhas.
2024-11-30 09:37:17,073 - ERROR - Erro ao carregar os dados: Length mismatch: Expected axis has 15 elements, new values have 6 elements
2024-11-30 09:37:17,073 - ERROR - Erro durante a execução do pipeline de produção: Length mismatch: Expected axis has 15 elements, new values have 6 elements
2024-11-30 09:39:38,791 - INFO - Carregando o dataset bruto.
2024-11-30 09:39:38,853 - INFO - Dataset carregado com sucesso com 1811 linhas.
2024-11-30 09:39:38,853 - ERROR - Erro ao carregar os dados: "A coluna 'sentimento_codificado' não está presente no DataFrame."
2024-11-30 09:39:38,853 - ERROR - Erro durante a execução do pipeline de produção: "A coluna 'sentimento_codificado' não está presente no DataFrame."
2024-11-30 09:39:38,853 - INFO - Carregando o dataset bruto.
2024-11-30 09:39:38,875 - INFO - Dataset carregado com sucesso com 1811 linhas.
2024-11-30 09:39:38,875 - ERROR - Erro ao carregar os dados: "A coluna 'sentimento_codificado' não está presente no DataFrame."
2024-11-30 09:39:38,880 - ERROR - Erro durante a execução do pipeline de produção: "A coluna 'sentimento_codificado' não está presente no DataFrame."
2024-11-30 09:44:52,391 - INFO - Carregando o dataset bruto.
2024-11-30 09:44:52,448 - INFO - Dataset carregado com sucesso com 1811 linhas.
2024-11-30 09:44:52,460 - ERROR - Erro ao carregar os dados: "A coluna 'sentimento_codificado' não está presente no DataFrame."
2024-11-30 09:44:52,460 - ERROR - Erro durante a execução do pipeline de produção: "A coluna 'sentimento_codificado' não está presente no DataFrame."
2024-11-30 09:44:52,460 - INFO - Carregando o dataset bruto.
2024-11-30 09:44:52,478 - INFO - Dataset carregado com sucesso com 1811 linhas.
2024-11-30 09:44:52,480 - ERROR - Erro ao carregar os dados: "A coluna 'sentimento_codificado' não está presente no DataFrame."
2024-11-30 09:44:52,481 - ERROR - Erro durante a execução do pipeline de produção: "A coluna 'sentimento_codificado' não está presente no DataFrame."
2024-11-30 09:47:07,960 - INFO - Carregando o dataset bruto.
2024-11-30 09:47:08,027 - INFO - Dataset carregado com sucesso com 1811 linhas.
2024-11-30 09:47:08,027 - INFO - Colunas do DataFrame: ['index', 'id', 'date', 'query', 'username', 'tweet', 'tokens', 'bigrams', 'tokens_sem_stopwords', 'tokens_stemmed', 'tokens_lemmatizados', 'sentimento_vader', 'sentimento_bert', 'sentimento', 'sentimento_codificado']
2024-11-30 09:48:16,174 - INFO - Carregando o dataset bruto.
2024-11-30 09:48:16,239 - INFO - Dataset carregado com sucesso com 1811 linhas.
2024-11-30 09:48:16,240 - INFO - Colunas do DataFrame: ['index', 'id', 'date', 'query', 'username', 'tweet', 'tokens', 'bigrams', 'tokens_sem_stopwords', 'tokens_stemmed', 'tokens_lemmatizados', 'sentimento_vader', 'sentimento_bert', 'sentimento', 'sentimento_codificado']
2024-11-30 09:48:16,240 - INFO - Carregando o dataset bruto.
2024-11-30 09:48:16,257 - INFO - Dataset carregado com sucesso com 1811 linhas.
2024-11-30 09:48:16,258 - INFO - Colunas do DataFrame: ['index', 'id', 'date', 'query', 'username', 'tweet', 'tokens', 'bigrams', 'tokens_sem_stopwords', 'tokens_stemmed', 'tokens_lemmatizados', 'sentimento_vader', 'sentimento_bert', 'sentimento', 'sentimento_codificado']
2024-11-30 09:48:16,260 - INFO - Classificando sentimentos usando BERT.
2024-11-30 09:48:18,951 - INFO - Treinando o modelo BERT.
2024-11-30 09:48:19,056 - ERROR - Erro ao classificar sentimentos: in user code:

    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1284, in train_function  *
        return step_function(self, iterator)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1268, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1249, in run_step  **
        outputs = model.train_step(data)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\transformers\modeling_tf_utils.py", line 1630, in train_step
        x, y, sample_weight = keras.utils.unpack_x_y_sample_weight(data)

    AttributeError: module 'keras.utils' has no attribute 'unpack_x_y_sample_weight'

2024-11-30 09:48:19,058 - ERROR - Erro durante a execução do pipeline de produção: in user code:

    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1284, in train_function  *
        return step_function(self, iterator)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1268, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1249, in run_step  **
        outputs = model.train_step(data)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\transformers\modeling_tf_utils.py", line 1630, in train_step
        x, y, sample_weight = keras.utils.unpack_x_y_sample_weight(data)

    AttributeError: module 'keras.utils' has no attribute 'unpack_x_y_sample_weight'

2024-11-30 09:51:16,175 - INFO - Carregando o dataset bruto.
2024-11-30 09:51:16,222 - INFO - Dataset carregado com sucesso com 1811 linhas.
2024-11-30 09:51:16,222 - INFO - Colunas do DataFrame: ['index', 'id', 'date', 'query', 'username', 'tweet', 'tokens', 'bigrams', 'tokens_sem_stopwords', 'tokens_stemmed', 'tokens_lemmatizados', 'sentimento_vader', 'sentimento_bert', 'sentimento', 'sentimento_codificado']
2024-11-30 09:51:16,234 - INFO - Carregando o dataset bruto.
2024-11-30 09:51:16,254 - INFO - Dataset carregado com sucesso com 1811 linhas.
2024-11-30 09:51:16,254 - INFO - Colunas do DataFrame: ['index', 'id', 'date', 'query', 'username', 'tweet', 'tokens', 'bigrams', 'tokens_sem_stopwords', 'tokens_stemmed', 'tokens_lemmatizados', 'sentimento_vader', 'sentimento_bert', 'sentimento', 'sentimento_codificado']
2024-11-30 09:51:16,256 - INFO - Classificando sentimentos usando BERT.
2024-11-30 09:51:19,075 - INFO - Treinando o modelo BERT.
2024-11-30 09:51:19,169 - ERROR - Erro ao classificar sentimentos: in user code:

    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1284, in train_function  *
        return step_function(self, iterator)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1268, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1249, in run_step  **
        outputs = model.train_step(data)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\transformers\modeling_tf_utils.py", line 1630, in train_step
        x, y, sample_weight = keras.utils.unpack_x_y_sample_weight(data)

    AttributeError: module 'keras.utils' has no attribute 'unpack_x_y_sample_weight'

2024-11-30 09:51:19,176 - ERROR - Erro durante a execução do pipeline de produção: in user code:

    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1284, in train_function  *
        return step_function(self, iterator)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1268, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1249, in run_step  **
        outputs = model.train_step(data)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\transformers\modeling_tf_utils.py", line 1630, in train_step
        x, y, sample_weight = keras.utils.unpack_x_y_sample_weight(data)

    AttributeError: module 'keras.utils' has no attribute 'unpack_x_y_sample_weight'

2024-11-30 09:52:38,082 - INFO - Carregando o dataset bruto.
2024-11-30 09:52:38,137 - INFO - Dataset carregado com sucesso com 1811 linhas.
2024-11-30 09:52:38,137 - INFO - Colunas do DataFrame: ['index', 'id', 'date', 'query', 'username', 'tweet', 'tokens', 'bigrams', 'tokens_sem_stopwords', 'tokens_stemmed', 'tokens_lemmatizados', 'sentimento_vader', 'sentimento_bert', 'sentimento', 'sentimento_codificado']
2024-11-30 09:52:38,137 - INFO - Classificando sentimentos usando BERT.
2024-11-30 09:52:40,848 - INFO - Treinando o modelo BERT.
2024-11-30 09:52:40,938 - ERROR - Erro ao classificar sentimentos: in user code:

    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1284, in train_function  *
        return step_function(self, iterator)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1268, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1249, in run_step  **
        outputs = model.train_step(data)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\transformers\modeling_tf_utils.py", line 1630, in train_step
        x, y, sample_weight = keras.utils.unpack_x_y_sample_weight(data)

    AttributeError: module 'keras.utils' has no attribute 'unpack_x_y_sample_weight'

2024-11-30 09:52:40,947 - ERROR - Erro durante a execução do pipeline de produção: in user code:

    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1284, in train_function  *
        return step_function(self, iterator)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1268, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1249, in run_step  **
        outputs = model.train_step(data)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\transformers\modeling_tf_utils.py", line 1630, in train_step
        x, y, sample_weight = keras.utils.unpack_x_y_sample_weight(data)

    AttributeError: module 'keras.utils' has no attribute 'unpack_x_y_sample_weight'

2024-11-30 09:53:47,131 - INFO - Carregando o dataset bruto.
2024-11-30 09:53:47,187 - INFO - Dataset carregado com sucesso com 1811 linhas.
2024-11-30 09:53:47,187 - INFO - Colunas do DataFrame: ['index', 'id', 'date', 'query', 'username', 'tweet', 'tokens', 'bigrams', 'tokens_sem_stopwords', 'tokens_stemmed', 'tokens_lemmatizados', 'sentimento_vader', 'sentimento_bert', 'sentimento', 'sentimento_codificado']
2024-11-30 09:53:47,187 - INFO - Classificando sentimentos usando BERT.
2024-11-30 09:53:50,347 - INFO - Treinando o modelo BERT.
2024-11-30 09:53:50,403 - ERROR - Erro ao classificar sentimentos: in user code:

    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1284, in train_function  *
        return step_function(self, iterator)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1268, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1249, in run_step  **
        outputs = model.train_step(data)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\transformers\modeling_tf_utils.py", line 1630, in train_step
        x, y, sample_weight = keras.utils.unpack_x_y_sample_weight(data)

    AttributeError: module 'keras.utils' has no attribute 'unpack_x_y_sample_weight'

2024-11-30 09:53:50,403 - ERROR - Erro durante a execução do pipeline de produção: in user code:

    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1284, in train_function  *
        return step_function(self, iterator)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1268, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1249, in run_step  **
        outputs = model.train_step(data)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\transformers\modeling_tf_utils.py", line 1630, in train_step
        x, y, sample_weight = keras.utils.unpack_x_y_sample_weight(data)

    AttributeError: module 'keras.utils' has no attribute 'unpack_x_y_sample_weight'

2024-11-30 09:55:19,162 - INFO - Carregando o dataset bruto.
2024-11-30 09:55:19,217 - INFO - Dataset carregado com sucesso com 1811 linhas.
2024-11-30 09:55:19,217 - INFO - Colunas do DataFrame: ['index', 'id', 'date', 'query', 'username', 'tweet', 'tokens', 'bigrams', 'tokens_sem_stopwords', 'tokens_stemmed', 'tokens_lemmatizados', 'sentimento_vader', 'sentimento_bert', 'sentimento', 'sentimento_codificado']
2024-11-30 09:55:19,217 - INFO - Classificando sentimentos usando BERT.
2024-11-30 09:55:22,145 - INFO - Treinando o modelo BERT.
2024-11-30 09:55:22,212 - ERROR - Erro ao classificar sentimentos: in user code:

    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1284, in train_function  *
        return step_function(self, iterator)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1268, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1249, in run_step  **
        outputs = model.train_step(data)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\transformers\modeling_tf_utils.py", line 1630, in train_step
        x, y, sample_weight = keras.utils.unpack_x_y_sample_weight(data)

    AttributeError: module 'keras.utils' has no attribute 'unpack_x_y_sample_weight'

2024-11-30 09:55:22,214 - ERROR - Erro durante a execução do pipeline de produção: in user code:

    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1284, in train_function  *
        return step_function(self, iterator)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1268, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1249, in run_step  **
        outputs = model.train_step(data)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\transformers\modeling_tf_utils.py", line 1630, in train_step
        x, y, sample_weight = keras.utils.unpack_x_y_sample_weight(data)

    AttributeError: module 'keras.utils' has no attribute 'unpack_x_y_sample_weight'

2024-11-30 09:59:52,390 - INFO - Carregando o dataset bruto.
2024-11-30 09:59:52,445 - INFO - Dataset carregado com sucesso com 1811 linhas.
2024-11-30 09:59:52,445 - INFO - Colunas do DataFrame: ['index', 'id', 'date', 'query', 'username', 'tweet', 'tokens', 'bigrams', 'tokens_sem_stopwords', 'tokens_stemmed', 'tokens_lemmatizados', 'sentimento_vader', 'sentimento_bert', 'sentimento', 'sentimento_codificado']
2024-11-30 09:59:52,445 - INFO - Classificando sentimentos usando BERT.
2024-11-30 09:59:55,156 - INFO - Treinando o modelo BERT.
2024-11-30 09:59:55,209 - ERROR - Erro ao classificar sentimentos: in user code:

    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1284, in train_function  *
        return step_function(self, iterator)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1268, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1249, in run_step  **
        outputs = model.train_step(data)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\transformers\modeling_tf_utils.py", line 1630, in train_step
        x, y, sample_weight = keras.utils.unpack_x_y_sample_weight(data)

    AttributeError: module 'keras.utils' has no attribute 'unpack_x_y_sample_weight'

2024-11-30 09:59:55,211 - ERROR - Erro durante a execução do pipeline de produção: in user code:

    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1284, in train_function  *
        return step_function(self, iterator)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1268, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1249, in run_step  **
        outputs = model.train_step(data)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\transformers\modeling_tf_utils.py", line 1630, in train_step
        x, y, sample_weight = keras.utils.unpack_x_y_sample_weight(data)

    AttributeError: module 'keras.utils' has no attribute 'unpack_x_y_sample_weight'

2024-11-30 10:14:43,188 - INFO - Carregando o dataset bruto.
2024-11-30 10:14:43,256 - INFO - Dataset carregado com sucesso com 1811 linhas.
2024-11-30 10:14:43,256 - INFO - Colunas do DataFrame: ['index', 'id', 'date', 'query', 'username', 'tweet', 'tokens', 'bigrams', 'tokens_sem_stopwords', 'tokens_stemmed', 'tokens_lemmatizados', 'sentimento_vader', 'sentimento_bert', 'sentimento', 'sentimento_codificado']
2024-11-30 10:14:43,256 - INFO - Classificando sentimentos usando BERT.
2024-11-30 10:14:46,488 - INFO - Treinando o modelo BERT.
2024-11-30 10:14:46,545 - ERROR - Erro ao classificar sentimentos: in user code:

    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1284, in train_function  *
        return step_function(self, iterator)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1268, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1249, in run_step  **
        outputs = model.train_step(data)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\transformers\modeling_tf_utils.py", line 1630, in train_step
        x, y, sample_weight = keras.utils.unpack_x_y_sample_weight(data)

    AttributeError: module 'keras.utils' has no attribute 'unpack_x_y_sample_weight'

2024-11-30 10:14:46,545 - ERROR - Erro durante a execução do pipeline de produção: in user code:

    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1284, in train_function  *
        return step_function(self, iterator)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1268, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1249, in run_step  **
        outputs = model.train_step(data)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\transformers\modeling_tf_utils.py", line 1630, in train_step
        x, y, sample_weight = keras.utils.unpack_x_y_sample_weight(data)

    AttributeError: module 'keras.utils' has no attribute 'unpack_x_y_sample_weight'

2024-11-30 10:17:11,635 - INFO - Carregando o dataset bruto.
2024-11-30 10:17:11,691 - INFO - Dataset carregado com sucesso com 1811 linhas.
2024-11-30 10:17:11,691 - INFO - Colunas do DataFrame: ['index', 'id', 'date', 'query', 'username', 'tweet', 'tokens', 'bigrams', 'tokens_sem_stopwords', 'tokens_stemmed', 'tokens_lemmatizados', 'sentimento_vader', 'sentimento_bert', 'sentimento', 'sentimento_codificado']
2024-11-30 10:17:11,691 - INFO - Classificando sentimentos usando BERT.
2024-11-30 10:17:14,901 - INFO - Treinando o modelo BERT.
2024-11-30 10:17:14,958 - ERROR - Erro ao classificar sentimentos: in user code:

    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1284, in train_function  *
        return step_function(self, iterator)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1268, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1249, in run_step  **
        outputs = model.train_step(data)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\transformers\modeling_tf_utils.py", line 1630, in train_step
        x, y, sample_weight = keras.utils.unpack_x_y_sample_weight(data)

    AttributeError: module 'keras.utils' has no attribute 'unpack_x_y_sample_weight'

2024-11-30 10:17:14,968 - ERROR - Erro durante a execução do pipeline de produção: in user code:

    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1284, in train_function  *
        return step_function(self, iterator)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1268, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1249, in run_step  **
        outputs = model.train_step(data)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\transformers\modeling_tf_utils.py", line 1630, in train_step
        x, y, sample_weight = keras.utils.unpack_x_y_sample_weight(data)

    AttributeError: module 'keras.utils' has no attribute 'unpack_x_y_sample_weight'

2024-11-30 10:17:50,384 - INFO - Carregando o dataset bruto.
2024-11-30 10:17:50,442 - INFO - Dataset carregado com sucesso com 1811 linhas.
2024-11-30 10:17:50,442 - INFO - Colunas do DataFrame: ['index', 'id', 'date', 'query', 'username', 'tweet', 'tokens', 'bigrams', 'tokens_sem_stopwords', 'tokens_stemmed', 'tokens_lemmatizados', 'sentimento_vader', 'sentimento_bert', 'sentimento', 'sentimento_codificado']
2024-11-30 10:17:50,451 - INFO - Classificando sentimentos usando BERT.
2024-11-30 10:17:53,221 - INFO - Treinando o modelo BERT.
2024-11-30 10:17:53,271 - ERROR - Erro ao classificar sentimentos: in user code:

    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1284, in train_function  *
        return step_function(self, iterator)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1268, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1249, in run_step  **
        outputs = model.train_step(data)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\transformers\modeling_tf_utils.py", line 1630, in train_step
        x, y, sample_weight = keras.utils.unpack_x_y_sample_weight(data)

    AttributeError: module 'keras.utils' has no attribute 'unpack_x_y_sample_weight'

2024-11-30 10:17:53,273 - ERROR - Erro durante a execução do pipeline de produção: in user code:

    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1284, in train_function  *
        return step_function(self, iterator)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1268, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1249, in run_step  **
        outputs = model.train_step(data)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\transformers\modeling_tf_utils.py", line 1630, in train_step
        x, y, sample_weight = keras.utils.unpack_x_y_sample_weight(data)

    AttributeError: module 'keras.utils' has no attribute 'unpack_x_y_sample_weight'

2024-11-30 10:19:01,999 - INFO - Carregando o dataset bruto.
2024-11-30 10:19:02,054 - INFO - Dataset carregado com sucesso com 1811 linhas.
2024-11-30 10:19:02,054 - INFO - Colunas do DataFrame: ['index', 'id', 'date', 'query', 'username', 'tweet', 'tokens', 'bigrams', 'tokens_sem_stopwords', 'tokens_stemmed', 'tokens_lemmatizados', 'sentimento_vader', 'sentimento_bert', 'sentimento', 'sentimento_codificado']
2024-11-30 10:19:02,054 - INFO - Classificando sentimentos usando BERT.
2024-11-30 10:19:04,799 - INFO - Treinando o modelo BERT.
2024-11-30 10:19:04,854 - ERROR - Erro ao classificar sentimentos: in user code:

    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1284, in train_function  *
        return step_function(self, iterator)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1268, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1249, in run_step  **
        outputs = model.train_step(data)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\transformers\modeling_tf_utils.py", line 1630, in train_step
        x, y, sample_weight = keras.utils.unpack_x_y_sample_weight(data)

    AttributeError: module 'keras.utils' has no attribute 'unpack_x_y_sample_weight'

2024-11-30 10:19:04,854 - ERROR - Erro durante a execução do pipeline de produção: in user code:

    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1284, in train_function  *
        return step_function(self, iterator)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1268, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1249, in run_step  **
        outputs = model.train_step(data)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\transformers\modeling_tf_utils.py", line 1630, in train_step
        x, y, sample_weight = keras.utils.unpack_x_y_sample_weight(data)

    AttributeError: module 'keras.utils' has no attribute 'unpack_x_y_sample_weight'

2024-11-30 10:20:50,430 - INFO - Carregando o dataset bruto.
2024-11-30 10:20:50,484 - INFO - Dataset carregado com sucesso com 1811 linhas.
2024-11-30 10:20:50,485 - INFO - Colunas do DataFrame: ['index', 'id', 'date', 'query', 'username', 'tweet', 'tokens', 'bigrams', 'tokens_sem_stopwords', 'tokens_stemmed', 'tokens_lemmatizados', 'sentimento_vader', 'sentimento_bert', 'sentimento', 'sentimento_codificado']
2024-11-30 10:20:50,486 - INFO - Classificando sentimentos usando BERT.
2024-11-30 10:20:57,147 - INFO - Treinando o modelo BERT.
2024-11-30 10:20:57,205 - ERROR - Erro ao classificar sentimentos: in user code:

    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1284, in train_function  *
        return step_function(self, iterator)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1268, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1249, in run_step  **
        outputs = model.train_step(data)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1050, in train_step
        y_pred = self(x, training=True)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\utils\traceback_utils.py", line 70, in error_handler
        raise e.with_traceback(filtered_tb) from None
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\input_spec.py", line 298, in assert_input_compatibility
        raise ValueError(

    ValueError: Input 0 of layer "model" is incompatible with the layer: expected shape=(None, 128), found shape=(None, 37)

2024-11-30 10:20:57,205 - ERROR - Erro durante a execução do pipeline de produção: in user code:

    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1284, in train_function  *
        return step_function(self, iterator)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1268, in step_function  **
        outputs = model.distribute_strategy.run(run_step, args=(data,))
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1249, in run_step  **
        outputs = model.train_step(data)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\training.py", line 1050, in train_step
        y_pred = self(x, training=True)
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\utils\traceback_utils.py", line 70, in error_handler
        raise e.with_traceback(filtered_tb) from None
    File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\keras\engine\input_spec.py", line 298, in assert_input_compatibility
        raise ValueError(

    ValueError: Input 0 of layer "model" is incompatible with the layer: expected shape=(None, 128), found shape=(None, 37)

2024-11-30 10:30:34,354 - INFO - Carregando o dataset bruto.
2024-11-30 10:30:34,425 - INFO - Dataset carregado com sucesso com 1811 linhas.
2024-11-30 10:30:34,425 - INFO - Colunas do DataFrame: ['index', 'id', 'date', 'query', 'username', 'tweet', 'tokens', 'bigrams', 'tokens_sem_stopwords', 'tokens_stemmed', 'tokens_lemmatizados', 'sentimento_vader', 'sentimento_bert', 'sentimento', 'sentimento_codificado']
2024-11-30 10:30:34,425 - INFO - Classificando sentimentos usando BERT.
2024-11-30 10:30:41,515 - INFO - Treinando o modelo BERT.
2024-11-30 10:30:45,585 - WARNING - Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?
2024-11-30 10:30:45,957 - WARNING - Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?
2024-11-30 10:30:53,719 - WARNING - Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?
2024-11-30 10:30:53,719 - WARNING - Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?
2024-11-30 10:36:21,030 - INFO - Carregando o dataset bruto.
2024-11-30 10:36:21,123 - INFO - Dataset carregado com sucesso com 1811 linhas.
2024-11-30 10:36:21,123 - INFO - Colunas do DataFrame: ['index', 'id', 'date', 'query', 'username', 'tweet', 'tokens', 'bigrams', 'tokens_sem_stopwords', 'tokens_stemmed', 'tokens_lemmatizados', 'sentimento_vader', 'sentimento_bert', 'sentimento', 'sentimento_codificado']
2024-11-30 10:36:21,124 - INFO - Classificando sentimentos usando BERT.
2024-11-30 10:36:29,307 - INFO - Treinando o modelo BERT.
2024-11-30 10:36:33,795 - WARNING - Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?
2024-11-30 10:36:34,180 - WARNING - Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?
2024-11-30 10:36:43,070 - WARNING - Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?
2024-11-30 10:36:43,070 - WARNING - Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?
2024-11-30 10:44:18,737 - INFO - Carregando o dataset bruto.
2024-11-30 10:44:19,026 - INFO - Dataset carregado com sucesso com 1811 linhas.
2024-11-30 10:44:19,031 - INFO - Colunas do DataFrame: ['index', 'id', 'date', 'query', 'username', 'tweet', 'tokens', 'bigrams', 'tokens_sem_stopwords', 'tokens_stemmed', 'tokens_lemmatizados', 'sentimento_vader', 'sentimento_bert', 'sentimento', 'sentimento_codificado']
2024-11-30 10:44:19,039 - INFO - Classificando sentimentos usando BERT.
2024-11-30 10:44:34,368 - INFO - Treinando o modelo BERT.
2024-11-30 10:44:42,689 - WARNING - Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?
2024-11-30 10:44:43,335 - WARNING - Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?
2024-11-30 10:45:00,860 - WARNING - Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?
2024-11-30 10:45:00,881 - WARNING - Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?
2024-11-30 10:50:07,171 - INFO - Carregando o dataset bruto.
2024-11-30 10:50:07,453 - INFO - Dataset carregado com sucesso com 1811 linhas.
2024-11-30 10:50:07,453 - INFO - Colunas do DataFrame: ['index', 'id', 'date', 'query', 'username', 'tweet', 'tokens', 'bigrams', 'tokens_sem_stopwords', 'tokens_stemmed', 'tokens_lemmatizados', 'sentimento_vader', 'sentimento_bert', 'sentimento', 'sentimento_codificado']
2024-11-30 10:50:07,470 - INFO - Classificando sentimentos usando BERT.
2024-11-30 10:50:22,963 - INFO - Treinando o modelo BERT.
2024-11-30 10:50:31,384 - WARNING - Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?
2024-11-30 10:50:32,010 - WARNING - Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?
2024-11-30 10:50:49,369 - WARNING - Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?
2024-11-30 10:50:49,389 - WARNING - Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?
2024-11-30 11:19:07,660 - INFO - Carregando o dataset bruto.
2024-11-30 11:19:08,260 - INFO - Dataset carregado com sucesso com 1811 linhas.
2024-11-30 11:19:08,276 - INFO - Colunas do DataFrame: ['index', 'id', 'date', 'query', 'username', 'tweet', 'tokens', 'bigrams', 'tokens_sem_stopwords', 'tokens_stemmed', 'tokens_lemmatizados', 'sentimento_vader', 'sentimento_bert', 'sentimento', 'sentimento_codificado']
2024-11-30 11:19:08,277 - INFO - Classificando sentimentos usando BERT.
2024-11-30 11:19:42,872 - INFO - Treinando o modelo BERT.
2024-11-30 11:20:06,095 - WARNING - Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?
2024-11-30 11:20:07,260 - WARNING - Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?
2024-11-30 11:20:56,771 - WARNING - Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?
2024-11-30 11:20:56,834 - WARNING - Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?
2024-11-30 12:57:10,922 - INFO - Fazendo previsões no conjunto de teste.
2024-11-30 13:00:27,534 - INFO - Relatório de Classificação - BERT:
              precision    recall  f1-score   support

           0       0.52      0.57      0.55       282
           1       0.38      0.37      0.37       190
           2       0.14      0.08      0.10        72

    accuracy                           0.44       544
   macro avg       0.34      0.34      0.34       544
weighted avg       0.42      0.44      0.43       544

2024-11-30 13:00:27,549 - INFO - Relatório de Classificação - Padrão:
              precision    recall  f1-score   support

           0       0.52      0.57      0.55       282
           1       0.38      0.37      0.37       190
           2       0.14      0.08      0.10        72

    accuracy                           0.44       544
   macro avg       0.34      0.34      0.34       544
weighted avg       0.42      0.44      0.43       544

2024-11-30 13:00:27,588 - INFO - AUC-ROC Score: 0.51
2024-11-30 13:00:28,448 - ERROR - Erro ao avaliar o modelo: [Errno 2] No such file or directory: 'D\\\\Github\\\\data-science\\\\projetos\\\\analise-de-sentimentos\\\\nlp\\\\reports\\\\figures\\\\roc_curve_bert.png'
2024-11-30 13:00:28,495 - ERROR - Erro durante a execução do pipeline de produção: [Errno 2] No such file or directory: 'D\\\\Github\\\\data-science\\\\projetos\\\\analise-de-sentimentos\\\\nlp\\\\reports\\\\figures\\\\roc_curve_bert.png'
2024-11-30 13:26:08,798 - INFO - Fazendo previsões no conjunto de teste.
2024-11-30 13:28:01,748 - INFO - Relatório de Classificação - BERT:
              precision    recall  f1-score   support

           0       0.48      0.35      0.40       282
           1       0.32      0.46      0.38       190
           2       0.16      0.15      0.16        72

    accuracy                           0.36       544
   macro avg       0.32      0.32      0.31       544
weighted avg       0.38      0.36      0.36       544

2024-11-30 13:28:01,748 - INFO - Relatório de Classificação - Padrão:
              precision    recall  f1-score   support

           0       0.48      0.35      0.40       282
           1       0.32      0.46      0.38       190
           2       0.16      0.15      0.16        72

    accuracy                           0.36       544
   macro avg       0.32      0.32      0.31       544
weighted avg       0.38      0.36      0.36       544

2024-11-30 13:28:01,763 - INFO - AUC-ROC Score: 0.49
2024-11-30 13:28:02,162 - ERROR - Erro ao avaliar o modelo: [Errno 2] No such file or directory: 'D\\\\Github\\\\data-science\\\\projetos\\\\analise-de-sentimentos\\\\nlp\\\\reports\\\\figures\\\\roc_curve_bert.png'
2024-11-30 13:28:02,172 - ERROR - Erro durante a execução do pipeline de produção: [Errno 2] No such file or directory: 'D\\\\Github\\\\data-science\\\\projetos\\\\analise-de-sentimentos\\\\nlp\\\\reports\\\\figures\\\\roc_curve_bert.png'
2024-11-30 17:02:51,786 - INFO - Carregando o dataset bruto.
2024-11-30 17:02:51,859 - INFO - Dataset carregado com sucesso com 1811 linhas.
2024-11-30 17:02:51,859 - INFO - Colunas do DataFrame: ['index', 'id', 'date', 'query', 'username', 'tweet', 'tokens', 'bigrams', 'tokens_sem_stopwords', 'tokens_stemmed', 'tokens_lemmatizados', 'sentimento_vader', 'sentimento_bert', 'sentimento', 'sentimento_codificado']
2024-11-30 17:02:51,859 - INFO - Classificando sentimentos usando BERT.
2024-11-30 17:03:00,067 - INFO - Treinando o modelo BERT.
2024-11-30 17:03:04,486 - WARNING - Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?
2024-11-30 17:03:04,814 - WARNING - Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?
2024-11-30 17:03:13,318 - WARNING - Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?
2024-11-30 17:03:13,352 - WARNING - Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?
2024-11-30 18:42:02,186 - INFO - Fazendo previsões no conjunto de teste.
2024-11-30 18:44:13,328 - INFO - Relatório de Classificação - BERT:
              precision    recall  f1-score   support

           0       0.56      0.48      0.52       282
           1       0.35      0.46      0.40       190
           2       0.13      0.10      0.11        72

    accuracy                           0.42       544
   macro avg       0.35      0.35      0.34       544
weighted avg       0.43      0.42      0.42       544

2024-11-30 18:44:13,341 - INFO - Relatório de Classificação - Padrão:
              precision    recall  f1-score   support

           0       0.56      0.48      0.52       282
           1       0.35      0.46      0.40       190
           2       0.13      0.10      0.11        72

    accuracy                           0.42       544
   macro avg       0.35      0.35      0.34       544
weighted avg       0.43      0.42      0.42       544

2024-11-30 18:44:13,364 - INFO - AUC-ROC Score: 0.49
2024-11-30 18:44:13,787 - ERROR - Erro ao avaliar o modelo: [Errno 2] No such file or directory: 'D\\\\Github\\\\data-science\\\\projetos\\\\analise-de-sentimentos\\\\nlp\\\\reports\\\\figures\\\\roc_curve_bert.png'
2024-11-30 18:44:13,803 - ERROR - Erro durante a execução do pipeline de produção: [Errno 2] No such file or directory: 'D\\\\Github\\\\data-science\\\\projetos\\\\analise-de-sentimentos\\\\nlp\\\\reports\\\\figures\\\\roc_curve_bert.png'
2024-11-30 19:17:49,883 - INFO - Carregando o dataset bruto.
2024-11-30 19:17:50,134 - INFO - Dataset carregado com sucesso com 1811 linhas.
2024-11-30 19:17:50,144 - INFO - Colunas do DataFrame: ['index', 'id', 'date', 'query', 'username', 'tweet', 'tokens', 'bigrams', 'tokens_sem_stopwords', 'tokens_stemmed', 'tokens_lemmatizados', 'sentimento_vader', 'sentimento_bert', 'sentimento', 'sentimento_codificado']
2024-11-30 19:17:50,150 - INFO - Classificando sentimentos usando BERT.
2024-11-30 19:18:05,305 - INFO - Treinando o modelo BERT.
2024-11-30 19:18:13,965 - WARNING - Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?
2024-11-30 19:18:14,666 - WARNING - Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?
2024-11-30 19:18:29,878 - WARNING - Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?
2024-11-30 19:18:29,907 - WARNING - Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?
2024-11-30 19:48:19,709 - INFO - Carregando o dataset bruto.
2024-11-30 19:48:19,731 - INFO - Dataset carregado com sucesso com 10000 linhas.
2024-11-30 19:48:19,732 - INFO - Renomeando colunas.
2024-11-30 19:48:19,753 - INFO - Total de linhas a serem processadas: 10000
2024-11-30 19:48:19,753 - INFO - Total de blocos a serem processados: 2
2024-11-30 19:48:19,769 - INFO - Processando bloco 1 de 2
2024-11-30 19:48:19,770 - INFO - Pré-processando os dados.
2024-11-30 19:48:45,413 - INFO - Normalizando os textos.
2024-11-30 19:48:56,614 - INFO - Tokenizando os textos.
2024-11-30 19:49:20,376 - INFO - Criando bigramas.
2024-11-30 19:49:20,795 - INFO - Removendo stopwords.
2024-11-30 19:49:20,821 - INFO - Aplicando stemming.
2024-11-30 19:49:21,207 - INFO - Aplicando lematização.
2024-11-30 19:49:40,280 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-30 19:49:40,285 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-30 19:52:59,740 - INFO - Codificando sentimentos.
2024-11-30 19:52:59,740 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-30 19:52:59,823 - INFO - Bloco 1 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_1.parquet
2024-11-30 19:52:59,845 - INFO - Processando bloco 2 de 2
2024-11-30 19:52:59,845 - INFO - Pré-processando os dados.
2024-11-30 19:53:23,922 - INFO - Normalizando os textos.
2024-11-30 19:53:34,639 - INFO - Tokenizando os textos.
2024-11-30 19:53:57,123 - INFO - Criando bigramas.
2024-11-30 19:53:57,522 - INFO - Removendo stopwords.
2024-11-30 19:53:57,541 - INFO - Aplicando stemming.
2024-11-30 19:53:57,905 - INFO - Aplicando lematização.
2024-11-30 19:54:16,706 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-30 19:54:16,706 - INFO - Classificando sentimentos usando VADER e BERT.
2024-11-30 19:59:21,116 - INFO - Codificando sentimentos.
2024-11-30 19:59:21,116 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-11-30 19:59:21,238 - INFO - Bloco 2 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_2.parquet
2024-11-30 19:59:21,247 - INFO - Salvando dataset processado.
2024-11-30 19:59:21,392 - INFO - Número de linhas com NaN em 'sentimento_codificado' antes da exclusão: 0
2024-11-30 19:59:21,399 - INFO - Número de linhas restantes após a remoção de NaNs: 9204
2024-11-30 19:59:21,399 - INFO - Contando sentimentos positivos, neutros e negativos.
2024-11-30 19:59:21,401 - INFO - Sentimentos positivos: 1350
2024-11-30 19:59:21,401 - INFO - Sentimentos neutros: 3528
2024-11-30 19:59:21,401 - INFO - Sentimentos negativos: 4326
2024-11-30 19:59:21,408 - INFO - Amostra salva com sucesso.
2024-11-30 19:59:23,407 - INFO - Dataset salvo com sucesso.
2024-11-30 19:59:23,413 - INFO - Todos os blocos processados e combinados com sucesso.
2024-11-30 19:59:23,426 - INFO - Gerando relatórios.
2024-11-30 19:59:23,462 - INFO - Relatórios gerados com sucesso.
2024-12-01 07:25:01,615 - INFO - Carregando o dataset bruto.
2024-12-01 07:25:01,636 - INFO - Dataset carregado com sucesso com 40000 linhas.
2024-12-01 07:25:01,636 - INFO - Renomeando colunas.
2024-12-01 07:25:01,707 - INFO - Total de linhas a serem processadas: 40000
2024-12-01 07:25:01,707 - INFO - Total de blocos a serem processados: 8
2024-12-01 07:25:01,762 - INFO - Processando bloco 1 de 8
2024-12-01 07:25:01,762 - INFO - Pré-processando os dados.
2024-12-01 07:25:25,964 - INFO - Normalizando os textos.
2024-12-01 07:25:36,665 - INFO - Tokenizando os textos.
2024-12-01 07:26:00,631 - INFO - Criando bigramas.
2024-12-01 07:26:01,064 - INFO - Removendo stopwords.
2024-12-01 07:26:01,085 - INFO - Aplicando stemming.
2024-12-01 07:26:01,449 - INFO - Aplicando lematização.
2024-12-01 07:26:20,833 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-01 07:26:20,833 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-01 07:29:23,800 - INFO - Codificando sentimentos.
2024-12-01 07:29:23,802 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-01 07:29:23,879 - INFO - Bloco 1 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_1.parquet
2024-12-01 07:29:23,934 - INFO - Processando bloco 2 de 8
2024-12-01 07:29:23,935 - INFO - Pré-processando os dados.
2024-12-01 07:29:48,521 - INFO - Normalizando os textos.
2024-12-01 07:29:58,972 - INFO - Tokenizando os textos.
2024-12-01 07:30:21,895 - INFO - Criando bigramas.
2024-12-01 07:30:22,315 - INFO - Removendo stopwords.
2024-12-01 07:30:22,330 - INFO - Aplicando stemming.
2024-12-01 07:30:22,707 - INFO - Aplicando lematização.
2024-12-01 07:30:41,567 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-01 07:30:41,574 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-01 07:34:09,088 - INFO - Codificando sentimentos.
2024-12-01 07:34:09,091 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-01 07:34:09,187 - INFO - Bloco 2 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_2.parquet
2024-12-01 07:34:09,246 - INFO - Processando bloco 3 de 8
2024-12-01 07:34:09,246 - INFO - Pré-processando os dados.
2024-12-01 07:34:35,097 - INFO - Normalizando os textos.
2024-12-01 07:34:45,774 - INFO - Tokenizando os textos.
2024-12-01 07:35:07,536 - INFO - Criando bigramas.
2024-12-01 07:35:07,946 - INFO - Removendo stopwords.
2024-12-01 07:35:07,960 - INFO - Aplicando stemming.
2024-12-01 07:35:08,308 - INFO - Aplicando lematização.
2024-12-01 07:35:26,908 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-01 07:35:26,914 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-01 07:38:45,199 - INFO - Codificando sentimentos.
2024-12-01 07:38:45,200 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-01 07:38:45,278 - INFO - Bloco 3 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_3.parquet
2024-12-01 07:38:45,336 - INFO - Processando bloco 4 de 8
2024-12-01 07:38:45,336 - INFO - Pré-processando os dados.
2024-12-01 07:39:13,789 - INFO - Normalizando os textos.
2024-12-01 07:39:24,929 - INFO - Tokenizando os textos.
2024-12-01 07:39:49,100 - INFO - Criando bigramas.
2024-12-01 07:39:49,536 - INFO - Removendo stopwords.
2024-12-01 07:39:49,549 - INFO - Aplicando stemming.
2024-12-01 07:39:49,934 - INFO - Aplicando lematização.
2024-12-01 07:40:10,148 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-01 07:40:10,155 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-01 07:43:25,170 - INFO - Codificando sentimentos.
2024-12-01 07:43:25,171 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-01 07:43:25,243 - INFO - Bloco 4 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_4.parquet
2024-12-01 07:43:25,299 - INFO - Processando bloco 5 de 8
2024-12-01 07:43:25,300 - INFO - Pré-processando os dados.
2024-12-01 07:43:50,340 - INFO - Normalizando os textos.
2024-12-01 07:44:01,262 - INFO - Tokenizando os textos.
2024-12-01 07:44:22,497 - INFO - Criando bigramas.
2024-12-01 07:44:22,973 - INFO - Removendo stopwords.
2024-12-01 07:44:22,988 - INFO - Aplicando stemming.
2024-12-01 07:44:23,348 - INFO - Aplicando lematização.
2024-12-01 07:44:43,243 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-01 07:44:43,251 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-01 07:48:01,550 - INFO - Codificando sentimentos.
2024-12-01 07:48:01,551 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-01 07:48:01,621 - INFO - Bloco 5 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_5.parquet
2024-12-01 07:48:01,678 - INFO - Processando bloco 6 de 8
2024-12-01 07:48:01,678 - INFO - Pré-processando os dados.
2024-12-01 07:48:26,262 - INFO - Normalizando os textos.
2024-12-01 07:48:37,182 - INFO - Tokenizando os textos.
2024-12-01 07:49:04,074 - INFO - Criando bigramas.
2024-12-01 07:49:04,600 - INFO - Removendo stopwords.
2024-12-01 07:49:04,614 - INFO - Aplicando stemming.
2024-12-01 07:49:04,978 - INFO - Aplicando lematização.
2024-12-01 07:49:24,319 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-01 07:49:24,326 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-01 07:53:25,090 - INFO - Carregando o dataset bruto.
2024-12-01 07:53:25,123 - INFO - Dataset carregado com sucesso com 40000 linhas.
2024-12-01 07:53:25,124 - INFO - Renomeando colunas.
2024-12-01 07:53:25,179 - INFO - Total de linhas a serem processadas: 40000
2024-12-01 07:53:25,179 - INFO - Total de blocos a serem processados: 8
2024-12-01 07:53:25,223 - INFO - Processando bloco 1 de 8
2024-12-01 07:53:25,224 - INFO - Pré-processando os dados.
2024-12-01 07:53:48,973 - INFO - Normalizando os textos.
2024-12-01 07:53:59,673 - INFO - Tokenizando os textos.
2024-12-01 07:54:23,896 - INFO - Criando bigramas.
2024-12-01 07:54:24,358 - INFO - Removendo stopwords.
2024-12-01 07:54:24,381 - INFO - Aplicando stemming.
2024-12-01 07:54:24,759 - INFO - Aplicando lematização.
2024-12-01 07:54:44,526 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-01 07:54:44,526 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-01 07:58:02,133 - INFO - Codificando sentimentos.
2024-12-01 07:58:02,137 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-01 07:58:02,232 - INFO - Bloco 1 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_1.parquet
2024-12-01 07:58:02,326 - INFO - Processando bloco 2 de 8
2024-12-01 07:58:02,326 - INFO - Pré-processando os dados.
2024-12-01 07:58:26,892 - INFO - Normalizando os textos.
2024-12-01 07:58:37,695 - INFO - Tokenizando os textos.
2024-12-01 07:59:01,002 - INFO - Criando bigramas.
2024-12-01 07:59:01,435 - INFO - Removendo stopwords.
2024-12-01 07:59:01,452 - INFO - Aplicando stemming.
2024-12-01 07:59:01,802 - INFO - Aplicando lematização.
2024-12-01 07:59:20,569 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-01 07:59:20,590 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-01 08:01:34,300 - INFO - Carregando o dataset bruto.
2024-12-01 08:01:34,334 - INFO - Dataset carregado com sucesso com 40000 linhas.
2024-12-01 08:01:34,334 - INFO - Renomeando colunas.
2024-12-01 08:01:34,400 - INFO - Total de linhas a serem processadas: 40000
2024-12-01 08:01:34,400 - INFO - Total de blocos a serem processados: 8
2024-12-01 08:01:34,456 - INFO - Processando bloco 1 de 8
2024-12-01 08:01:34,456 - INFO - Pré-processando os dados.
2024-12-01 08:01:59,061 - INFO - Normalizando os textos.
2024-12-01 08:02:09,879 - INFO - Tokenizando os textos.
2024-12-01 08:02:32,916 - INFO - Criando bigramas.
2024-12-01 08:02:33,343 - INFO - Removendo stopwords.
2024-12-01 08:02:33,360 - INFO - Aplicando stemming.
2024-12-01 08:02:33,725 - INFO - Aplicando lematização.
2024-12-01 08:02:54,150 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-01 08:02:54,150 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-01 08:06:17,043 - INFO - Codificando sentimentos.
2024-12-01 08:06:17,045 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-01 08:06:17,126 - INFO - Bloco 1 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_1.parquet
2024-12-01 08:06:17,127 - INFO - Tempo médio por bloco: 282.65 segundos
2024-12-01 08:06:17,127 - INFO - Tempo total estimado: 2261.20 segundos
2024-12-01 08:06:17,180 - INFO - Processando bloco 2 de 8
2024-12-01 08:06:17,180 - INFO - Pré-processando os dados.
2024-12-01 08:06:41,512 - INFO - Normalizando os textos.
2024-12-01 08:06:52,762 - INFO - Tokenizando os textos.
2024-12-01 08:07:16,220 - INFO - Criando bigramas.
2024-12-01 08:07:16,646 - INFO - Removendo stopwords.
2024-12-01 08:07:16,646 - INFO - Aplicando stemming.
2024-12-01 08:07:17,028 - INFO - Aplicando lematização.
2024-12-01 08:07:41,428 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-01 08:07:41,428 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-01 08:08:18,948 - INFO - Carregando o dataset bruto.
2024-12-01 08:08:18,979 - INFO - Dataset carregado com sucesso com 40000 linhas.
2024-12-01 08:08:18,979 - INFO - Renomeando colunas.
2024-12-01 08:08:19,033 - INFO - Total de linhas a serem processadas: 40000
2024-12-01 08:08:19,033 - INFO - Total de blocos a serem processados: 8
2024-12-01 08:08:19,082 - INFO - Processando bloco 1 de 8
2024-12-01 08:08:19,083 - INFO - Pré-processando os dados.
2024-12-01 08:08:45,868 - INFO - Normalizando os textos.
2024-12-01 08:08:58,943 - INFO - Tokenizando os textos.
2024-12-01 08:09:28,830 - INFO - Criando bigramas.
2024-12-01 08:09:29,276 - INFO - Removendo stopwords.
2024-12-01 08:09:29,292 - INFO - Aplicando stemming.
2024-12-01 08:09:29,646 - INFO - Aplicando lematização.
2024-12-01 08:09:56,113 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-01 08:09:56,129 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-01 08:13:14,555 - INFO - Codificando sentimentos.
2024-12-01 08:13:14,558 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-01 08:13:14,641 - INFO - Bloco 1 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_1.parquet
2024-12-01 08:13:14,642 - INFO - Tempo médio por bloco: 0 horas, 4 minutos, 55.53 segundos
2024-12-01 08:13:14,643 - INFO - Tempo total estimado: 0 horas, 39 minutos, 24.24 segundos
2024-12-01 08:13:14,710 - INFO - Processando bloco 2 de 8
2024-12-01 08:13:14,711 - INFO - Pré-processando os dados.
2024-12-01 08:13:43,194 - INFO - Normalizando os textos.
2024-12-01 08:13:57,072 - INFO - Tokenizando os textos.
2024-12-01 08:14:19,971 - INFO - Criando bigramas.
2024-12-01 08:14:20,406 - INFO - Removendo stopwords.
2024-12-01 08:14:20,426 - INFO - Aplicando stemming.
2024-12-01 08:14:20,847 - INFO - Aplicando lematização.
2024-12-01 08:14:38,576 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-01 08:14:38,595 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-01 08:17:58,354 - INFO - Codificando sentimentos.
2024-12-01 08:17:58,354 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-01 08:17:58,436 - INFO - Bloco 2 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_2.parquet
2024-12-01 08:17:58,509 - INFO - Processando bloco 3 de 8
2024-12-01 08:17:58,509 - INFO - Pré-processando os dados.
2024-12-01 08:18:23,552 - INFO - Normalizando os textos.
2024-12-01 08:18:34,768 - INFO - Tokenizando os textos.
2024-12-01 08:18:58,968 - INFO - Criando bigramas.
2024-12-01 08:18:59,485 - INFO - Removendo stopwords.
2024-12-01 08:18:59,502 - INFO - Aplicando stemming.
2024-12-01 08:18:59,917 - INFO - Aplicando lematização.
2024-12-01 08:19:19,935 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-01 08:19:19,951 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-01 08:22:33,098 - INFO - Codificando sentimentos.
2024-12-01 08:22:33,098 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-01 08:22:33,165 - INFO - Bloco 3 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_3.parquet
2024-12-01 08:22:33,238 - INFO - Processando bloco 4 de 8
2024-12-01 08:22:33,238 - INFO - Pré-processando os dados.
2024-12-01 08:22:59,967 - INFO - Normalizando os textos.
2024-12-01 08:23:11,135 - INFO - Tokenizando os textos.
2024-12-01 08:23:32,691 - INFO - Criando bigramas.
2024-12-01 08:23:33,123 - INFO - Removendo stopwords.
2024-12-01 08:23:33,131 - INFO - Aplicando stemming.
2024-12-01 08:23:33,476 - INFO - Aplicando lematização.
2024-12-01 08:23:50,892 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-01 08:23:50,892 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-01 08:27:01,694 - INFO - Codificando sentimentos.
2024-12-01 08:27:01,694 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-01 08:27:01,761 - INFO - Bloco 4 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_4.parquet
2024-12-01 08:27:01,831 - INFO - Processando bloco 5 de 8
2024-12-01 08:27:01,831 - INFO - Pré-processando os dados.
2024-12-01 08:27:26,561 - INFO - Normalizando os textos.
2024-12-01 08:27:37,728 - INFO - Tokenizando os textos.
2024-12-01 08:27:59,544 - INFO - Criando bigramas.
2024-12-01 08:27:59,977 - INFO - Removendo stopwords.
2024-12-01 08:27:59,977 - INFO - Aplicando stemming.
2024-12-01 08:28:00,344 - INFO - Aplicando lematização.
2024-12-01 08:28:19,429 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-01 08:28:19,429 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-01 08:31:22,816 - INFO - Codificando sentimentos.
2024-12-01 08:31:22,816 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-01 08:31:22,879 - INFO - Bloco 5 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_5.parquet
2024-12-01 08:31:22,925 - INFO - Processando bloco 6 de 8
2024-12-01 08:31:22,925 - INFO - Pré-processando os dados.
2024-12-01 08:31:47,581 - INFO - Normalizando os textos.
2024-12-01 08:31:58,562 - INFO - Tokenizando os textos.
2024-12-01 08:32:21,441 - INFO - Criando bigramas.
2024-12-01 08:32:21,896 - INFO - Removendo stopwords.
2024-12-01 08:32:21,915 - INFO - Aplicando stemming.
2024-12-01 08:32:22,308 - INFO - Aplicando lematização.
2024-12-01 08:32:41,040 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-01 08:32:41,047 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-01 08:35:57,570 - INFO - Codificando sentimentos.
2024-12-01 08:35:57,570 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-01 08:35:57,638 - INFO - Bloco 6 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_6.parquet
2024-12-01 08:35:57,709 - INFO - Processando bloco 7 de 8
2024-12-01 08:35:57,709 - INFO - Pré-processando os dados.
2024-12-01 08:36:22,320 - INFO - Normalizando os textos.
2024-12-01 08:36:33,370 - INFO - Tokenizando os textos.
2024-12-01 08:36:55,453 - INFO - Criando bigramas.
2024-12-01 08:36:55,869 - INFO - Removendo stopwords.
2024-12-01 08:36:55,891 - INFO - Aplicando stemming.
2024-12-01 08:36:56,236 - INFO - Aplicando lematização.
2024-12-01 08:37:14,606 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-01 08:37:14,606 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-01 08:40:22,132 - INFO - Codificando sentimentos.
2024-12-01 08:40:22,133 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-01 08:40:22,200 - INFO - Bloco 7 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_7.parquet
2024-12-01 08:40:22,268 - INFO - Processando bloco 8 de 8
2024-12-01 08:40:22,268 - INFO - Pré-processando os dados.
2024-12-01 08:40:47,050 - INFO - Normalizando os textos.
2024-12-01 08:40:58,117 - INFO - Tokenizando os textos.
2024-12-01 08:41:19,966 - INFO - Criando bigramas.
2024-12-01 08:41:20,382 - INFO - Removendo stopwords.
2024-12-01 08:41:20,399 - INFO - Aplicando stemming.
2024-12-01 08:41:20,766 - INFO - Aplicando lematização.
2024-12-01 08:41:39,299 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-01 08:41:39,299 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-01 08:44:46,513 - INFO - Codificando sentimentos.
2024-12-01 08:44:46,513 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-01 08:44:46,599 - INFO - Bloco 8 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_8.parquet
2024-12-01 08:44:46,599 - INFO - Tempo médio por bloco (recalculado): 0 horas, 4 minutos, 33.37 segundos
2024-12-01 08:44:46,599 - INFO - Tempo total estimado (recalculado): 0 horas, 36 minutos, 26.99 segundos
2024-12-01 08:44:46,599 - INFO - Salvando dataset processado.
2024-12-01 08:44:46,896 - INFO - Número de linhas com NaN em 'sentimento_codificado' antes da exclusão: 0
2024-12-01 08:44:46,915 - INFO - Número de linhas restantes após a remoção de NaNs: 36691
2024-12-01 08:44:46,915 - INFO - Contando sentimentos positivos, neutros e negativos.
2024-12-01 08:44:46,918 - INFO - Sentimentos positivos: 6101
2024-12-01 08:44:46,918 - INFO - Sentimentos neutros: 13896
2024-12-01 08:44:46,918 - INFO - Sentimentos negativos: 16694
2024-12-01 08:44:46,930 - INFO - Amostra salva com sucesso.
2024-12-01 08:44:52,593 - INFO - Dataset salvo com sucesso.
2024-12-01 08:44:52,617 - INFO - Todos os blocos processados e combinados com sucesso.
2024-12-01 08:44:52,623 - INFO - Gerando relatórios.
2024-12-01 08:44:52,679 - INFO - Relatórios gerados com sucesso.
2024-12-01 12:57:01,867 - INFO - Carregando o dataset bruto.
2024-12-01 12:57:01,885 - INFO - Dataset carregado com sucesso com 20000 linhas.
2024-12-01 12:57:01,885 - INFO - Renomeando colunas.
2024-12-01 12:57:01,919 - INFO - Total de linhas a serem processadas: 20000
2024-12-01 12:57:01,919 - INFO - Total de blocos a serem processados: 4
2024-12-01 12:57:01,951 - INFO - Processando bloco 1 de 4
2024-12-01 12:57:01,951 - INFO - Pré-processando os dados.
2024-12-01 12:57:44,532 - INFO - Normalizando os textos.
2024-12-01 12:58:02,585 - INFO - Tokenizando os textos.
2024-12-01 12:58:33,169 - INFO - Criando bigramas.
2024-12-01 12:58:33,656 - INFO - Removendo stopwords.
2024-12-01 12:58:33,672 - INFO - Aplicando stemming.
2024-12-01 12:58:34,060 - INFO - Aplicando lematização.
2024-12-01 12:59:02,568 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-01 12:59:02,574 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-01 13:04:01,637 - INFO - Codificando sentimentos.
2024-12-01 13:04:01,639 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-01 13:04:01,747 - INFO - Bloco 1 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_1.parquet
2024-12-01 13:04:01,748 - INFO - Tempo médio por bloco: 0 horas, 6 minutos, 59.73 segundos
2024-12-01 13:04:01,749 - INFO - Tempo total estimado: 0 horas, 27 minutos, 58.91 segundos
2024-12-01 13:04:01,796 - INFO - Processando bloco 2 de 4
2024-12-01 13:04:01,796 - INFO - Pré-processando os dados.
2024-12-01 13:04:31,638 - INFO - Normalizando os textos.
2024-12-01 13:04:42,928 - INFO - Tokenizando os textos.
2024-12-01 13:05:08,371 - INFO - Criando bigramas.
2024-12-01 13:05:08,852 - INFO - Removendo stopwords.
2024-12-01 13:05:08,868 - INFO - Aplicando stemming.
2024-12-01 13:05:09,272 - INFO - Aplicando lematização.
2024-12-01 13:05:33,493 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-01 13:05:33,498 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-01 13:08:42,028 - INFO - Codificando sentimentos.
2024-12-01 13:08:42,029 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-01 13:08:42,100 - INFO - Bloco 2 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_2.parquet
2024-12-01 13:08:42,138 - INFO - Processando bloco 3 de 4
2024-12-01 13:08:42,138 - INFO - Pré-processando os dados.
2024-12-01 13:09:07,265 - INFO - Normalizando os textos.
2024-12-01 13:09:18,131 - INFO - Tokenizando os textos.
2024-12-01 13:09:40,526 - INFO - Criando bigramas.
2024-12-01 13:09:40,931 - INFO - Removendo stopwords.
2024-12-01 13:09:40,946 - INFO - Aplicando stemming.
2024-12-01 13:09:41,297 - INFO - Aplicando lematização.
2024-12-01 13:09:59,436 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-01 13:09:59,455 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-01 13:13:05,527 - INFO - Codificando sentimentos.
2024-12-01 13:13:05,529 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-01 13:13:05,602 - INFO - Bloco 3 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_3.parquet
2024-12-01 13:13:05,644 - INFO - Processando bloco 4 de 4
2024-12-01 13:13:05,644 - INFO - Pré-processando os dados.
2024-12-01 13:13:31,764 - INFO - Normalizando os textos.
2024-12-01 13:13:42,539 - INFO - Tokenizando os textos.
2024-12-01 13:14:03,891 - INFO - Criando bigramas.
2024-12-01 13:14:04,293 - INFO - Removendo stopwords.
2024-12-01 13:14:04,307 - INFO - Aplicando stemming.
2024-12-01 13:14:04,652 - INFO - Aplicando lematização.
2024-12-01 13:14:22,665 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-01 13:14:22,670 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-01 13:17:23,413 - INFO - Codificando sentimentos.
2024-12-01 13:17:23,414 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-01 13:17:23,485 - INFO - Bloco 4 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_4.parquet
2024-12-01 13:17:23,486 - INFO - Tempo médio por bloco (recalculado): 0 horas, 5 minutos, 5.32 segundos
2024-12-01 13:17:23,486 - INFO - Tempo total estimado (recalculado): 0 horas, 20 minutos, 21.26 segundos
2024-12-01 13:17:23,494 - INFO - Salvando dataset processado.
2024-12-01 13:17:23,653 - INFO - Número de linhas com NaN em 'sentimento_codificado' antes da exclusão: 0
2024-12-01 13:17:23,659 - INFO - Número de linhas restantes após a remoção de NaNs: 18318
2024-12-01 13:17:23,660 - INFO - Contando sentimentos positivos, neutros e negativos.
2024-12-01 13:17:23,663 - INFO - Sentimentos positivos: 2881
2024-12-01 13:17:23,664 - INFO - Sentimentos neutros: 6900
2024-12-01 13:17:23,664 - INFO - Sentimentos negativos: 8537
2024-12-01 13:17:23,672 - INFO - Amostra salva com sucesso.
2024-12-01 13:17:26,564 - INFO - Dataset salvo com sucesso.
2024-12-01 13:17:26,575 - INFO - Todos os blocos processados e combinados com sucesso.
2024-12-01 13:17:26,581 - INFO - Gerando relatórios.
2024-12-01 13:17:26,615 - INFO - Relatórios gerados com sucesso.
2024-12-01 14:00:30,432 - INFO - Carregando o dataset bruto.
2024-12-01 14:00:30,487 - INFO - Dataset carregado com sucesso com 1599999 linhas.
2024-12-01 14:00:30,488 - INFO - Renomeando colunas.
2024-12-01 14:00:32,894 - INFO - Total de linhas a serem processadas: 1599999
2024-12-01 14:00:32,895 - INFO - Total de blocos a serem processados: 320
2024-12-01 14:01:10,686 - INFO - Carregando o dataset bruto.
2024-12-01 14:01:10,706 - INFO - Dataset carregado com sucesso com 3000 linhas.
2024-12-01 14:01:10,707 - INFO - Renomeando colunas.
2024-12-01 14:01:10,716 - INFO - Total de linhas a serem processadas: 3000
2024-12-01 14:01:10,716 - INFO - Total de blocos a serem processados: 1
2024-12-01 14:01:10,725 - INFO - Processando bloco 1 de 1
2024-12-01 14:01:10,725 - INFO - Pré-processando os dados.
2024-12-01 14:01:26,522 - INFO - Normalizando os textos.
2024-12-01 14:01:36,582 - INFO - Tokenizando os textos.
2024-12-01 14:01:50,612 - INFO - Criando bigramas.
2024-12-01 14:01:50,884 - INFO - Removendo stopwords.
2024-12-01 14:01:50,894 - INFO - Aplicando stemming.
2024-12-01 14:01:51,119 - INFO - Aplicando lematização.
2024-12-01 14:02:02,235 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-01 14:02:02,238 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-01 14:04:14,959 - INFO - Codificando sentimentos.
2024-12-01 14:04:14,960 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-01 14:04:15,028 - INFO - Bloco 1 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_1.parquet
2024-12-01 14:04:15,029 - INFO - Tempo médio por bloco: 0 horas, 3 minutos, 4.25 segundos
2024-12-01 14:04:15,029 - INFO - Tempo total estimado: 0 horas, 3 minutos, 4.25 segundos
2024-12-01 14:04:15,029 - INFO - Tempo médio por bloco (recalculado): 0 horas, 3 minutos, 4.25 segundos
2024-12-01 14:04:15,030 - INFO - Tempo total estimado (recalculado): 0 horas, 3 minutos, 4.25 segundos
2024-12-01 14:04:15,042 - INFO - Salvando dataset processado.
2024-12-01 14:04:15,096 - INFO - Número de linhas com NaN em 'sentimento_codificado' antes da exclusão: 0
2024-12-01 14:04:15,099 - INFO - Número de linhas restantes após a remoção de NaNs: 2731
2024-12-01 14:04:15,099 - INFO - Contando sentimentos positivos, neutros e negativos.
2024-12-01 14:04:15,102 - INFO - Sentimentos positivos: 403
2024-12-01 14:04:15,102 - INFO - Sentimentos neutros: 990
2024-12-01 14:04:15,103 - INFO - Sentimentos negativos: 1338
2024-12-01 14:04:15,114 - INFO - Amostra salva com sucesso.
2024-12-01 14:04:15,671 - INFO - Dataset salvo com sucesso.
2024-12-01 14:04:15,676 - INFO - Todos os blocos processados e combinados com sucesso.
2024-12-01 14:04:15,683 - INFO - Gerando relatórios.
2024-12-01 14:04:15,706 - INFO - Relatórios gerados com sucesso.
2024-12-02 10:16:52,243 - INFO - Carregando o dataset bruto.
2024-12-02 10:16:52,265 - INFO - Dataset carregado com sucesso com 500 linhas.
2024-12-02 10:16:52,265 - INFO - Renomeando colunas.
2024-12-02 10:16:52,276 - INFO - Total de linhas a serem processadas: 500
2024-12-02 10:16:52,276 - INFO - Total de blocos a serem processados: 1
2024-12-02 10:16:52,282 - INFO - Processando bloco 1 de 1
2024-12-02 10:16:52,283 - INFO - Pré-processando os dados.
2024-12-02 10:16:54,911 - INFO - Normalizando os textos.
2024-12-02 10:16:55,976 - INFO - Tokenizando os textos.
2024-12-02 10:16:58,285 - INFO - Criando bigramas.
2024-12-02 10:16:58,332 - INFO - Removendo stopwords.
2024-12-02 10:16:58,332 - INFO - Aplicando stemming.
2024-12-02 10:16:58,380 - INFO - Aplicando lematização.
2024-12-02 10:17:00,143 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-02 10:17:00,143 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-02 10:17:15,484 - INFO - Codificando sentimentos.
2024-12-02 10:17:15,485 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-02 10:17:15,497 - INFO - Bloco 1 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_1.parquet
2024-12-02 10:17:15,497 - INFO - Tempo médio por bloco: 0 horas, 0 minutos, 23.21 segundos
2024-12-02 10:17:15,497 - INFO - Tempo total estimado: 0 horas, 0 minutos, 23.21 segundos
2024-12-02 10:17:15,497 - INFO - Tempo médio por bloco (recalculado): 0 horas, 0 minutos, 23.21 segundos
2024-12-02 10:17:15,497 - INFO - Tempo total estimado (recalculado): 0 horas, 0 minutos, 23.21 segundos
2024-12-02 10:17:15,507 - INFO - Salvando dataset processado.
2024-12-02 10:17:15,518 - INFO - Número de linhas com NaN em 'sentimento_codificado' antes da exclusão: 0
2024-12-02 10:17:15,520 - INFO - Número de linhas restantes após a remoção de NaNs: 460
2024-12-02 10:17:15,520 - INFO - Contando sentimentos positivos, neutros e negativos.
2024-12-02 10:17:15,522 - INFO - Sentimentos positivos: 64
2024-12-02 10:17:15,522 - INFO - Sentimentos neutros: 165
2024-12-02 10:17:15,522 - INFO - Sentimentos negativos: 231
2024-12-02 10:17:15,528 - INFO - Amostra salva com sucesso.
2024-12-02 10:17:15,609 - INFO - Dataset salvo com sucesso.
2024-12-02 10:17:15,609 - INFO - Todos os blocos processados e combinados com sucesso.
2024-12-02 10:17:15,609 - INFO - Gerando relatórios.
2024-12-02 10:17:15,609 - INFO - Relatórios gerados com sucesso.
2024-12-02 11:11:02,307 - INFO - Carregando o dataset bruto.
2024-12-02 11:11:02,329 - INFO - Dataset carregado com sucesso com 20000 linhas.
2024-12-02 11:11:02,329 - INFO - Renomeando colunas.
2024-12-02 11:11:02,374 - INFO - Total de linhas a serem processadas: 20000
2024-12-02 11:11:02,374 - INFO - Total de blocos a serem processados: 4
2024-12-02 11:11:02,397 - INFO - Processando bloco 1 de 4
2024-12-02 11:11:02,397 - INFO - Pré-processando os dados.
2024-12-02 11:11:26,240 - INFO - Normalizando os textos.
2024-12-02 11:11:38,490 - INFO - Tokenizando os textos.
2024-12-02 11:12:01,218 - INFO - Criando bigramas.
2024-12-02 11:12:01,648 - INFO - Removendo stopwords.
2024-12-02 11:12:01,661 - INFO - Aplicando stemming.
2024-12-02 11:12:02,018 - INFO - Aplicando lematização.
2024-12-02 11:12:20,399 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-02 11:12:20,403 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-02 11:15:56,366 - INFO - Codificando sentimentos.
2024-12-02 11:15:56,368 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-02 11:15:56,447 - INFO - Bloco 1 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_1.parquet
2024-12-02 11:15:56,447 - INFO - Tempo médio por bloco: 0 horas, 4 minutos, 54.00 segundos
2024-12-02 11:15:56,448 - INFO - Tempo total estimado: 0 horas, 19 minutos, 35.99 segundos
2024-12-02 11:15:56,494 - INFO - Processando bloco 2 de 4
2024-12-02 11:15:56,495 - INFO - Pré-processando os dados.
2024-12-02 11:16:24,106 - INFO - Normalizando os textos.
2024-12-02 11:16:35,793 - INFO - Tokenizando os textos.
2024-12-02 11:16:59,642 - INFO - Criando bigramas.
2024-12-02 11:17:00,086 - INFO - Removendo stopwords.
2024-12-02 11:17:00,098 - INFO - Aplicando stemming.
2024-12-02 11:17:00,494 - INFO - Aplicando lematização.
2024-12-02 11:17:19,540 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-02 11:17:19,545 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-02 11:20:35,267 - INFO - Codificando sentimentos.
2024-12-02 11:20:35,270 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-02 11:20:35,342 - INFO - Bloco 2 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_2.parquet
2024-12-02 11:20:35,386 - INFO - Processando bloco 3 de 4
2024-12-02 11:20:35,387 - INFO - Pré-processando os dados.
2024-12-02 11:21:02,253 - INFO - Normalizando os textos.
2024-12-02 11:21:13,781 - INFO - Tokenizando os textos.
2024-12-02 11:21:36,774 - INFO - Criando bigramas.
2024-12-02 11:21:37,212 - INFO - Removendo stopwords.
2024-12-02 11:21:37,224 - INFO - Aplicando stemming.
2024-12-02 11:21:37,597 - INFO - Aplicando lematização.
2024-12-02 11:21:56,650 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-02 11:21:56,655 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-02 11:24:55,219 - INFO - Codificando sentimentos.
2024-12-02 11:24:55,221 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-02 11:24:55,296 - INFO - Bloco 3 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_3.parquet
2024-12-02 11:24:55,336 - INFO - Processando bloco 4 de 4
2024-12-02 11:24:55,336 - INFO - Pré-processando os dados.
2024-12-02 11:25:23,048 - INFO - Normalizando os textos.
2024-12-02 11:25:34,413 - INFO - Tokenizando os textos.
2024-12-02 11:25:57,035 - INFO - Criando bigramas.
2024-12-02 11:25:57,470 - INFO - Removendo stopwords.
2024-12-02 11:25:57,484 - INFO - Aplicando stemming.
2024-12-02 11:25:57,853 - INFO - Aplicando lematização.
2024-12-02 11:26:16,452 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-02 11:26:16,461 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-02 11:29:13,319 - INFO - Codificando sentimentos.
2024-12-02 11:29:13,321 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-02 11:29:13,393 - INFO - Bloco 4 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_4.parquet
2024-12-02 11:29:13,394 - INFO - Tempo médio por bloco (recalculado): 0 horas, 4 minutos, 32.68 segundos
2024-12-02 11:29:13,394 - INFO - Tempo total estimado (recalculado): 0 horas, 18 minutos, 10.74 segundos
2024-12-02 11:29:13,403 - INFO - Salvando dataset processado.
2024-12-02 11:29:13,579 - INFO - Número de linhas com NaN em 'sentimento_codificado' antes da exclusão: 0
2024-12-02 11:29:13,586 - INFO - Número de linhas restantes após a remoção de NaNs: 18303
2024-12-02 11:29:13,587 - INFO - Contando sentimentos positivos, neutros e negativos.
2024-12-02 11:29:13,589 - INFO - Sentimentos positivos: 2878
2024-12-02 11:29:13,590 - INFO - Sentimentos neutros: 6897
2024-12-02 11:29:13,590 - INFO - Sentimentos negativos: 8528
2024-12-02 11:29:13,596 - INFO - Amostra salva com sucesso.
2024-12-02 11:29:16,643 - INFO - Dataset salvo com sucesso.
2024-12-02 11:29:16,655 - INFO - Todos os blocos processados e combinados com sucesso.
2024-12-02 11:29:16,660 - INFO - Gerando relatórios.
2024-12-02 11:29:16,693 - INFO - Relatórios gerados com sucesso.
2024-12-02 21:42:30,636 - INFO - Carregando o dataset bruto.
2024-12-02 21:42:30,658 - INFO - Dataset carregado com sucesso com 10000 linhas.
2024-12-02 21:42:30,658 - INFO - Renomeando colunas.
2024-12-02 21:42:30,670 - INFO - Total de linhas a serem processadas: 10000
2024-12-02 21:42:30,670 - INFO - Total de blocos a serem processados: 2
2024-12-02 21:42:30,691 - INFO - Processando bloco 1 de 2
2024-12-02 21:42:30,691 - INFO - Pré-processando os dados.
2024-12-02 21:42:55,718 - INFO - Normalizando os textos.
2024-12-02 21:43:06,818 - INFO - Tokenizando os textos.
2024-12-02 21:43:29,254 - INFO - Criando bigramas.
2024-12-02 21:43:29,684 - INFO - Removendo stopwords.
2024-12-02 21:43:29,684 - INFO - Aplicando stemming.
2024-12-02 21:43:30,051 - INFO - Aplicando lematização.
2024-12-02 21:43:48,783 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-02 21:43:48,784 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-02 21:46:49,663 - INFO - Codificando sentimentos.
2024-12-02 21:46:49,663 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-02 21:46:49,746 - INFO - Bloco 1 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_1.parquet
2024-12-02 21:46:49,746 - INFO - Tempo médio por bloco: 0 horas, 4 minutos, 18.99 segundos
2024-12-02 21:46:49,746 - INFO - Tempo total estimado: 0 horas, 8 minutos, 37.99 segundos
2024-12-02 21:46:49,768 - INFO - Processando bloco 2 de 2
2024-12-02 21:46:49,768 - INFO - Pré-processando os dados.
2024-12-02 21:47:15,246 - INFO - Normalizando os textos.
2024-12-02 21:47:27,196 - INFO - Tokenizando os textos.
2024-12-02 21:47:50,679 - INFO - Criando bigramas.
2024-12-02 21:47:51,128 - INFO - Removendo stopwords.
2024-12-02 21:47:51,129 - INFO - Aplicando stemming.
2024-12-02 21:47:51,529 - INFO - Aplicando lematização.
2024-12-02 21:48:10,928 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-02 21:48:10,928 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-02 21:51:12,607 - INFO - Codificando sentimentos.
2024-12-02 21:51:12,607 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-02 21:51:12,674 - INFO - Bloco 2 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_2.parquet
2024-12-02 21:51:12,674 - INFO - Tempo médio por bloco (recalculado): 0 horas, 4 minutos, 20.93 segundos
2024-12-02 21:51:12,674 - INFO - Tempo total estimado (recalculado): 0 horas, 8 minutos, 41.85 segundos
2024-12-02 21:51:12,691 - INFO - Salvando dataset processado.
2024-12-02 21:51:12,774 - INFO - Número de linhas com NaN em 'sentimento_codificado' antes da exclusão: 0
2024-12-02 21:51:12,774 - INFO - Número de linhas restantes após a remoção de NaNs: 9219
2024-12-02 21:51:12,774 - INFO - Contando sentimentos positivos, neutros e negativos.
2024-12-02 21:51:12,774 - INFO - Sentimentos positivos: 1347
2024-12-02 21:51:12,774 - INFO - Sentimentos neutros: 3527
2024-12-02 21:51:12,790 - INFO - Sentimentos negativos: 4345
2024-12-02 21:51:12,796 - INFO - Amostra salva com sucesso.
2024-12-02 21:51:14,291 - INFO - Dataset salvo com sucesso.
2024-12-02 21:51:14,291 - INFO - Todos os blocos processados e combinados com sucesso.
2024-12-02 21:51:14,304 - INFO - Gerando relatórios.
2024-12-02 21:51:14,326 - INFO - Relatórios gerados com sucesso.
2024-12-03 04:30:53,832 - INFO - Carregando o dataset bruto.
2024-12-03 04:30:53,854 - INFO - Dataset carregado com sucesso com 50000 linhas.
2024-12-03 04:30:53,865 - INFO - Renomeando colunas.
2024-12-03 04:30:53,933 - INFO - Total de linhas a serem processadas: 50000
2024-12-03 04:30:53,933 - INFO - Total de blocos a serem processados: 10
2024-12-03 04:30:53,988 - INFO - Processando bloco 1 de 10
2024-12-03 04:30:53,988 - INFO - Pré-processando os dados.
2024-12-03 04:31:16,881 - INFO - Normalizando os textos.
2024-12-03 04:31:27,314 - INFO - Tokenizando os textos.
2024-12-03 04:31:49,343 - INFO - Criando bigramas.
2024-12-03 04:31:49,747 - INFO - Removendo stopwords.
2024-12-03 04:31:49,768 - INFO - Aplicando stemming.
2024-12-03 04:31:50,114 - INFO - Aplicando lematização.
2024-12-03 04:32:07,897 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-03 04:32:07,916 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-03 04:35:03,943 - INFO - Codificando sentimentos.
2024-12-03 04:35:03,948 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-03 04:35:04,011 - INFO - Bloco 1 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_1.parquet
2024-12-03 04:35:04,011 - INFO - Tempo médio por bloco: 0 horas, 4 minutos, 10.01 segundos
2024-12-03 04:35:04,011 - INFO - Tempo total estimado: 0 horas, 41 minutos, 40.15 segundos
2024-12-03 04:35:04,094 - INFO - Processando bloco 2 de 10
2024-12-03 04:35:04,094 - INFO - Pré-processando os dados.
2024-12-03 04:35:28,493 - INFO - Normalizando os textos.
2024-12-03 04:35:39,693 - INFO - Tokenizando os textos.
2024-12-03 04:36:01,342 - INFO - Criando bigramas.
2024-12-03 04:36:01,759 - INFO - Removendo stopwords.
2024-12-03 04:36:01,781 - INFO - Aplicando stemming.
2024-12-03 04:36:02,142 - INFO - Aplicando lematização.
2024-12-03 04:36:19,908 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-03 04:36:19,908 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-03 04:39:18,154 - INFO - Codificando sentimentos.
2024-12-03 04:39:18,154 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-03 04:39:18,238 - INFO - Bloco 2 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_2.parquet
2024-12-03 04:39:18,306 - INFO - Processando bloco 3 de 10
2024-12-03 04:39:18,306 - INFO - Pré-processando os dados.
2024-12-03 04:39:43,404 - INFO - Normalizando os textos.
2024-12-03 04:39:54,271 - INFO - Tokenizando os textos.
2024-12-03 04:40:15,754 - INFO - Criando bigramas.
2024-12-03 04:40:16,170 - INFO - Removendo stopwords.
2024-12-03 04:40:16,192 - INFO - Aplicando stemming.
2024-12-03 04:40:16,553 - INFO - Aplicando lematização.
2024-12-03 04:40:34,172 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-03 04:40:34,172 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-03 04:43:30,819 - INFO - Codificando sentimentos.
2024-12-03 04:43:30,821 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-03 04:43:30,884 - INFO - Bloco 3 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_3.parquet
2024-12-03 04:43:30,967 - INFO - Processando bloco 4 de 10
2024-12-03 04:43:30,967 - INFO - Pré-processando os dados.
2024-12-03 04:43:57,065 - INFO - Normalizando os textos.
2024-12-03 04:44:07,815 - INFO - Tokenizando os textos.
2024-12-03 04:44:28,865 - INFO - Criando bigramas.
2024-12-03 04:44:29,265 - INFO - Removendo stopwords.
2024-12-03 04:44:29,283 - INFO - Aplicando stemming.
2024-12-03 04:44:29,631 - INFO - Aplicando lematização.
2024-12-03 04:44:47,131 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-03 04:44:47,131 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-03 04:47:42,511 - INFO - Codificando sentimentos.
2024-12-03 04:47:42,511 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-03 04:47:42,579 - INFO - Bloco 4 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_4.parquet
2024-12-03 04:47:42,646 - INFO - Processando bloco 5 de 10
2024-12-03 04:47:42,646 - INFO - Pré-processando os dados.
2024-12-03 04:48:07,844 - INFO - Normalizando os textos.
2024-12-03 04:48:18,810 - INFO - Tokenizando os textos.
2024-12-03 04:48:40,110 - INFO - Criando bigramas.
2024-12-03 04:48:40,525 - INFO - Removendo stopwords.
2024-12-03 04:48:40,526 - INFO - Aplicando stemming.
2024-12-03 04:48:40,909 - INFO - Aplicando lematização.
2024-12-03 04:48:58,726 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-03 04:48:58,726 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-03 04:51:57,239 - INFO - Codificando sentimentos.
2024-12-03 04:51:57,239 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-03 04:51:57,322 - INFO - Bloco 5 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_5.parquet
2024-12-03 04:51:57,415 - INFO - Processando bloco 6 de 10
2024-12-03 04:51:57,416 - INFO - Pré-processando os dados.
2024-12-03 04:52:22,572 - INFO - Normalizando os textos.
2024-12-03 04:52:33,188 - INFO - Tokenizando os textos.
2024-12-03 04:52:54,221 - INFO - Criando bigramas.
2024-12-03 04:52:54,638 - INFO - Removendo stopwords.
2024-12-03 04:52:54,653 - INFO - Aplicando stemming.
2024-12-03 04:52:55,004 - INFO - Aplicando lematização.
2024-12-03 04:53:12,687 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-03 04:53:12,704 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-03 04:56:08,784 - INFO - Codificando sentimentos.
2024-12-03 04:56:08,784 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-03 04:56:08,868 - INFO - Bloco 6 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_6.parquet
2024-12-03 04:56:08,935 - INFO - Processando bloco 7 de 10
2024-12-03 04:56:08,935 - INFO - Pré-processando os dados.
2024-12-03 04:56:33,783 - INFO - Normalizando os textos.
2024-12-03 04:56:44,533 - INFO - Tokenizando os textos.
2024-12-03 04:57:05,766 - INFO - Criando bigramas.
2024-12-03 04:57:06,182 - INFO - Removendo stopwords.
2024-12-03 04:57:06,202 - INFO - Aplicando stemming.
2024-12-03 04:57:06,549 - INFO - Aplicando lematização.
2024-12-03 04:57:24,351 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-03 04:57:24,359 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-03 05:00:22,578 - INFO - Codificando sentimentos.
2024-12-03 05:00:22,578 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-03 05:00:22,646 - INFO - Bloco 7 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_7.parquet
2024-12-03 05:00:22,730 - INFO - Processando bloco 8 de 10
2024-12-03 05:00:22,730 - INFO - Pré-processando os dados.
2024-12-03 05:00:47,895 - INFO - Normalizando os textos.
2024-12-03 05:00:58,761 - INFO - Tokenizando os textos.
2024-12-03 05:01:20,044 - INFO - Criando bigramas.
2024-12-03 05:01:20,460 - INFO - Removendo stopwords.
2024-12-03 05:01:20,481 - INFO - Aplicando stemming.
2024-12-03 05:01:20,827 - INFO - Aplicando lematização.
2024-12-03 05:01:38,577 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-03 05:01:38,594 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-03 05:04:37,273 - INFO - Codificando sentimentos.
2024-12-03 05:04:37,273 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-03 05:04:37,341 - INFO - Bloco 8 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_8.parquet
2024-12-03 05:04:37,423 - INFO - Processando bloco 9 de 10
2024-12-03 05:04:37,423 - INFO - Pré-processando os dados.
2024-12-03 05:05:03,439 - INFO - Normalizando os textos.
2024-12-03 05:05:14,222 - INFO - Tokenizando os textos.
2024-12-03 05:05:35,339 - INFO - Criando bigramas.
2024-12-03 05:05:35,755 - INFO - Removendo stopwords.
2024-12-03 05:05:35,755 - INFO - Aplicando stemming.
2024-12-03 05:05:36,122 - INFO - Aplicando lematização.
2024-12-03 05:05:54,105 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-03 05:05:54,122 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-03 05:08:50,618 - INFO - Codificando sentimentos.
2024-12-03 05:08:50,618 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-03 05:08:50,685 - INFO - Bloco 9 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_9.parquet
2024-12-03 05:08:50,769 - INFO - Processando bloco 10 de 10
2024-12-03 05:08:50,769 - INFO - Pré-processando os dados.
2024-12-03 05:09:17,584 - INFO - Normalizando os textos.
2024-12-03 05:09:28,583 - INFO - Tokenizando os textos.
2024-12-03 05:09:49,667 - INFO - Criando bigramas.
2024-12-03 05:09:50,067 - INFO - Removendo stopwords.
2024-12-03 05:09:50,089 - INFO - Aplicando stemming.
2024-12-03 05:09:50,450 - INFO - Aplicando lematização.
2024-12-03 05:10:08,100 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-03 05:10:08,100 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-03 05:13:05,829 - INFO - Codificando sentimentos.
2024-12-03 05:13:05,829 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-03 05:13:05,912 - INFO - Bloco 10 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_10.parquet
2024-12-03 05:13:05,913 - INFO - Tempo médio por bloco (recalculado): 0 horas, 4 minutos, 13.13 segundos
2024-12-03 05:13:05,913 - INFO - Tempo total estimado (recalculado): 0 horas, 42 minutos, 11.30 segundos
2024-12-03 05:13:05,913 - INFO - Salvando dataset processado.
2024-12-03 05:13:06,280 - INFO - Número de linhas com NaN em 'sentimento_codificado' antes da exclusão: 0
2024-12-03 05:13:06,298 - INFO - Número de linhas restantes após a remoção de NaNs: 45823
2024-12-03 05:13:06,299 - INFO - Contando sentimentos positivos, neutros e negativos.
2024-12-03 05:13:06,302 - INFO - Sentimentos positivos: 7682
2024-12-03 05:13:06,302 - INFO - Sentimentos neutros: 17184
2024-12-03 05:13:06,302 - INFO - Sentimentos negativos: 20957
2024-12-03 05:13:06,315 - INFO - Amostra salva com sucesso.
2024-12-03 05:13:13,579 - INFO - Dataset salvo com sucesso.
2024-12-03 05:13:13,618 - INFO - Todos os blocos processados e combinados com sucesso.
2024-12-03 05:13:13,626 - INFO - Gerando relatórios.
2024-12-03 05:13:13,681 - INFO - Relatórios gerados com sucesso.
2024-12-09 10:04:11,688 - INFO -  * Running on http://127.0.0.1:5000 (Press CTRL+C to quit)
2024-12-09 10:04:21,783 - INFO - 127.0.0.1 - - [09/Dec/2024 10:04:21] "GET / HTTP/1.1" 200 -
2024-12-09 10:04:22,055 - INFO - 127.0.0.1 - - [09/Dec/2024 10:04:22] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2024-12-09 10:05:36,639 - ERROR - Exception on /predict [POST]
Traceback (most recent call last):
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 2051, in wsgi_app
    response = self.full_dispatch_request()
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 1501, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 1499, in full_dispatch_request
    rv = self.dispatch_request()
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 1485, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)
  File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\06_app.py", line 180, in predict
    bigrams = criar_bigramas(tweet_normalizado)
  File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\06_app.py", line 96, in criar_bigramas
    tokens = word_tokenize(texto)
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\nltk\tokenize\__init__.py", line 129, in word_tokenize
    sentences = [text] if preserve_line else sent_tokenize(text, language)
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\nltk\tokenize\__init__.py", line 106, in sent_tokenize
    tokenizer = load(f"tokenizers/punkt/{language}.pickle")
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\nltk\data.py", line 750, in load
    opened_resource = _open(resource_url)
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\nltk\data.py", line 876, in _open
    return find(path_, path + [""]).open()
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\nltk\data.py", line 583, in find
    raise LookupError(resource_not_found)
LookupError: 
**********************************************************************
  Resource [93mpunkt[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt/english.pickle[0m

  Searched in:
    - 'C:\\Users\\alanj/nltk_data'
    - 'd:\\github\\data-science\\projetos\\analise-de-sentimentos\\nlp\\src\\asentimentos\\nltk_data'
    - 'd:\\github\\data-science\\projetos\\analise-de-sentimentos\\nlp\\src\\asentimentos\\share\\nltk_data'
    - 'd:\\github\\data-science\\projetos\\analise-de-sentimentos\\nlp\\src\\asentimentos\\lib\\nltk_data'
    - 'C:\\Users\\alanj\\AppData\\Roaming\\nltk_data'
    - 'C:\\nltk_data'
    - 'D:\\nltk_data'
    - 'E:\\nltk_data'
    - ''
**********************************************************************

2024-12-09 10:05:36,794 - INFO - 127.0.0.1 - - [09/Dec/2024 10:05:36] "[35m[1mPOST /predict HTTP/1.1[0m" 500 -
2024-12-09 10:06:06,867 - ERROR - Exception on /predict [POST]
Traceback (most recent call last):
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 2051, in wsgi_app
    response = self.full_dispatch_request()
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 1501, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 1499, in full_dispatch_request
    rv = self.dispatch_request()
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 1485, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)
  File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\06_app.py", line 180, in predict
    bigrams = criar_bigramas(tweet_normalizado)
  File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\06_app.py", line 96, in criar_bigramas
    tokens = word_tokenize(texto)
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\nltk\tokenize\__init__.py", line 129, in word_tokenize
    sentences = [text] if preserve_line else sent_tokenize(text, language)
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\nltk\tokenize\__init__.py", line 106, in sent_tokenize
    tokenizer = load(f"tokenizers/punkt/{language}.pickle")
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\nltk\data.py", line 750, in load
    opened_resource = _open(resource_url)
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\nltk\data.py", line 876, in _open
    return find(path_, path + [""]).open()
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\nltk\data.py", line 583, in find
    raise LookupError(resource_not_found)
LookupError: 
**********************************************************************
  Resource [93mpunkt[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt/english.pickle[0m

  Searched in:
    - 'C:\\Users\\alanj/nltk_data'
    - 'd:\\github\\data-science\\projetos\\analise-de-sentimentos\\nlp\\src\\asentimentos\\nltk_data'
    - 'd:\\github\\data-science\\projetos\\analise-de-sentimentos\\nlp\\src\\asentimentos\\share\\nltk_data'
    - 'd:\\github\\data-science\\projetos\\analise-de-sentimentos\\nlp\\src\\asentimentos\\lib\\nltk_data'
    - 'C:\\Users\\alanj\\AppData\\Roaming\\nltk_data'
    - 'C:\\nltk_data'
    - 'D:\\nltk_data'
    - 'E:\\nltk_data'
    - ''
**********************************************************************

2024-12-09 10:06:06,885 - INFO - 127.0.0.1 - - [09/Dec/2024 10:06:06] "[35m[1mPOST /predict HTTP/1.1[0m" 500 -
2024-12-09 10:06:25,841 - INFO - 127.0.0.1 - - [09/Dec/2024 10:06:25] "GET / HTTP/1.1" 200 -
2024-12-09 10:06:29,679 - ERROR - Exception on /predict [POST]
Traceback (most recent call last):
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 2051, in wsgi_app
    response = self.full_dispatch_request()
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 1501, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 1499, in full_dispatch_request
    rv = self.dispatch_request()
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 1485, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)
  File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\06_app.py", line 180, in predict
    bigrams = criar_bigramas(tweet_normalizado)
  File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\06_app.py", line 96, in criar_bigramas
    tokens = word_tokenize(texto)
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\nltk\tokenize\__init__.py", line 129, in word_tokenize
    sentences = [text] if preserve_line else sent_tokenize(text, language)
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\nltk\tokenize\__init__.py", line 106, in sent_tokenize
    tokenizer = load(f"tokenizers/punkt/{language}.pickle")
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\nltk\data.py", line 750, in load
    opened_resource = _open(resource_url)
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\nltk\data.py", line 876, in _open
    return find(path_, path + [""]).open()
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\nltk\data.py", line 583, in find
    raise LookupError(resource_not_found)
LookupError: 
**********************************************************************
  Resource [93mpunkt[0m not found.
  Please use the NLTK Downloader to obtain the resource:

  [31m>>> import nltk
  >>> nltk.download('punkt')
  [0m
  For more information see: https://www.nltk.org/data.html

  Attempted to load [93mtokenizers/punkt/english.pickle[0m

  Searched in:
    - 'C:\\Users\\alanj/nltk_data'
    - 'd:\\github\\data-science\\projetos\\analise-de-sentimentos\\nlp\\src\\asentimentos\\nltk_data'
    - 'd:\\github\\data-science\\projetos\\analise-de-sentimentos\\nlp\\src\\asentimentos\\share\\nltk_data'
    - 'd:\\github\\data-science\\projetos\\analise-de-sentimentos\\nlp\\src\\asentimentos\\lib\\nltk_data'
    - 'C:\\Users\\alanj\\AppData\\Roaming\\nltk_data'
    - 'C:\\nltk_data'
    - 'D:\\nltk_data'
    - 'E:\\nltk_data'
    - ''
**********************************************************************

2024-12-09 10:06:29,698 - INFO - 127.0.0.1 - - [09/Dec/2024 10:06:29] "[35m[1mPOST /predict HTTP/1.1[0m" 500 -
2024-12-09 10:09:40,396 - INFO -  * Running on http://127.0.0.1:5000 (Press CTRL+C to quit)
2024-12-09 10:09:55,220 - INFO - 127.0.0.1 - - [09/Dec/2024 10:09:55] "GET / HTTP/1.1" 200 -
2024-12-09 10:10:08,936 - ERROR - Exception on /predict [POST]
Traceback (most recent call last):
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 2051, in wsgi_app
    response = self.full_dispatch_request()
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 1501, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 1499, in full_dispatch_request
    rv = self.dispatch_request()
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 1485, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)
  File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\06_app.py", line 184, in predict
    tokens_stemmed = aplicar_stemming(tokens_sem_stopwords)
  File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\06_app.py", line 119, in aplicar_stemming
    stemmer = SnowballStemmer(language='english')
NameError: name 'SnowballStemmer' is not defined
2024-12-09 10:10:08,946 - INFO - 127.0.0.1 - - [09/Dec/2024 10:10:08] "[35m[1mPOST /predict HTTP/1.1[0m" 500 -
2024-12-09 10:12:29,518 - INFO -  * Running on http://127.0.0.1:5000 (Press CTRL+C to quit)
2024-12-09 10:13:38,202 - INFO - 127.0.0.1 - - [09/Dec/2024 10:13:38] "GET / HTTP/1.1" 200 -
2024-12-09 10:13:46,918 - ERROR - Exception on /predict [POST]
Traceback (most recent call last):
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 2051, in wsgi_app
    response = self.full_dispatch_request()
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 1501, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 1499, in full_dispatch_request
    rv = self.dispatch_request()
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 1485, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)
  File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\06_app.py", line 185, in predict
    tokens_stemmed = aplicar_stemming(tokens_sem_stopwords)
  File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\06_app.py", line 120, in aplicar_stemming
    stemmer = SnowballStemmer(language='english')
NameError: name 'SnowballStemmer' is not defined
2024-12-09 10:13:46,961 - INFO - 127.0.0.1 - - [09/Dec/2024 10:13:46] "[35m[1mPOST /predict HTTP/1.1[0m" 500 -
2024-12-09 10:15:46,847 - INFO -  * Running on http://127.0.0.1:5000 (Press CTRL+C to quit)
2024-12-09 10:15:46,916 - INFO - 127.0.0.1 - - [09/Dec/2024 10:15:46] "GET / HTTP/1.1" 200 -
2024-12-09 10:15:58,421 - ERROR - Exception on /predict [POST]
Traceback (most recent call last):
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 2051, in wsgi_app
    response = self.full_dispatch_request()
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 1501, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 1499, in full_dispatch_request
    rv = self.dispatch_request()
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 1485, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)
  File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\06_app.py", line 198, in predict
    prediction = model.predict(features)
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\sklearn\linear_model\_base.py", line 309, in predict
    scores = self.decision_function(X)
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\sklearn\linear_model\_base.py", line 288, in decision_function
    raise ValueError("X has %d features per sample; expecting %d"
ValueError: X has 7649 features per sample; expecting 7336
2024-12-09 10:15:58,427 - INFO - 127.0.0.1 - - [09/Dec/2024 10:15:58] "[35m[1mPOST /predict HTTP/1.1[0m" 500 -
2024-12-09 10:18:09,784 - INFO -  * Running on http://127.0.0.1:5000 (Press CTRL+C to quit)
2024-12-09 10:18:09,897 - INFO - 127.0.0.1 - - [09/Dec/2024 10:18:09] "GET / HTTP/1.1" 200 -
2024-12-09 10:18:15,823 - ERROR - Exception on /predict [POST]
Traceback (most recent call last):
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 2051, in wsgi_app
    response = self.full_dispatch_request()
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 1501, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 1499, in full_dispatch_request
    rv = self.dispatch_request()
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 1485, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)
  File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\06_app.py", line 198, in predict
    prediction = model.predict(features)
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\sklearn\linear_model\_base.py", line 309, in predict
    scores = self.decision_function(X)
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\sklearn\linear_model\_base.py", line 284, in decision_function
    X = check_array(X, accept_sparse='csr')
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\sklearn\utils\validation.py", line 63, in inner_f
    return f(*args, **kwargs)
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\sklearn\utils\validation.py", line 720, in check_array
    _assert_all_finite(array,
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\sklearn\utils\validation.py", line 103, in _assert_all_finite
    raise ValueError(
ValueError: Input contains NaN, infinity or a value too large for dtype('float64').
2024-12-09 10:18:15,828 - INFO - 127.0.0.1 - - [09/Dec/2024 10:18:15] "[35m[1mPOST /predict HTTP/1.1[0m" 500 -
2024-12-09 10:24:44,222 - INFO -  * Running on http://127.0.0.1:5000 (Press CTRL+C to quit)
2024-12-09 10:24:49,552 - INFO - 127.0.0.1 - - [09/Dec/2024 10:24:49] "GET / HTTP/1.1" 200 -
2024-12-09 10:24:56,994 - ERROR - Exception on /predict [POST]
Traceback (most recent call last):
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 2051, in wsgi_app
    response = self.full_dispatch_request()
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 1501, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 1499, in full_dispatch_request
    rv = self.dispatch_request()
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 1485, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)
  File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\06_app.py", line 205, in predict
    prediction = model.predict(features)
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\sklearn\linear_model\_base.py", line 309, in predict
    scores = self.decision_function(X)
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\sklearn\linear_model\_base.py", line 288, in decision_function
    raise ValueError("X has %d features per sample; expecting %d"
ValueError: X has 7649 features per sample; expecting 7336
2024-12-09 10:24:56,997 - INFO - 127.0.0.1 - - [09/Dec/2024 10:24:56] "[35m[1mPOST /predict HTTP/1.1[0m" 500 -
2024-12-09 10:32:19,768 - INFO -  * Running on http://127.0.0.1:5000 (Press CTRL+C to quit)
2024-12-09 10:32:21,025 - INFO - 127.0.0.1 - - [09/Dec/2024 10:32:21] "GET / HTTP/1.1" 200 -
2024-12-09 10:32:31,290 - ERROR - Exception on /predict [POST]
Traceback (most recent call last):
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 2051, in wsgi_app
    response = self.full_dispatch_request()
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 1501, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 1499, in full_dispatch_request
    rv = self.dispatch_request()
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 1485, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)
  File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\06_app.py", line 205, in predict
    prediction = model.predict(features)
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\sklearn\linear_model\_base.py", line 309, in predict
    scores = self.decision_function(X)
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\sklearn\linear_model\_base.py", line 288, in decision_function
    raise ValueError("X has %d features per sample; expecting %d"
ValueError: X has 7649 features per sample; expecting 7336
2024-12-09 10:32:31,312 - INFO - 127.0.0.1 - - [09/Dec/2024 10:32:31] "[35m[1mPOST /predict HTTP/1.1[0m" 500 -
2024-12-09 10:51:37,346 - INFO -  * Running on http://127.0.0.1:5000 (Press CTRL+C to quit)
2024-12-09 10:51:37,396 - INFO - 127.0.0.1 - - [09/Dec/2024 10:51:37] "GET / HTTP/1.1" 200 -
2024-12-09 10:51:45,151 - ERROR - Exception on /predict [POST]
Traceback (most recent call last):
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 2051, in wsgi_app
    response = self.full_dispatch_request()
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 1501, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 1499, in full_dispatch_request
    rv = self.dispatch_request()
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 1485, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)
  File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\06_app.py", line 205, in predict
    prediction = model.predict(features)
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\sklearn\linear_model\_base.py", line 309, in predict
    scores = self.decision_function(X)
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\sklearn\linear_model\_base.py", line 288, in decision_function
    raise ValueError("X has %d features per sample; expecting %d"
ValueError: X has 7649 features per sample; expecting 7336
2024-12-09 10:51:45,175 - INFO - 127.0.0.1 - - [09/Dec/2024 10:51:45] "[35m[1mPOST /predict HTTP/1.1[0m" 500 -
2024-12-09 10:55:43,421 - INFO -  * Running on http://127.0.0.1:5000 (Press CTRL+C to quit)
2024-12-09 10:55:57,485 - INFO - 127.0.0.1 - - [09/Dec/2024 10:55:57] "GET / HTTP/1.1" 200 -
2024-12-09 10:56:04,218 - ERROR - Exception on /predict [POST]
Traceback (most recent call last):
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 2051, in wsgi_app
    response = self.full_dispatch_request()
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 1501, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 1499, in full_dispatch_request
    rv = self.dispatch_request()
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 1485, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)
  File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\06_app.py", line 206, in predict
    prediction = model.predict(features)
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\sklearn\linear_model\_base.py", line 309, in predict
    scores = self.decision_function(X)
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\sklearn\linear_model\_base.py", line 288, in decision_function
    raise ValueError("X has %d features per sample; expecting %d"
ValueError: X has 7649 features per sample; expecting 7336
2024-12-09 10:56:04,242 - INFO - 127.0.0.1 - - [09/Dec/2024 10:56:04] "[35m[1mPOST /predict HTTP/1.1[0m" 500 -
2024-12-09 10:59:31,887 - INFO -  * Running on http://127.0.0.1:5000 (Press CTRL+C to quit)
2024-12-09 10:59:38,524 - INFO - 127.0.0.1 - - [09/Dec/2024 10:59:38] "GET / HTTP/1.1" 200 -
2024-12-09 10:59:45,706 - ERROR - Exception on /predict [POST]
Traceback (most recent call last):
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 2051, in wsgi_app
    response = self.full_dispatch_request()
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 1501, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 1499, in full_dispatch_request
    rv = self.dispatch_request()
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 1485, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)
  File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\06_app.py", line 205, in predict
    prediction = model.predict(features)
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\sklearn\linear_model\_base.py", line 309, in predict
    scores = self.decision_function(X)
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\sklearn\linear_model\_base.py", line 288, in decision_function
    raise ValueError("X has %d features per sample; expecting %d"
ValueError: X has 7649 features per sample; expecting 7336
2024-12-09 10:59:45,727 - INFO - 127.0.0.1 - - [09/Dec/2024 10:59:45] "[35m[1mPOST /predict HTTP/1.1[0m" 500 -
2024-12-09 11:49:57,502 - INFO -  * Running on http://127.0.0.1:5000 (Press CTRL+C to quit)
2024-12-09 11:50:00,269 - INFO - 127.0.0.1 - - [09/Dec/2024 11:50:00] "GET / HTTP/1.1" 200 -
2024-12-09 11:50:06,924 - INFO - 127.0.0.1 - - [09/Dec/2024 11:50:06] "GET / HTTP/1.1" 200 -
2024-12-09 11:50:10,585 - ERROR - Exception on /predict [POST]
Traceback (most recent call last):
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 2051, in wsgi_app
    response = self.full_dispatch_request()
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 1501, in full_dispatch_request
    rv = self.handle_user_exception(e)
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 1499, in full_dispatch_request
    rv = self.dispatch_request()
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\flask\app.py", line 1485, in dispatch_request
    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)
  File "D:\Github\data-science\projetos\analise-de-sentimentos\nlp\src\06_app.py", line 205, in predict
    prediction = model.predict(features)
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\sklearn\linear_model\_base.py", line 309, in predict
    scores = self.decision_function(X)
  File "d:\github\data-science\projetos\analise-de-sentimentos\nlp\src\asentimentos\lib\site-packages\sklearn\linear_model\_base.py", line 288, in decision_function
    raise ValueError("X has %d features per sample; expecting %d"
ValueError: X has 7333 features per sample; expecting 7336
2024-12-09 11:50:10,589 - INFO - 127.0.0.1 - - [09/Dec/2024 11:50:10] "[35m[1mPOST /predict HTTP/1.1[0m" 500 -
2024-12-10 17:18:48,891 - INFO - Carregando o dataset bruto.
2024-12-10 17:18:48,910 - INFO - Dataset carregado com sucesso com 100000 linhas.
2024-12-10 17:18:48,910 - INFO - Renomeando colunas.
2024-12-10 17:18:49,039 - INFO - Total de linhas a serem processadas: 100000
2024-12-10 17:18:49,039 - INFO - Total de blocos a serem processados: 20
2024-12-10 17:18:49,142 - INFO - Processando bloco 1 de 20
2024-12-10 17:18:49,143 - INFO - Pré-processando os dados.
2024-12-10 17:19:11,423 - INFO - Normalizando os textos.
2024-12-10 17:19:21,434 - INFO - Tokenizando os textos.
2024-12-10 17:19:43,726 - INFO - Criando bigramas.
2024-12-10 17:19:44,142 - INFO - Removendo stopwords.
2024-12-10 17:19:44,158 - INFO - Aplicando stemming.
2024-12-10 17:19:44,505 - INFO - Aplicando lematização.
2024-12-10 17:20:02,176 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 17:20:02,191 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-10 17:22:33,367 - INFO - Codificando sentimentos.
2024-12-10 17:22:33,367 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 17:22:33,441 - INFO - Bloco 1 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_1.parquet
2024-12-10 17:22:33,441 - INFO - Tempo médio por bloco: 0 horas, 3 minutos, 44.33 segundos
2024-12-10 17:22:33,441 - INFO - Tempo total estimado: 1 horas, 14 minutos, 46.57 segundos
2024-12-10 17:22:33,552 - INFO - Processando bloco 2 de 20
2024-12-10 17:22:33,552 - INFO - Pré-processando os dados.
2024-12-10 17:22:56,070 - INFO - Normalizando os textos.
2024-12-10 17:23:06,020 - INFO - Tokenizando os textos.
2024-12-10 17:23:28,685 - INFO - Criando bigramas.
2024-12-10 17:23:29,084 - INFO - Removendo stopwords.
2024-12-10 17:23:29,100 - INFO - Aplicando stemming.
2024-12-10 17:23:29,445 - INFO - Aplicando lematização.
2024-12-10 17:23:47,108 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 17:23:47,124 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-10 17:26:31,914 - INFO - Codificando sentimentos.
2024-12-10 17:26:31,914 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 17:26:31,980 - INFO - Bloco 2 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_2.parquet
2024-12-10 17:26:32,089 - INFO - Processando bloco 3 de 20
2024-12-10 17:26:32,089 - INFO - Pré-processando os dados.
2024-12-10 17:26:55,376 - INFO - Normalizando os textos.
2024-12-10 17:27:05,469 - INFO - Tokenizando os textos.
2024-12-10 17:27:25,699 - INFO - Criando bigramas.
2024-12-10 17:27:26,093 - INFO - Removendo stopwords.
2024-12-10 17:27:26,093 - INFO - Aplicando stemming.
2024-12-10 17:27:26,437 - INFO - Aplicando lematização.
2024-12-10 17:27:43,334 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 17:27:43,350 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-10 17:30:30,926 - INFO - Codificando sentimentos.
2024-12-10 17:30:30,926 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 17:30:30,992 - INFO - Bloco 3 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_3.parquet
2024-12-10 17:30:31,121 - INFO - Processando bloco 4 de 20
2024-12-10 17:30:31,121 - INFO - Pré-processando os dados.
2024-12-10 17:30:55,656 - INFO - Normalizando os textos.
2024-12-10 17:31:06,041 - INFO - Tokenizando os textos.
2024-12-10 17:31:27,113 - INFO - Criando bigramas.
2024-12-10 17:31:27,559 - INFO - Removendo stopwords.
2024-12-10 17:31:27,578 - INFO - Aplicando stemming.
2024-12-10 17:31:27,942 - INFO - Aplicando lematização.
2024-12-10 17:31:46,376 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 17:31:46,393 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-10 17:34:39,912 - INFO - Codificando sentimentos.
2024-12-10 17:34:39,912 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 17:34:39,988 - INFO - Bloco 4 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_4.parquet
2024-12-10 17:34:40,116 - INFO - Processando bloco 5 de 20
2024-12-10 17:34:40,116 - INFO - Pré-processando os dados.
2024-12-10 17:35:03,737 - INFO - Normalizando os textos.
2024-12-10 17:35:14,080 - INFO - Tokenizando os textos.
2024-12-10 17:35:34,878 - INFO - Criando bigramas.
2024-12-10 17:35:35,278 - INFO - Removendo stopwords.
2024-12-10 17:35:35,292 - INFO - Aplicando stemming.
2024-12-10 17:35:35,625 - INFO - Aplicando lematização.
2024-12-10 17:35:53,051 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 17:35:53,051 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-10 17:38:27,593 - INFO - Codificando sentimentos.
2024-12-10 17:38:27,593 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 17:38:27,678 - INFO - Bloco 5 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_5.parquet
2024-12-10 17:38:27,783 - INFO - Processando bloco 6 de 20
2024-12-10 17:38:27,783 - INFO - Pré-processando os dados.
2024-12-10 17:38:54,135 - INFO - Normalizando os textos.
2024-12-10 17:39:04,590 - INFO - Tokenizando os textos.
2024-12-10 17:39:24,665 - INFO - Criando bigramas.
2024-12-10 17:39:25,062 - INFO - Removendo stopwords.
2024-12-10 17:39:25,062 - INFO - Aplicando stemming.
2024-12-10 17:39:25,408 - INFO - Aplicando lematização.
2024-12-10 17:39:42,337 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 17:39:42,353 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-10 17:40:45,632 - INFO -  * Running on http://127.0.0.1:5000 (Press CTRL+C to quit)
2024-12-10 17:40:45,634 - INFO -  * Restarting with stat
2024-12-10 17:41:00,197 - WARNING -  * Debugger is active!
2024-12-10 17:41:00,197 - INFO -  * Debugger PIN: 708-303-649
2024-12-10 17:41:00,627 - INFO - 127.0.0.1 - - [10/Dec/2024 17:41:00] "GET / HTTP/1.1" 200 -
2024-12-10 17:41:00,638 - INFO - 127.0.0.1 - - [10/Dec/2024 17:41:00] "GET /static/style.css HTTP/1.1" 200 -
2024-12-10 17:41:00,682 - INFO - 127.0.0.1 - - [10/Dec/2024 17:41:00] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2024-12-10 17:41:19,680 - INFO - 127.0.0.1 - - [10/Dec/2024 17:41:19] "POST /predict HTTP/1.1" 200 -
2024-12-10 17:41:19,695 - INFO - 127.0.0.1 - - [10/Dec/2024 17:41:19] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:41:37,528 - INFO - 127.0.0.1 - - [10/Dec/2024 17:41:37] "POST /predict HTTP/1.1" 200 -
2024-12-10 17:41:37,545 - INFO - 127.0.0.1 - - [10/Dec/2024 17:41:37] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:41:53,443 - INFO - 127.0.0.1 - - [10/Dec/2024 17:41:53] "POST /predict HTTP/1.1" 200 -
2024-12-10 17:41:53,448 - INFO - 127.0.0.1 - - [10/Dec/2024 17:41:53] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:42:06,935 - INFO - 127.0.0.1 - - [10/Dec/2024 17:42:06] "POST /predict HTTP/1.1" 200 -
2024-12-10 17:42:06,943 - INFO - 127.0.0.1 - - [10/Dec/2024 17:42:06] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:42:26,325 - INFO - 127.0.0.1 - - [10/Dec/2024 17:42:26] "POST /predict HTTP/1.1" 200 -
2024-12-10 17:42:26,333 - INFO - 127.0.0.1 - - [10/Dec/2024 17:42:26] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:42:29,982 - INFO - Codificando sentimentos.
2024-12-10 17:42:29,982 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 17:42:30,060 - INFO - Bloco 6 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_6.parquet
2024-12-10 17:42:30,185 - INFO - Processando bloco 7 de 20
2024-12-10 17:42:30,185 - INFO - Pré-processando os dados.
2024-12-10 17:42:49,456 - INFO - 127.0.0.1 - - [10/Dec/2024 17:42:49] "POST /predict HTTP/1.1" 200 -
2024-12-10 17:42:49,462 - INFO - 127.0.0.1 - - [10/Dec/2024 17:42:49] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:42:53,854 - INFO - Normalizando os textos.
2024-12-10 17:43:04,137 - INFO - Tokenizando os textos.
2024-12-10 17:43:08,956 - INFO - 127.0.0.1 - - [10/Dec/2024 17:43:08] "POST /predict HTTP/1.1" 200 -
2024-12-10 17:43:08,964 - INFO - 127.0.0.1 - - [10/Dec/2024 17:43:08] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:43:24,844 - INFO - 127.0.0.1 - - [10/Dec/2024 17:43:24] "POST /predict HTTP/1.1" 200 -
2024-12-10 17:43:24,861 - INFO - 127.0.0.1 - - [10/Dec/2024 17:43:24] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:43:25,193 - INFO - Criando bigramas.
2024-12-10 17:43:25,568 - INFO - Removendo stopwords.
2024-12-10 17:43:25,595 - INFO - Aplicando stemming.
2024-12-10 17:43:25,939 - INFO - Aplicando lematização.
2024-12-10 17:43:37,752 - INFO - 127.0.0.1 - - [10/Dec/2024 17:43:37] "POST /predict HTTP/1.1" 200 -
2024-12-10 17:43:37,759 - INFO - 127.0.0.1 - - [10/Dec/2024 17:43:37] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:43:43,660 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 17:43:43,675 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-10 17:44:48,209 - INFO - 127.0.0.1 - - [10/Dec/2024 17:44:48] "POST /predict HTTP/1.1" 200 -
2024-12-10 17:44:48,209 - INFO - 127.0.0.1 - - [10/Dec/2024 17:44:48] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:45:00,124 - INFO - 127.0.0.1 - - [10/Dec/2024 17:45:00] "POST /predict HTTP/1.1" 200 -
2024-12-10 17:45:00,142 - INFO - 127.0.0.1 - - [10/Dec/2024 17:45:00] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:45:07,690 - INFO - 127.0.0.1 - - [10/Dec/2024 17:45:07] "POST /predict HTTP/1.1" 200 -
2024-12-10 17:45:07,690 - INFO - 127.0.0.1 - - [10/Dec/2024 17:45:07] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:45:15,257 - INFO - 127.0.0.1 - - [10/Dec/2024 17:45:15] "POST /predict HTTP/1.1" 200 -
2024-12-10 17:45:15,275 - INFO - 127.0.0.1 - - [10/Dec/2024 17:45:15] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:45:25,307 - INFO - 127.0.0.1 - - [10/Dec/2024 17:45:25] "POST /predict HTTP/1.1" 200 -
2024-12-10 17:45:25,326 - INFO - 127.0.0.1 - - [10/Dec/2024 17:45:25] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:45:33,040 - INFO - 127.0.0.1 - - [10/Dec/2024 17:45:33] "POST /predict HTTP/1.1" 200 -
2024-12-10 17:45:33,058 - INFO - 127.0.0.1 - - [10/Dec/2024 17:45:33] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:45:41,375 - INFO - 127.0.0.1 - - [10/Dec/2024 17:45:41] "POST /predict HTTP/1.1" 200 -
2024-12-10 17:45:41,392 - INFO - 127.0.0.1 - - [10/Dec/2024 17:45:41] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:45:48,539 - INFO - 127.0.0.1 - - [10/Dec/2024 17:45:48] "POST /predict HTTP/1.1" 200 -
2024-12-10 17:45:48,557 - INFO - 127.0.0.1 - - [10/Dec/2024 17:45:48] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:45:56,321 - INFO - 127.0.0.1 - - [10/Dec/2024 17:45:56] "POST /predict HTTP/1.1" 200 -
2024-12-10 17:45:56,324 - INFO - 127.0.0.1 - - [10/Dec/2024 17:45:56] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:46:05,363 - INFO - 127.0.0.1 - - [10/Dec/2024 17:46:05] "POST /predict HTTP/1.1" 200 -
2024-12-10 17:46:05,373 - INFO - 127.0.0.1 - - [10/Dec/2024 17:46:05] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:46:13,308 - INFO - 127.0.0.1 - - [10/Dec/2024 17:46:13] "POST /predict HTTP/1.1" 200 -
2024-12-10 17:46:13,317 - INFO - 127.0.0.1 - - [10/Dec/2024 17:46:13] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:46:35,217 - INFO - Codificando sentimentos.
2024-12-10 17:46:35,217 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 17:46:35,289 - INFO - Bloco 7 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_7.parquet
2024-12-10 17:46:35,399 - INFO - Processando bloco 8 de 20
2024-12-10 17:46:35,399 - INFO - Pré-processando os dados.
2024-12-10 17:46:59,820 - INFO - Normalizando os textos.
2024-12-10 17:47:10,148 - INFO - Tokenizando os textos.
2024-12-10 17:47:15,857 - INFO - 127.0.0.1 - - [10/Dec/2024 17:47:15] "POST /predict HTTP/1.1" 200 -
2024-12-10 17:47:15,857 - INFO - 127.0.0.1 - - [10/Dec/2024 17:47:15] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:47:28,271 - INFO - 127.0.0.1 - - [10/Dec/2024 17:47:28] "POST /predict HTTP/1.1" 200 -
2024-12-10 17:47:28,271 - INFO - 127.0.0.1 - - [10/Dec/2024 17:47:28] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:47:31,565 - INFO - Criando bigramas.
2024-12-10 17:47:31,945 - INFO - Removendo stopwords.
2024-12-10 17:47:31,961 - INFO - Aplicando stemming.
2024-12-10 17:47:32,327 - INFO - Aplicando lematização.
2024-12-10 17:47:44,260 - INFO - 127.0.0.1 - - [10/Dec/2024 17:47:44] "POST /predict HTTP/1.1" 200 -
2024-12-10 17:47:44,266 - INFO - 127.0.0.1 - - [10/Dec/2024 17:47:44] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:47:50,415 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 17:47:50,426 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-10 17:47:52,344 - INFO - 127.0.0.1 - - [10/Dec/2024 17:47:52] "POST /predict HTTP/1.1" 200 -
2024-12-10 17:47:52,352 - INFO - 127.0.0.1 - - [10/Dec/2024 17:47:52] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:47:59,486 - INFO - 127.0.0.1 - - [10/Dec/2024 17:47:59] "POST /predict HTTP/1.1" 200 -
2024-12-10 17:47:59,491 - INFO - 127.0.0.1 - - [10/Dec/2024 17:47:59] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:48:05,803 - INFO - 127.0.0.1 - - [10/Dec/2024 17:48:05] "POST /predict HTTP/1.1" 200 -
2024-12-10 17:48:05,826 - INFO - 127.0.0.1 - - [10/Dec/2024 17:48:05] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:48:12,536 - INFO - 127.0.0.1 - - [10/Dec/2024 17:48:12] "POST /predict HTTP/1.1" 200 -
2024-12-10 17:48:12,545 - INFO - 127.0.0.1 - - [10/Dec/2024 17:48:12] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:48:19,903 - INFO - 127.0.0.1 - - [10/Dec/2024 17:48:19] "POST /predict HTTP/1.1" 200 -
2024-12-10 17:48:19,904 - INFO - 127.0.0.1 - - [10/Dec/2024 17:48:19] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:48:27,621 - INFO - 127.0.0.1 - - [10/Dec/2024 17:48:27] "POST /predict HTTP/1.1" 200 -
2024-12-10 17:48:27,621 - INFO - 127.0.0.1 - - [10/Dec/2024 17:48:27] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:49:16,386 - INFO - 127.0.0.1 - - [10/Dec/2024 17:49:16] "POST /predict HTTP/1.1" 200 -
2024-12-10 17:49:16,386 - INFO - 127.0.0.1 - - [10/Dec/2024 17:49:16] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:49:25,035 - INFO - 127.0.0.1 - - [10/Dec/2024 17:49:25] "POST /predict HTTP/1.1" 200 -
2024-12-10 17:49:25,054 - INFO - 127.0.0.1 - - [10/Dec/2024 17:49:25] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:49:33,101 - INFO - 127.0.0.1 - - [10/Dec/2024 17:49:33] "POST /predict HTTP/1.1" 200 -
2024-12-10 17:49:33,121 - INFO - 127.0.0.1 - - [10/Dec/2024 17:49:33] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:49:47,285 - INFO - 127.0.0.1 - - [10/Dec/2024 17:49:47] "POST /predict HTTP/1.1" 200 -
2024-12-10 17:49:47,304 - INFO - 127.0.0.1 - - [10/Dec/2024 17:49:47] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:49:55,198 - INFO - 127.0.0.1 - - [10/Dec/2024 17:49:55] "POST /predict HTTP/1.1" 200 -
2024-12-10 17:49:55,208 - INFO - 127.0.0.1 - - [10/Dec/2024 17:49:55] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:50:02,385 - INFO - 127.0.0.1 - - [10/Dec/2024 17:50:02] "POST /predict HTTP/1.1" 200 -
2024-12-10 17:50:02,395 - INFO - 127.0.0.1 - - [10/Dec/2024 17:50:02] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:50:10,034 - INFO - 127.0.0.1 - - [10/Dec/2024 17:50:10] "POST /predict HTTP/1.1" 200 -
2024-12-10 17:50:10,034 - INFO - 127.0.0.1 - - [10/Dec/2024 17:50:10] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:50:17,684 - INFO - 127.0.0.1 - - [10/Dec/2024 17:50:17] "POST /predict HTTP/1.1" 200 -
2024-12-10 17:50:17,703 - INFO - 127.0.0.1 - - [10/Dec/2024 17:50:17] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:50:26,185 - INFO - 127.0.0.1 - - [10/Dec/2024 17:50:26] "POST /predict HTTP/1.1" 200 -
2024-12-10 17:50:26,185 - INFO - 127.0.0.1 - - [10/Dec/2024 17:50:26] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:50:34,231 - INFO - 127.0.0.1 - - [10/Dec/2024 17:50:34] "POST /predict HTTP/1.1" 200 -
2024-12-10 17:50:34,241 - INFO - 127.0.0.1 - - [10/Dec/2024 17:50:34] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:50:41,598 - INFO - Codificando sentimentos.
2024-12-10 17:50:41,601 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 17:50:41,675 - INFO - Bloco 8 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_8.parquet
2024-12-10 17:50:41,784 - INFO - Processando bloco 9 de 20
2024-12-10 17:50:41,784 - INFO - Pré-processando os dados.
2024-12-10 17:51:06,613 - INFO - Normalizando os textos.
2024-12-10 17:51:17,236 - INFO - Tokenizando os textos.
2024-12-10 17:51:37,453 - INFO - Criando bigramas.
2024-12-10 17:51:37,829 - INFO - Removendo stopwords.
2024-12-10 17:51:37,845 - INFO - Aplicando stemming.
2024-12-10 17:51:38,190 - INFO - Aplicando lematização.
2024-12-10 17:51:54,662 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 17:51:54,677 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-10 17:53:49,229 - INFO -  * Running on http://127.0.0.1:5000 (Press CTRL+C to quit)
2024-12-10 17:53:49,237 - INFO -  * Restarting with stat
2024-12-10 17:54:07,968 - WARNING -  * Debugger is active!
2024-12-10 17:54:07,974 - INFO -  * Debugger PIN: 708-303-649
2024-12-10 17:54:08,560 - INFO - 127.0.0.1 - - [10/Dec/2024 17:54:08] "GET / HTTP/1.1" 200 -
2024-12-10 17:54:08,740 - INFO - 127.0.0.1 - - [10/Dec/2024 17:54:08] "GET /static/style.css HTTP/1.1" 200 -
2024-12-10 17:54:08,939 - INFO - 127.0.0.1 - - [10/Dec/2024 17:54:08] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2024-12-10 17:54:22,320 - INFO - 127.0.0.1 - - [10/Dec/2024 17:54:22] "POST /predict HTTP/1.1" 200 -
2024-12-10 17:54:22,389 - INFO - 127.0.0.1 - - [10/Dec/2024 17:54:22] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:54:41,137 - INFO - Codificando sentimentos.
2024-12-10 17:54:41,139 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 17:54:41,195 - INFO - Bloco 9 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_9.parquet
2024-12-10 17:54:41,330 - INFO - Processando bloco 10 de 20
2024-12-10 17:54:41,331 - INFO - Pré-processando os dados.
2024-12-10 17:55:08,011 - INFO -  * Running on http://127.0.0.1:5000 (Press CTRL+C to quit)
2024-12-10 17:55:08,013 - INFO -  * Restarting with stat
2024-12-10 17:55:08,212 - INFO - Normalizando os textos.
2024-12-10 17:55:18,020 - WARNING -  * Debugger is active!
2024-12-10 17:55:18,023 - INFO -  * Debugger PIN: 708-303-649
2024-12-10 17:55:18,318 - INFO - 127.0.0.1 - - [10/Dec/2024 17:55:18] "GET / HTTP/1.1" 200 -
2024-12-10 17:55:18,368 - INFO - 127.0.0.1 - - [10/Dec/2024 17:55:18] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:55:20,054 - INFO - Tokenizando os textos.
2024-12-10 17:55:25,056 - INFO - 127.0.0.1 - - [10/Dec/2024 17:55:25] "POST /predict HTTP/1.1" 200 -
2024-12-10 17:55:25,105 - INFO - 127.0.0.1 - - [10/Dec/2024 17:55:25] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:55:33,583 - INFO - 127.0.0.1 - - [10/Dec/2024 17:55:33] "POST /predict HTTP/1.1" 200 -
2024-12-10 17:55:33,618 - INFO - 127.0.0.1 - - [10/Dec/2024 17:55:33] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:55:39,684 - INFO - 127.0.0.1 - - [10/Dec/2024 17:55:39] "POST /predict HTTP/1.1" 200 -
2024-12-10 17:55:39,722 - INFO - 127.0.0.1 - - [10/Dec/2024 17:55:39] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 17:55:41,221 - INFO - Criando bigramas.
2024-12-10 17:55:41,612 - INFO - Removendo stopwords.
2024-12-10 17:55:41,628 - INFO - Aplicando stemming.
2024-12-10 17:55:42,006 - INFO - Aplicando lematização.
2024-12-10 17:55:59,274 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 17:55:59,290 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-10 17:58:20,474 - INFO - Codificando sentimentos.
2024-12-10 17:58:20,474 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 17:58:20,542 - INFO - Bloco 10 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_10.parquet
2024-12-10 17:58:20,657 - INFO - Processando bloco 11 de 20
2024-12-10 17:58:20,657 - INFO - Pré-processando os dados.
2024-12-10 17:58:44,089 - INFO - Normalizando os textos.
2024-12-10 17:58:54,269 - INFO - Tokenizando os textos.
2024-12-10 17:59:13,631 - INFO - Criando bigramas.
2024-12-10 17:59:14,016 - INFO - Removendo stopwords.
2024-12-10 17:59:14,028 - INFO - Aplicando stemming.
2024-12-10 17:59:14,358 - INFO - Aplicando lematização.
2024-12-10 17:59:30,518 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 17:59:30,534 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-10 18:01:52,375 - INFO - Codificando sentimentos.
2024-12-10 18:01:52,375 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 18:01:52,454 - INFO - Bloco 11 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_11.parquet
2024-12-10 18:01:52,580 - INFO - Processando bloco 12 de 20
2024-12-10 18:01:52,580 - INFO - Pré-processando os dados.
2024-12-10 18:02:16,303 - INFO - Normalizando os textos.
2024-12-10 18:02:26,481 - INFO - Tokenizando os textos.
2024-12-10 18:02:45,846 - INFO - Criando bigramas.
2024-12-10 18:02:46,223 - INFO - Removendo stopwords.
2024-12-10 18:02:46,239 - INFO - Aplicando stemming.
2024-12-10 18:02:46,582 - INFO - Aplicando lematização.
2024-12-10 18:03:02,686 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 18:03:02,686 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-10 18:05:24,421 - INFO - Codificando sentimentos.
2024-12-10 18:05:24,421 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 18:05:24,483 - INFO - Bloco 12 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_12.parquet
2024-12-10 18:05:24,631 - INFO - Processando bloco 13 de 20
2024-12-10 18:05:24,631 - INFO - Pré-processando os dados.
2024-12-10 18:05:47,842 - INFO - Normalizando os textos.
2024-12-10 18:05:57,848 - INFO - Tokenizando os textos.
2024-12-10 18:06:17,057 - INFO - Criando bigramas.
2024-12-10 18:06:17,451 - INFO - Removendo stopwords.
2024-12-10 18:06:17,451 - INFO - Aplicando stemming.
2024-12-10 18:06:17,798 - INFO - Aplicando lematização.
2024-12-10 18:06:33,977 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 18:06:33,977 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-10 18:08:56,400 - INFO - Codificando sentimentos.
2024-12-10 18:08:56,400 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 18:08:56,478 - INFO - Bloco 13 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_13.parquet
2024-12-10 18:08:56,594 - INFO - Processando bloco 14 de 20
2024-12-10 18:08:56,594 - INFO - Pré-processando os dados.
2024-12-10 18:09:20,340 - INFO - Normalizando os textos.
2024-12-10 18:09:30,300 - INFO - Tokenizando os textos.
2024-12-10 18:09:49,413 - INFO - Criando bigramas.
2024-12-10 18:09:49,798 - INFO - Removendo stopwords.
2024-12-10 18:09:49,820 - INFO - Aplicando stemming.
2024-12-10 18:09:50,151 - INFO - Aplicando lematização.
2024-12-10 18:10:06,082 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 18:10:06,082 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-10 18:12:31,062 - INFO - Codificando sentimentos.
2024-12-10 18:12:31,064 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 18:12:31,141 - INFO - Bloco 14 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_14.parquet
2024-12-10 18:12:31,256 - INFO - Processando bloco 15 de 20
2024-12-10 18:12:31,256 - INFO - Pré-processando os dados.
2024-12-10 18:12:55,204 - INFO - Normalizando os textos.
2024-12-10 18:13:05,405 - INFO - Tokenizando os textos.
2024-12-10 18:13:24,985 - INFO - Criando bigramas.
2024-12-10 18:13:25,361 - INFO - Removendo stopwords.
2024-12-10 18:13:25,377 - INFO - Aplicando stemming.
2024-12-10 18:13:25,723 - INFO - Aplicando lematização.
2024-12-10 18:13:42,855 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 18:13:42,870 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-10 18:16:04,748 - INFO - Codificando sentimentos.
2024-12-10 18:16:04,748 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 18:16:04,819 - INFO - Bloco 15 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_15.parquet
2024-12-10 18:16:04,952 - INFO - Processando bloco 16 de 20
2024-12-10 18:16:04,952 - INFO - Pré-processando os dados.
2024-12-10 18:16:28,639 - INFO - Normalizando os textos.
2024-12-10 18:16:38,682 - INFO - Tokenizando os textos.
2024-12-10 18:16:58,725 - INFO - Criando bigramas.
2024-12-10 18:16:59,123 - INFO - Removendo stopwords.
2024-12-10 18:16:59,139 - INFO - Aplicando stemming.
2024-12-10 18:16:59,482 - INFO - Aplicando lematização.
2024-12-10 18:17:16,335 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 18:17:16,335 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-10 18:19:36,584 - INFO - Codificando sentimentos.
2024-12-10 18:19:36,584 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 18:19:36,663 - INFO - Bloco 16 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_16.parquet
2024-12-10 18:19:36,780 - INFO - Processando bloco 17 de 20
2024-12-10 18:19:36,780 - INFO - Pré-processando os dados.
2024-12-10 18:20:00,500 - INFO - Normalizando os textos.
2024-12-10 18:20:10,905 - INFO - Tokenizando os textos.
2024-12-10 18:20:30,123 - INFO - Criando bigramas.
2024-12-10 18:20:30,516 - INFO - Removendo stopwords.
2024-12-10 18:20:30,536 - INFO - Aplicando stemming.
2024-12-10 18:20:30,865 - INFO - Aplicando lematização.
2024-12-10 18:20:46,859 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 18:20:46,875 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-10 18:23:10,425 - INFO - Codificando sentimentos.
2024-12-10 18:23:10,425 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 18:23:10,510 - INFO - Bloco 17 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_17.parquet
2024-12-10 18:23:10,642 - INFO - Processando bloco 18 de 20
2024-12-10 18:23:10,642 - INFO - Pré-processando os dados.
2024-12-10 18:23:33,831 - INFO - Normalizando os textos.
2024-12-10 18:23:44,773 - INFO - Tokenizando os textos.
2024-12-10 18:24:07,018 - INFO - Criando bigramas.
2024-12-10 18:24:07,419 - INFO - Removendo stopwords.
2024-12-10 18:24:07,435 - INFO - Aplicando stemming.
2024-12-10 18:24:07,898 - INFO - Aplicando lematização.
2024-12-10 18:24:24,264 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 18:24:24,264 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-10 18:26:57,175 - INFO - Codificando sentimentos.
2024-12-10 18:26:57,176 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 18:26:57,254 - INFO - Bloco 18 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_18.parquet
2024-12-10 18:26:57,388 - INFO - Processando bloco 19 de 20
2024-12-10 18:26:57,388 - INFO - Pré-processando os dados.
2024-12-10 18:27:22,522 - INFO - Normalizando os textos.
2024-12-10 18:27:32,818 - INFO - Tokenizando os textos.
2024-12-10 18:27:52,671 - INFO - Criando bigramas.
2024-12-10 18:27:53,060 - INFO - Removendo stopwords.
2024-12-10 18:27:53,074 - INFO - Aplicando stemming.
2024-12-10 18:27:53,405 - INFO - Aplicando lematização.
2024-12-10 18:28:12,068 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 18:28:12,068 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-10 18:30:49,243 - INFO - Codificando sentimentos.
2024-12-10 18:30:49,243 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 18:30:49,321 - INFO - Bloco 19 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_19.parquet
2024-12-10 18:30:49,432 - INFO - Processando bloco 20 de 20
2024-12-10 18:30:49,432 - INFO - Pré-processando os dados.
2024-12-10 18:31:13,559 - INFO - Normalizando os textos.
2024-12-10 18:31:24,517 - INFO - Tokenizando os textos.
2024-12-10 18:31:44,598 - INFO - Criando bigramas.
2024-12-10 18:31:45,004 - INFO - Removendo stopwords.
2024-12-10 18:31:45,018 - INFO - Aplicando stemming.
2024-12-10 18:31:45,357 - INFO - Aplicando lematização.
2024-12-10 18:32:02,246 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 18:32:02,246 - INFO - Classificando sentimentos usando VADER e BERT.
2024-12-10 18:34:58,660 - INFO - Codificando sentimentos.
2024-12-10 18:34:58,676 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 18:34:58,745 - INFO - Bloco 20 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_20.parquet
2024-12-10 18:34:58,745 - INFO - Tempo médio por bloco (recalculado): 0 horas, 3 minutos, 48.42 segundos
2024-12-10 18:34:58,745 - INFO - Tempo total estimado (recalculado): 1 horas, 16 minutos, 8.34 segundos
2024-12-10 18:34:58,745 - INFO - Salvando dataset processado.
2024-12-10 18:34:59,441 - INFO - Número de linhas com NaN em 'sentimento_codificado' antes da exclusão: 0
2024-12-10 18:34:59,485 - INFO - Número de linhas restantes após a remoção de NaNs: 91394
2024-12-10 18:34:59,485 - INFO - Contando sentimentos positivos, neutros e negativos.
2024-12-10 18:34:59,487 - INFO - Sentimentos positivos: 15112
2024-12-10 18:34:59,487 - INFO - Sentimentos neutros: 33971
2024-12-10 18:34:59,487 - INFO - Sentimentos negativos: 42311
2024-12-10 18:34:59,497 - INFO - Amostra salva com sucesso.
2024-12-10 18:35:13,383 - INFO - Dataset salvo com sucesso.
2024-12-10 18:35:13,448 - INFO - Todos os blocos processados e combinados com sucesso.
2024-12-10 18:35:13,464 - INFO - Gerando relatórios.
2024-12-10 18:35:13,573 - INFO - Relatórios gerados com sucesso.
2024-12-10 18:47:54,000 - INFO - Carregando o dataset bruto.
2024-12-10 18:47:54,036 - INFO - Dataset carregado com sucesso com 20000 linhas.
2024-12-10 18:47:54,036 - INFO - Renomeando colunas.
2024-12-10 18:47:54,070 - INFO - Total de linhas a serem processadas: 20000
2024-12-10 18:47:54,071 - INFO - Total de blocos a serem processados: 2
2024-12-10 18:47:54,097 - INFO - Processando bloco 1 de 2
2024-12-10 18:47:54,097 - INFO - Pré-processando os dados.
2024-12-10 18:48:39,321 - INFO - Normalizando os textos.
2024-12-10 18:49:55,426 - INFO - Carregando o dataset bruto.
2024-12-10 18:49:55,449 - INFO - Dataset carregado com sucesso com 200000 linhas.
2024-12-10 18:49:55,449 - INFO - Renomeando colunas.
2024-12-10 18:49:55,689 - INFO - Total de linhas a serem processadas: 200000
2024-12-10 18:49:55,689 - INFO - Total de blocos a serem processados: 20
2024-12-10 18:49:55,888 - INFO - Processando bloco 1 de 20
2024-12-10 18:49:55,888 - INFO - Pré-processando os dados.
2024-12-10 18:50:38,637 - INFO - Normalizando os textos.
2024-12-10 18:50:58,284 - INFO - Tokenizando os textos.
2024-12-10 18:51:40,825 - INFO - Criando bigramas.
2024-12-10 18:51:41,583 - INFO - Removendo stopwords.
2024-12-10 18:51:41,865 - INFO - Aplicando stemming.
2024-12-10 18:51:42,601 - INFO - Aplicando lematização.
2024-12-10 18:52:20,612 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 18:52:20,644 - INFO - Classificando sentimentos usando BERT.
2024-12-10 18:57:09,705 - INFO - Codificando sentimentos.
2024-12-10 18:57:09,705 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 18:57:09,833 - INFO - Bloco 1 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_1.parquet
2024-12-10 18:57:09,833 - INFO - Tempo médio por bloco: 0 horas, 7 minutos, 14.04 segundos
2024-12-10 18:57:09,833 - INFO - Tempo total estimado: 2 horas, 24 minutos, 40.77 segundos
2024-12-10 18:57:10,059 - INFO - Processando bloco 2 de 20
2024-12-10 18:57:10,059 - INFO - Pré-processando os dados.
2024-12-10 18:57:56,765 - INFO - Normalizando os textos.
2024-12-10 18:58:16,358 - INFO - Tokenizando os textos.
2024-12-10 18:58:55,686 - INFO - Criando bigramas.
2024-12-10 18:58:56,423 - INFO - Removendo stopwords.
2024-12-10 18:58:56,460 - INFO - Aplicando stemming.
2024-12-10 18:58:57,111 - INFO - Aplicando lematização.
2024-12-10 18:59:29,695 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 18:59:29,722 - INFO - Classificando sentimentos usando BERT.
2024-12-10 19:04:09,774 - INFO - Codificando sentimentos.
2024-12-10 19:04:09,774 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 19:04:09,906 - INFO - Bloco 2 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_2.parquet
2024-12-10 19:04:10,150 - INFO - Processando bloco 3 de 20
2024-12-10 19:04:10,150 - INFO - Pré-processando os dados.
2024-12-10 19:04:56,115 - INFO - Normalizando os textos.
2024-12-10 19:05:15,618 - INFO - Tokenizando os textos.
2024-12-10 19:05:54,802 - INFO - Criando bigramas.
2024-12-10 19:05:55,554 - INFO - Removendo stopwords.
2024-12-10 19:05:55,590 - INFO - Aplicando stemming.
2024-12-10 19:05:56,259 - INFO - Aplicando lematização.
2024-12-10 19:06:29,218 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 19:06:29,251 - INFO - Classificando sentimentos usando BERT.
2024-12-10 19:11:10,348 - INFO - Codificando sentimentos.
2024-12-10 19:11:10,348 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 19:11:10,482 - INFO - Bloco 3 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_3.parquet
2024-12-10 19:11:10,708 - INFO - Processando bloco 4 de 20
2024-12-10 19:11:10,708 - INFO - Pré-processando os dados.
2024-12-10 19:11:56,479 - INFO - Normalizando os textos.
2024-12-10 19:12:16,126 - INFO - Tokenizando os textos.
2024-12-10 19:12:55,778 - INFO - Criando bigramas.
2024-12-10 19:12:56,533 - INFO - Removendo stopwords.
2024-12-10 19:12:56,564 - INFO - Aplicando stemming.
2024-12-10 19:12:57,223 - INFO - Aplicando lematização.
2024-12-10 19:13:30,734 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 19:13:30,752 - INFO - Classificando sentimentos usando BERT.
2024-12-10 19:18:15,756 - INFO - Codificando sentimentos.
2024-12-10 19:18:15,756 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 19:18:15,888 - INFO - Bloco 4 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_4.parquet
2024-12-10 19:18:16,134 - INFO - Processando bloco 5 de 20
2024-12-10 19:18:16,134 - INFO - Pré-processando os dados.
2024-12-10 19:19:04,068 - INFO - Normalizando os textos.
2024-12-10 19:19:23,924 - INFO - Tokenizando os textos.
2024-12-10 19:20:03,099 - INFO - Criando bigramas.
2024-12-10 19:20:03,848 - INFO - Removendo stopwords.
2024-12-10 19:20:03,887 - INFO - Aplicando stemming.
2024-12-10 19:20:04,536 - INFO - Aplicando lematização.
2024-12-10 19:20:37,362 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 19:20:37,393 - INFO - Classificando sentimentos usando BERT.
2024-12-10 19:25:18,974 - INFO - Codificando sentimentos.
2024-12-10 19:25:18,974 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 19:25:19,096 - INFO - Bloco 5 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_5.parquet
2024-12-10 19:25:19,328 - INFO - Processando bloco 6 de 20
2024-12-10 19:25:19,328 - INFO - Pré-processando os dados.
2024-12-10 19:26:05,826 - INFO - Normalizando os textos.
2024-12-10 19:26:25,856 - INFO - Tokenizando os textos.
2024-12-10 19:27:05,128 - INFO - Criando bigramas.
2024-12-10 19:27:05,885 - INFO - Removendo stopwords.
2024-12-10 19:27:05,918 - INFO - Aplicando stemming.
2024-12-10 19:27:06,582 - INFO - Aplicando lematização.
2024-12-10 19:27:39,485 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 19:27:39,506 - INFO - Classificando sentimentos usando BERT.
2024-12-10 19:32:24,443 - INFO - Codificando sentimentos.
2024-12-10 19:32:24,443 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 19:32:24,570 - INFO - Bloco 6 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_6.parquet
2024-12-10 19:32:24,820 - INFO - Processando bloco 7 de 20
2024-12-10 19:32:24,820 - INFO - Pré-processando os dados.
2024-12-10 19:33:11,382 - INFO - Normalizando os textos.
2024-12-10 19:33:30,863 - INFO - Tokenizando os textos.
2024-12-10 19:34:09,715 - INFO - Criando bigramas.
2024-12-10 19:34:10,469 - INFO - Removendo stopwords.
2024-12-10 19:34:10,491 - INFO - Aplicando stemming.
2024-12-10 19:34:11,143 - INFO - Aplicando lematização.
2024-12-10 19:34:43,914 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 19:34:43,943 - INFO - Classificando sentimentos usando BERT.
2024-12-10 19:39:24,904 - INFO - Codificando sentimentos.
2024-12-10 19:39:24,904 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 19:39:25,028 - INFO - Bloco 7 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_7.parquet
2024-12-10 19:39:25,274 - INFO - Processando bloco 8 de 20
2024-12-10 19:39:25,274 - INFO - Pré-processando os dados.
2024-12-10 19:40:12,162 - INFO - Normalizando os textos.
2024-12-10 19:40:31,996 - INFO - Tokenizando os textos.
2024-12-10 19:41:10,903 - INFO - Criando bigramas.
2024-12-10 19:41:11,905 - INFO - Removendo stopwords.
2024-12-10 19:41:11,934 - INFO - Aplicando stemming.
2024-12-10 19:41:12,593 - INFO - Aplicando lematização.
2024-12-10 19:41:45,403 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 19:41:45,424 - INFO - Classificando sentimentos usando BERT.
2024-12-10 19:46:29,836 - INFO - Codificando sentimentos.
2024-12-10 19:46:29,836 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 19:46:29,970 - INFO - Bloco 8 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_8.parquet
2024-12-10 19:46:30,212 - INFO - Processando bloco 9 de 20
2024-12-10 19:46:30,212 - INFO - Pré-processando os dados.
2024-12-10 19:47:16,468 - INFO - Normalizando os textos.
2024-12-10 19:47:37,213 - INFO - Tokenizando os textos.
2024-12-10 19:48:16,701 - INFO - Criando bigramas.
2024-12-10 19:48:17,464 - INFO - Removendo stopwords.
2024-12-10 19:48:17,492 - INFO - Aplicando stemming.
2024-12-10 19:48:18,172 - INFO - Aplicando lematização.
2024-12-10 19:48:51,708 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 19:48:51,729 - INFO - Classificando sentimentos usando BERT.
2024-12-10 19:53:40,209 - INFO - Codificando sentimentos.
2024-12-10 19:53:40,209 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 19:53:40,344 - INFO - Bloco 9 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_9.parquet
2024-12-10 19:53:40,572 - INFO - Processando bloco 10 de 20
2024-12-10 19:53:40,572 - INFO - Pré-processando os dados.
2024-12-10 19:54:27,750 - INFO - Normalizando os textos.
2024-12-10 19:54:47,885 - INFO - Tokenizando os textos.
2024-12-10 19:55:27,065 - INFO - Criando bigramas.
2024-12-10 19:55:27,822 - INFO - Removendo stopwords.
2024-12-10 19:55:27,850 - INFO - Aplicando stemming.
2024-12-10 19:55:28,511 - INFO - Aplicando lematização.
2024-12-10 19:56:01,492 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 19:56:01,508 - INFO - Classificando sentimentos usando BERT.
2024-12-10 20:00:48,258 - INFO - Codificando sentimentos.
2024-12-10 20:00:48,260 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 20:00:48,403 - INFO - Bloco 10 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_10.parquet
2024-12-10 20:00:48,660 - INFO - Processando bloco 11 de 20
2024-12-10 20:00:48,660 - INFO - Pré-processando os dados.
2024-12-10 20:01:38,219 - INFO - Normalizando os textos.
2024-12-10 20:01:58,214 - INFO - Tokenizando os textos.
2024-12-10 20:02:37,282 - INFO - Criando bigramas.
2024-12-10 20:02:38,048 - INFO - Removendo stopwords.
2024-12-10 20:02:38,070 - INFO - Aplicando stemming.
2024-12-10 20:02:38,744 - INFO - Aplicando lematização.
2024-12-10 20:03:11,954 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 20:03:11,976 - INFO - Classificando sentimentos usando BERT.
2024-12-10 20:07:54,464 - INFO - Codificando sentimentos.
2024-12-10 20:07:54,464 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 20:07:54,593 - INFO - Bloco 11 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_11.parquet
2024-12-10 20:07:54,839 - INFO - Processando bloco 12 de 20
2024-12-10 20:07:54,839 - INFO - Pré-processando os dados.
2024-12-10 20:08:41,072 - INFO - Normalizando os textos.
2024-12-10 20:09:01,356 - INFO - Tokenizando os textos.
2024-12-10 20:09:40,399 - INFO - Criando bigramas.
2024-12-10 20:09:41,151 - INFO - Removendo stopwords.
2024-12-10 20:09:41,189 - INFO - Aplicando stemming.
2024-12-10 20:09:41,851 - INFO - Aplicando lematização.
2024-12-10 20:10:14,694 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 20:10:14,725 - INFO - Classificando sentimentos usando BERT.
2024-12-10 20:14:56,925 - INFO - Codificando sentimentos.
2024-12-10 20:14:56,925 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 20:14:57,050 - INFO - Bloco 12 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_12.parquet
2024-12-10 20:14:57,300 - INFO - Processando bloco 13 de 20
2024-12-10 20:14:57,300 - INFO - Pré-processando os dados.
2024-12-10 20:15:44,266 - INFO - Normalizando os textos.
2024-12-10 20:16:04,131 - INFO - Tokenizando os textos.
2024-12-10 20:16:43,200 - INFO - Criando bigramas.
2024-12-10 20:16:43,953 - INFO - Removendo stopwords.
2024-12-10 20:16:43,990 - INFO - Aplicando stemming.
2024-12-10 20:16:44,643 - INFO - Aplicando lematização.
2024-12-10 20:17:17,476 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 20:17:17,512 - INFO - Classificando sentimentos usando BERT.
2024-12-10 20:22:00,110 - INFO - Codificando sentimentos.
2024-12-10 20:22:00,110 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 20:22:00,260 - INFO - Bloco 13 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_13.parquet
2024-12-10 20:22:00,489 - INFO - Processando bloco 14 de 20
2024-12-10 20:22:00,489 - INFO - Pré-processando os dados.
2024-12-10 20:22:46,603 - INFO - Normalizando os textos.
2024-12-10 20:23:06,673 - INFO - Tokenizando os textos.
2024-12-10 20:23:46,001 - INFO - Criando bigramas.
2024-12-10 20:23:46,772 - INFO - Removendo stopwords.
2024-12-10 20:23:46,794 - INFO - Aplicando stemming.
2024-12-10 20:23:47,471 - INFO - Aplicando lematização.
2024-12-10 20:24:20,496 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 20:24:20,517 - INFO - Classificando sentimentos usando BERT.
2024-12-10 20:29:04,542 - INFO - Codificando sentimentos.
2024-12-10 20:29:04,542 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 20:29:04,682 - INFO - Bloco 14 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_14.parquet
2024-12-10 20:29:04,927 - INFO - Processando bloco 15 de 20
2024-12-10 20:29:04,927 - INFO - Pré-processando os dados.
2024-12-10 20:29:51,178 - INFO - Normalizando os textos.
2024-12-10 20:30:11,860 - INFO - Tokenizando os textos.
2024-12-10 20:30:51,482 - INFO - Criando bigramas.
2024-12-10 20:30:52,245 - INFO - Removendo stopwords.
2024-12-10 20:30:52,268 - INFO - Aplicando stemming.
2024-12-10 20:30:53,194 - INFO - Aplicando lematização.
2024-12-10 20:31:26,635 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 20:31:26,659 - INFO - Classificando sentimentos usando BERT.
2024-12-10 20:36:10,745 - INFO - Codificando sentimentos.
2024-12-10 20:36:10,747 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 20:36:10,872 - INFO - Bloco 15 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_15.parquet
2024-12-10 20:36:11,104 - INFO - Processando bloco 16 de 20
2024-12-10 20:36:11,104 - INFO - Pré-processando os dados.
2024-12-10 20:36:58,214 - INFO - Normalizando os textos.
2024-12-10 20:37:18,256 - INFO - Tokenizando os textos.
2024-12-10 20:37:57,335 - INFO - Criando bigramas.
2024-12-10 20:37:58,101 - INFO - Removendo stopwords.
2024-12-10 20:37:58,124 - INFO - Aplicando stemming.
2024-12-10 20:37:58,786 - INFO - Aplicando lematização.
2024-12-10 20:38:31,552 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 20:38:31,568 - INFO - Classificando sentimentos usando BERT.
2024-12-10 20:43:12,650 - INFO - Codificando sentimentos.
2024-12-10 20:43:12,650 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 20:43:12,781 - INFO - Bloco 16 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_16.parquet
2024-12-10 20:43:13,011 - INFO - Processando bloco 17 de 20
2024-12-10 20:43:13,011 - INFO - Pré-processando os dados.
2024-12-10 20:43:59,829 - INFO - Normalizando os textos.
2024-12-10 20:44:19,780 - INFO - Tokenizando os textos.
2024-12-10 20:44:59,009 - INFO - Criando bigramas.
2024-12-10 20:44:59,766 - INFO - Removendo stopwords.
2024-12-10 20:44:59,785 - INFO - Aplicando stemming.
2024-12-10 20:45:00,452 - INFO - Aplicando lematização.
2024-12-10 20:45:33,341 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 20:45:33,356 - INFO - Classificando sentimentos usando BERT.
2024-12-10 20:50:16,881 - INFO - Codificando sentimentos.
2024-12-10 20:50:16,881 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 20:50:17,021 - INFO - Bloco 17 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_17.parquet
2024-12-10 20:50:17,256 - INFO - Processando bloco 18 de 20
2024-12-10 20:50:17,272 - INFO - Pré-processando os dados.
2024-12-10 20:51:03,850 - INFO - Normalizando os textos.
2024-12-10 20:51:23,866 - INFO - Tokenizando os textos.
2024-12-10 20:52:03,020 - INFO - Criando bigramas.
2024-12-10 20:52:03,770 - INFO - Removendo stopwords.
2024-12-10 20:52:03,792 - INFO - Aplicando stemming.
2024-12-10 20:52:04,443 - INFO - Aplicando lematização.
2024-12-10 20:52:37,218 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 20:52:37,241 - INFO - Classificando sentimentos usando BERT.
2024-12-10 20:57:20,429 - INFO - Codificando sentimentos.
2024-12-10 20:57:20,440 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 20:57:20,566 - INFO - Bloco 18 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_18.parquet
2024-12-10 20:57:20,795 - INFO - Processando bloco 19 de 20
2024-12-10 20:57:20,795 - INFO - Pré-processando os dados.
2024-12-10 20:58:08,309 - INFO - Normalizando os textos.
2024-12-10 20:58:28,078 - INFO - Tokenizando os textos.
2024-12-10 20:59:07,324 - INFO - Criando bigramas.
2024-12-10 20:59:08,074 - INFO - Removendo stopwords.
2024-12-10 20:59:08,096 - INFO - Aplicando stemming.
2024-12-10 20:59:08,756 - INFO - Aplicando lematização.
2024-12-10 20:59:41,441 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 20:59:41,462 - INFO - Classificando sentimentos usando BERT.
2024-12-10 21:04:47,594 - INFO - Codificando sentimentos.
2024-12-10 21:04:47,594 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 21:04:47,738 - INFO - Bloco 19 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_19.parquet
2024-12-10 21:04:47,983 - INFO - Processando bloco 20 de 20
2024-12-10 21:04:47,983 - INFO - Pré-processando os dados.
2024-12-10 21:05:36,688 - INFO - Normalizando os textos.
2024-12-10 21:05:57,719 - INFO - Tokenizando os textos.
2024-12-10 21:06:37,754 - INFO - Criando bigramas.
2024-12-10 21:06:38,513 - INFO - Removendo stopwords.
2024-12-10 21:06:38,536 - INFO - Aplicando stemming.
2024-12-10 21:06:39,202 - INFO - Aplicando lematização.
2024-12-10 21:07:11,715 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 21:07:11,737 - INFO - Classificando sentimentos usando BERT.
2024-12-10 21:12:10,385 - INFO - Codificando sentimentos.
2024-12-10 21:12:10,385 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-10 21:12:10,526 - INFO - Bloco 20 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_20.parquet
2024-12-10 21:12:10,526 - INFO - Tempo médio por bloco (recalculado): 0 horas, 7 minutos, 6.62 segundos
2024-12-10 21:12:10,526 - INFO - Tempo total estimado (recalculado): 2 horas, 22 minutos, 12.41 segundos
2024-12-10 21:12:10,543 - INFO - Salvando dataset processado.
2024-12-10 21:12:12,093 - INFO - Número de linhas com NaN em 'sentimento_codificado' antes da exclusão: 0
2024-12-10 21:12:12,163 - INFO - Número de linhas restantes após a remoção de NaNs: 182398
2024-12-10 21:12:12,163 - INFO - Contando sentimentos positivos, neutros e negativos.
2024-12-10 21:12:12,189 - INFO - Sentimentos positivos: 29731
2024-12-10 21:12:12,189 - INFO - Sentimentos neutros: 67642
2024-12-10 21:12:12,189 - INFO - Sentimentos negativos: 85025
2024-12-10 21:12:12,211 - INFO - Amostra salva com sucesso.
2024-12-10 21:12:40,254 - INFO - Dataset salvo com sucesso.
2024-12-10 21:12:40,377 - INFO - Todos os blocos processados e combinados com sucesso.
2024-12-10 21:12:40,378 - INFO - Gerando relatórios.
2024-12-10 21:12:40,651 - INFO - Relatórios gerados com sucesso.
2024-12-10 22:09:56,850 - INFO -  * Running on http://127.0.0.1:5000 (Press CTRL+C to quit)
2024-12-10 22:09:56,851 - INFO -  * Restarting with stat
2024-12-10 22:10:06,557 - WARNING -  * Debugger is active!
2024-12-10 22:10:06,561 - INFO -  * Debugger PIN: 708-303-649
2024-12-10 22:10:06,840 - INFO - 127.0.0.1 - - [10/Dec/2024 22:10:06] "GET / HTTP/1.1" 200 -
2024-12-10 22:10:06,840 - INFO - 127.0.0.1 - - [10/Dec/2024 22:10:06] "GET / HTTP/1.1" 200 -
2024-12-10 22:10:06,855 - INFO - 127.0.0.1 - - [10/Dec/2024 22:10:06] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 22:10:06,874 - INFO - 127.0.0.1 - - [10/Dec/2024 22:10:06] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2024-12-10 22:10:21,021 - INFO - 127.0.0.1 - - [10/Dec/2024 22:10:21] "POST /predict HTTP/1.1" 200 -
2024-12-10 22:10:21,028 - INFO - 127.0.0.1 - - [10/Dec/2024 22:10:21] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 22:10:39,601 - INFO - 127.0.0.1 - - [10/Dec/2024 22:10:39] "POST /predict HTTP/1.1" 200 -
2024-12-10 22:10:39,604 - INFO - 127.0.0.1 - - [10/Dec/2024 22:10:39] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 22:10:58,532 - INFO - 127.0.0.1 - - [10/Dec/2024 22:10:58] "POST /predict HTTP/1.1" 200 -
2024-12-10 22:10:58,537 - INFO - 127.0.0.1 - - [10/Dec/2024 22:10:58] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 22:11:10,838 - INFO - 127.0.0.1 - - [10/Dec/2024 22:11:10] "POST /predict HTTP/1.1" 200 -
2024-12-10 22:11:10,856 - INFO - 127.0.0.1 - - [10/Dec/2024 22:11:10] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 22:11:26,696 - INFO - 127.0.0.1 - - [10/Dec/2024 22:11:26] "POST /predict HTTP/1.1" 200 -
2024-12-10 22:11:26,703 - INFO - 127.0.0.1 - - [10/Dec/2024 22:11:26] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 22:11:53,033 - INFO - 127.0.0.1 - - [10/Dec/2024 22:11:53] "POST /predict HTTP/1.1" 200 -
2024-12-10 22:11:53,036 - INFO - 127.0.0.1 - - [10/Dec/2024 22:11:53] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 22:12:08,582 - INFO - 127.0.0.1 - - [10/Dec/2024 22:12:08] "POST /predict HTTP/1.1" 200 -
2024-12-10 22:12:08,585 - INFO - 127.0.0.1 - - [10/Dec/2024 22:12:08] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 22:12:32,253 - INFO - 127.0.0.1 - - [10/Dec/2024 22:12:32] "POST /predict HTTP/1.1" 200 -
2024-12-10 22:12:32,253 - INFO - 127.0.0.1 - - [10/Dec/2024 22:12:32] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 22:12:37,664 - INFO - 127.0.0.1 - - [10/Dec/2024 22:12:37] "POST /predict HTTP/1.1" 200 -
2024-12-10 22:12:37,668 - INFO - 127.0.0.1 - - [10/Dec/2024 22:12:37] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 22:12:51,337 - INFO - 127.0.0.1 - - [10/Dec/2024 22:12:51] "POST /predict HTTP/1.1" 200 -
2024-12-10 22:12:51,343 - INFO - 127.0.0.1 - - [10/Dec/2024 22:12:51] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 22:13:05,486 - INFO - 127.0.0.1 - - [10/Dec/2024 22:13:05] "POST /predict HTTP/1.1" 200 -
2024-12-10 22:13:05,503 - INFO - 127.0.0.1 - - [10/Dec/2024 22:13:05] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 22:13:25,922 - INFO - 127.0.0.1 - - [10/Dec/2024 22:13:25] "POST /predict HTTP/1.1" 200 -
2024-12-10 22:13:25,929 - INFO - 127.0.0.1 - - [10/Dec/2024 22:13:25] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 22:13:45,384 - INFO - 127.0.0.1 - - [10/Dec/2024 22:13:45] "POST /predict HTTP/1.1" 200 -
2024-12-10 22:13:45,384 - INFO - 127.0.0.1 - - [10/Dec/2024 22:13:45] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 22:14:03,650 - INFO - 127.0.0.1 - - [10/Dec/2024 22:14:03] "POST /predict HTTP/1.1" 200 -
2024-12-10 22:14:03,650 - INFO - 127.0.0.1 - - [10/Dec/2024 22:14:03] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 22:14:33,304 - INFO - 127.0.0.1 - - [10/Dec/2024 22:14:33] "POST /predict HTTP/1.1" 200 -
2024-12-10 22:14:33,311 - INFO - 127.0.0.1 - - [10/Dec/2024 22:14:33] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 22:14:57,124 - INFO - 127.0.0.1 - - [10/Dec/2024 22:14:57] "POST /predict HTTP/1.1" 200 -
2024-12-10 22:14:57,131 - INFO - 127.0.0.1 - - [10/Dec/2024 22:14:57] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 22:15:12,161 - INFO - 127.0.0.1 - - [10/Dec/2024 22:15:12] "POST /predict HTTP/1.1" 200 -
2024-12-10 22:15:12,165 - INFO - 127.0.0.1 - - [10/Dec/2024 22:15:12] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 22:15:37,287 - INFO - 127.0.0.1 - - [10/Dec/2024 22:15:37] "POST /predict HTTP/1.1" 200 -
2024-12-10 22:15:37,294 - INFO - 127.0.0.1 - - [10/Dec/2024 22:15:37] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 22:16:08,539 - INFO - 127.0.0.1 - - [10/Dec/2024 22:16:08] "POST /predict HTTP/1.1" 200 -
2024-12-10 22:16:08,546 - INFO - 127.0.0.1 - - [10/Dec/2024 22:16:08] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 22:16:24,067 - INFO - 127.0.0.1 - - [10/Dec/2024 22:16:24] "POST /predict HTTP/1.1" 200 -
2024-12-10 22:16:24,074 - INFO - 127.0.0.1 - - [10/Dec/2024 22:16:24] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 22:16:57,863 - INFO - 127.0.0.1 - - [10/Dec/2024 22:16:57] "POST /predict HTTP/1.1" 200 -
2024-12-10 22:16:57,863 - INFO - 127.0.0.1 - - [10/Dec/2024 22:16:57] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 22:21:22,539 - INFO -  * Running on http://127.0.0.1:5000 (Press CTRL+C to quit)
2024-12-10 22:21:22,545 - INFO -  * Restarting with stat
2024-12-10 22:21:32,068 - WARNING -  * Debugger is active!
2024-12-10 22:21:32,073 - INFO -  * Debugger PIN: 708-303-649
2024-12-10 22:21:32,442 - INFO - 127.0.0.1 - - [10/Dec/2024 22:21:32] "GET / HTTP/1.1" 200 -
2024-12-10 22:21:32,481 - INFO - 127.0.0.1 - - [10/Dec/2024 22:21:32] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 22:21:32,497 - INFO - 127.0.0.1 - - [10/Dec/2024 22:21:32] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2024-12-10 22:21:49,590 - INFO - 127.0.0.1 - - [10/Dec/2024 22:21:49] "POST /predict HTTP/1.1" 200 -
2024-12-10 22:21:49,600 - INFO - 127.0.0.1 - - [10/Dec/2024 22:21:49] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 22:22:24,930 - INFO - 127.0.0.1 - - [10/Dec/2024 22:22:24] "POST /predict HTTP/1.1" 200 -
2024-12-10 22:22:24,936 - INFO - 127.0.0.1 - - [10/Dec/2024 22:22:24] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 22:23:24,438 - INFO - 127.0.0.1 - - [10/Dec/2024 22:23:24] "POST /predict HTTP/1.1" 200 -
2024-12-10 22:23:24,438 - INFO - 127.0.0.1 - - [10/Dec/2024 22:23:24] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 22:23:29,038 - INFO - 127.0.0.1 - - [10/Dec/2024 22:23:29] "POST /predict HTTP/1.1" 200 -
2024-12-10 22:23:29,038 - INFO - 127.0.0.1 - - [10/Dec/2024 22:23:29] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 22:24:12,020 - INFO - 127.0.0.1 - - [10/Dec/2024 22:24:12] "POST /predict HTTP/1.1" 200 -
2024-12-10 22:24:12,021 - INFO - 127.0.0.1 - - [10/Dec/2024 22:24:12] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 22:24:32,973 - INFO - 127.0.0.1 - - [10/Dec/2024 22:24:32] "POST /predict HTTP/1.1" 200 -
2024-12-10 22:24:32,978 - INFO - 127.0.0.1 - - [10/Dec/2024 22:24:32] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 22:24:52,342 - INFO - 127.0.0.1 - - [10/Dec/2024 22:24:52] "POST /predict HTTP/1.1" 200 -
2024-12-10 22:24:52,348 - INFO - 127.0.0.1 - - [10/Dec/2024 22:24:52] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 22:25:07,203 - INFO - 127.0.0.1 - - [10/Dec/2024 22:25:07] "POST /predict HTTP/1.1" 200 -
2024-12-10 22:25:07,209 - INFO - 127.0.0.1 - - [10/Dec/2024 22:25:07] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-10 22:25:36,087 - INFO - 127.0.0.1 - - [10/Dec/2024 22:25:36] "POST /predict HTTP/1.1" 200 -
2024-12-10 22:25:36,093 - INFO - 127.0.0.1 - - [10/Dec/2024 22:25:36] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-11 13:16:28,637 - INFO - Carregando o dataset bruto.
2024-12-11 13:16:28,705 - INFO - Dataset carregado com sucesso com 200000 linhas.
2024-12-11 13:16:28,706 - INFO - Renomeando colunas.
2024-12-11 13:16:28,976 - INFO - Total de linhas a serem processadas: 200000
2024-12-11 13:16:28,992 - INFO - Total de blocos a serem processados: 20
2024-12-11 13:16:29,198 - INFO - Processando bloco 1 de 20
2024-12-11 13:16:29,198 - INFO - Pré-processando os dados.
2024-12-11 13:17:11,858 - INFO - Normalizando os textos.
2024-12-11 13:17:31,224 - INFO - Tokenizando os textos.
2024-12-11 13:18:11,631 - INFO - Criando bigramas.
2024-12-11 13:18:12,415 - INFO - Removendo stopwords.
2024-12-11 13:18:12,690 - INFO - Aplicando stemming.
2024-12-11 13:18:13,356 - INFO - Aplicando lematização.
2024-12-11 13:18:46,143 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 13:18:46,159 - INFO - Classificando sentimentos usando VADER, BERT e TextBlob.
2024-12-11 13:24:13,168 - INFO - Codificando sentimentos.
2024-12-11 13:24:13,184 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 13:24:13,294 - INFO - Bloco 1 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_1.parquet
2024-12-11 13:24:13,294 - INFO - Tempo médio por bloco: 0 horas, 7 minutos, 44.19 segundos
2024-12-11 13:24:13,294 - INFO - Tempo total estimado: 2 horas, 34 minutos, 43.84 segundos
2024-12-11 13:24:13,537 - INFO - Processando bloco 2 de 20
2024-12-11 13:24:13,537 - INFO - Pré-processando os dados.
2024-12-11 13:24:59,629 - INFO - Normalizando os textos.
2024-12-11 13:25:19,904 - INFO - Tokenizando os textos.
2024-12-11 13:26:01,002 - INFO - Criando bigramas.
2024-12-11 13:26:01,754 - INFO - Removendo stopwords.
2024-12-11 13:26:01,782 - INFO - Aplicando stemming.
2024-12-11 13:26:02,429 - INFO - Aplicando lematização.
2024-12-11 13:26:34,792 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 13:26:34,814 - INFO - Classificando sentimentos usando VADER, BERT e TextBlob.
2024-12-11 13:31:53,209 - INFO - Codificando sentimentos.
2024-12-11 13:31:53,209 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 13:31:53,334 - INFO - Bloco 2 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_2.parquet
2024-12-11 13:31:53,545 - INFO - Processando bloco 3 de 20
2024-12-11 13:31:53,545 - INFO - Pré-processando os dados.
2024-12-11 13:32:39,136 - INFO - Normalizando os textos.
2024-12-11 13:32:58,955 - INFO - Tokenizando os textos.
2024-12-11 13:33:37,952 - INFO - Criando bigramas.
2024-12-11 13:33:38,736 - INFO - Removendo stopwords.
2024-12-11 13:33:38,772 - INFO - Aplicando stemming.
2024-12-11 13:33:39,426 - INFO - Aplicando lematização.
2024-12-11 13:34:12,040 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 13:34:12,061 - INFO - Classificando sentimentos usando VADER, BERT e TextBlob.
2024-12-11 13:39:47,327 - INFO - Codificando sentimentos.
2024-12-11 13:39:47,342 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 13:39:47,458 - INFO - Bloco 3 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_3.parquet
2024-12-11 13:39:47,700 - INFO - Processando bloco 4 de 20
2024-12-11 13:39:47,700 - INFO - Pré-processando os dados.
2024-12-11 13:40:33,355 - INFO - Normalizando os textos.
2024-12-11 13:40:53,600 - INFO - Tokenizando os textos.
2024-12-11 13:41:35,216 - INFO - Criando bigramas.
2024-12-11 13:41:35,996 - INFO - Removendo stopwords.
2024-12-11 13:41:36,028 - INFO - Aplicando stemming.
2024-12-11 13:41:36,967 - INFO - Aplicando lematização.
2024-12-11 13:42:11,724 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 13:42:11,746 - INFO - Classificando sentimentos usando VADER, BERT e TextBlob.
2024-12-11 13:48:21,859 - INFO - Codificando sentimentos.
2024-12-11 13:48:21,859 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 13:48:21,980 - INFO - Bloco 4 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_4.parquet
2024-12-11 13:48:22,224 - INFO - Processando bloco 5 de 20
2024-12-11 13:48:22,224 - INFO - Pré-processando os dados.
2024-12-11 13:49:10,278 - INFO - Normalizando os textos.
2024-12-11 13:49:30,837 - INFO - Tokenizando os textos.
2024-12-11 13:50:12,093 - INFO - Criando bigramas.
2024-12-11 13:50:12,868 - INFO - Removendo stopwords.
2024-12-11 13:50:12,901 - INFO - Aplicando stemming.
2024-12-11 13:50:13,558 - INFO - Aplicando lematização.
2024-12-11 13:50:47,977 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 13:50:48,010 - INFO - Classificando sentimentos usando VADER, BERT e TextBlob.
2024-12-11 13:56:23,947 - INFO - Codificando sentimentos.
2024-12-11 13:56:23,947 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 13:56:24,087 - INFO - Bloco 5 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_5.parquet
2024-12-11 13:56:24,312 - INFO - Processando bloco 6 de 20
2024-12-11 13:56:24,312 - INFO - Pré-processando os dados.
2024-12-11 13:57:09,907 - INFO - Normalizando os textos.
2024-12-11 13:57:29,914 - INFO - Tokenizando os textos.
2024-12-11 13:58:08,911 - INFO - Criando bigramas.
2024-12-11 13:58:09,684 - INFO - Removendo stopwords.
2024-12-11 13:58:09,723 - INFO - Aplicando stemming.
2024-12-11 13:58:10,385 - INFO - Aplicando lematização.
2024-12-11 13:58:49,100 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 13:58:49,122 - INFO - Classificando sentimentos usando VADER, BERT e TextBlob.
2024-12-11 14:04:28,765 - INFO - Codificando sentimentos.
2024-12-11 14:04:28,765 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 14:04:28,894 - INFO - Bloco 6 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_6.parquet
2024-12-11 14:04:29,107 - INFO - Processando bloco 7 de 20
2024-12-11 14:04:29,123 - INFO - Pré-processando os dados.
2024-12-11 14:05:14,878 - INFO - Normalizando os textos.
2024-12-11 14:05:34,478 - INFO - Tokenizando os textos.
2024-12-11 14:06:12,978 - INFO - Criando bigramas.
2024-12-11 14:06:13,740 - INFO - Removendo stopwords.
2024-12-11 14:06:13,762 - INFO - Aplicando stemming.
2024-12-11 14:06:14,424 - INFO - Aplicando lematização.
2024-12-11 14:06:46,810 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 14:06:46,842 - INFO - Classificando sentimentos usando VADER, BERT e TextBlob.
2024-12-11 14:12:04,900 - INFO - Codificando sentimentos.
2024-12-11 14:12:04,900 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 14:12:05,036 - INFO - Bloco 7 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_7.parquet
2024-12-11 14:12:05,259 - INFO - Processando bloco 8 de 20
2024-12-11 14:12:05,275 - INFO - Pré-processando os dados.
2024-12-11 14:12:51,296 - INFO - Normalizando os textos.
2024-12-11 14:13:11,007 - INFO - Tokenizando os textos.
2024-12-11 14:13:49,815 - INFO - Criando bigramas.
2024-12-11 14:13:50,581 - INFO - Removendo stopwords.
2024-12-11 14:13:50,621 - INFO - Aplicando stemming.
2024-12-11 14:13:51,266 - INFO - Aplicando lematização.
2024-12-11 14:14:23,557 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 14:14:23,580 - INFO - Classificando sentimentos usando VADER, BERT e TextBlob.
2024-12-11 14:19:41,788 - INFO - Codificando sentimentos.
2024-12-11 14:19:41,788 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 14:19:41,910 - INFO - Bloco 8 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_8.parquet
2024-12-11 14:19:42,133 - INFO - Processando bloco 9 de 20
2024-12-11 14:19:42,133 - INFO - Pré-processando os dados.
2024-12-11 14:20:27,370 - INFO - Normalizando os textos.
2024-12-11 14:20:48,084 - INFO - Tokenizando os textos.
2024-12-11 14:21:27,189 - INFO - Criando bigramas.
2024-12-11 14:21:27,972 - INFO - Removendo stopwords.
2024-12-11 14:21:27,995 - INFO - Aplicando stemming.
2024-12-11 14:21:28,688 - INFO - Aplicando lematização.
2024-12-11 14:22:01,404 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 14:22:01,420 - INFO - Classificando sentimentos usando VADER, BERT e TextBlob.
2024-12-11 14:27:22,973 - INFO - Codificando sentimentos.
2024-12-11 14:27:22,973 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 14:27:23,120 - INFO - Bloco 9 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_9.parquet
2024-12-11 14:27:23,340 - INFO - Processando bloco 10 de 20
2024-12-11 14:27:23,340 - INFO - Pré-processando os dados.
2024-12-11 14:28:09,481 - INFO - Normalizando os textos.
2024-12-11 14:28:29,565 - INFO - Tokenizando os textos.
2024-12-11 14:29:08,280 - INFO - Criando bigramas.
2024-12-11 14:29:09,061 - INFO - Removendo stopwords.
2024-12-11 14:29:09,084 - INFO - Aplicando stemming.
2024-12-11 14:29:09,761 - INFO - Aplicando lematização.
2024-12-11 14:29:42,118 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 14:29:42,138 - INFO - Classificando sentimentos usando VADER, BERT e TextBlob.
2024-12-11 14:35:04,079 - INFO - Codificando sentimentos.
2024-12-11 14:35:04,079 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 14:35:04,212 - INFO - Bloco 10 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_10.parquet
2024-12-11 14:35:04,431 - INFO - Processando bloco 11 de 20
2024-12-11 14:35:04,431 - INFO - Pré-processando os dados.
2024-12-11 14:35:50,366 - INFO - Normalizando os textos.
2024-12-11 14:36:10,169 - INFO - Tokenizando os textos.
2024-12-11 14:36:48,917 - INFO - Criando bigramas.
2024-12-11 14:36:49,689 - INFO - Removendo stopwords.
2024-12-11 14:36:49,726 - INFO - Aplicando stemming.
2024-12-11 14:36:50,652 - INFO - Aplicando lematização.
2024-12-11 14:37:22,974 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 14:37:23,005 - INFO - Classificando sentimentos usando VADER, BERT e TextBlob.
2024-12-11 14:42:41,533 - INFO - Codificando sentimentos.
2024-12-11 14:42:41,533 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 14:42:41,664 - INFO - Bloco 11 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_11.parquet
2024-12-11 14:42:41,908 - INFO - Processando bloco 12 de 20
2024-12-11 14:42:41,908 - INFO - Pré-processando os dados.
2024-12-11 14:43:27,507 - INFO - Normalizando os textos.
2024-12-11 14:43:47,672 - INFO - Tokenizando os textos.
2024-12-11 14:44:26,227 - INFO - Criando bigramas.
2024-12-11 14:44:26,992 - INFO - Removendo stopwords.
2024-12-11 14:44:27,027 - INFO - Aplicando stemming.
2024-12-11 14:44:27,692 - INFO - Aplicando lematização.
2024-12-11 14:45:00,050 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 14:45:00,077 - INFO - Classificando sentimentos usando VADER, BERT e TextBlob.
2024-12-11 14:50:18,891 - INFO - Codificando sentimentos.
2024-12-11 14:50:18,891 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 14:50:19,018 - INFO - Bloco 12 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_12.parquet
2024-12-11 14:50:19,260 - INFO - Processando bloco 13 de 20
2024-12-11 14:50:19,260 - INFO - Pré-processando os dados.
2024-12-11 14:51:04,928 - INFO - Normalizando os textos.
2024-12-11 14:51:24,685 - INFO - Tokenizando os textos.
2024-12-11 14:52:03,447 - INFO - Criando bigramas.
2024-12-11 14:52:04,216 - INFO - Removendo stopwords.
2024-12-11 14:52:04,238 - INFO - Aplicando stemming.
2024-12-11 14:52:04,900 - INFO - Aplicando lematização.
2024-12-11 14:52:37,316 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 14:52:37,339 - INFO - Classificando sentimentos usando VADER, BERT e TextBlob.
2024-12-11 14:57:58,193 - INFO - Codificando sentimentos.
2024-12-11 14:57:58,193 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 14:57:58,329 - INFO - Bloco 13 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_13.parquet
2024-12-11 14:57:58,552 - INFO - Processando bloco 14 de 20
2024-12-11 14:57:58,552 - INFO - Pré-processando os dados.
2024-12-11 14:58:43,996 - INFO - Normalizando os textos.
2024-12-11 14:59:03,973 - INFO - Tokenizando os textos.
2024-12-11 14:59:42,906 - INFO - Criando bigramas.
2024-12-11 14:59:43,690 - INFO - Removendo stopwords.
2024-12-11 14:59:43,711 - INFO - Aplicando stemming.
2024-12-11 14:59:44,389 - INFO - Aplicando lematização.
2024-12-11 15:00:17,120 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 15:00:17,140 - INFO - Classificando sentimentos usando VADER, BERT e TextBlob.
2024-12-11 15:05:38,293 - INFO - Codificando sentimentos.
2024-12-11 15:05:38,294 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 15:05:38,418 - INFO - Bloco 14 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_14.parquet
2024-12-11 15:05:38,641 - INFO - Processando bloco 15 de 20
2024-12-11 15:05:38,641 - INFO - Pré-processando os dados.
2024-12-11 15:06:23,911 - INFO - Normalizando os textos.
2024-12-11 15:06:44,578 - INFO - Tokenizando os textos.
2024-12-11 15:07:23,997 - INFO - Criando bigramas.
2024-12-11 15:07:24,781 - INFO - Removendo stopwords.
2024-12-11 15:07:24,816 - INFO - Aplicando stemming.
2024-12-11 15:07:25,496 - INFO - Aplicando lematização.
2024-12-11 15:07:58,260 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 15:07:58,282 - INFO - Classificando sentimentos usando VADER, BERT e TextBlob.
2024-12-11 15:13:20,486 - INFO - Codificando sentimentos.
2024-12-11 15:13:20,486 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 15:13:20,626 - INFO - Bloco 15 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_15.parquet
2024-12-11 15:13:20,864 - INFO - Processando bloco 16 de 20
2024-12-11 15:13:20,864 - INFO - Pré-processando os dados.
2024-12-11 15:14:06,790 - INFO - Normalizando os textos.
2024-12-11 15:14:26,907 - INFO - Tokenizando os textos.
2024-12-11 15:15:05,418 - INFO - Criando bigramas.
2024-12-11 15:15:06,203 - INFO - Removendo stopwords.
2024-12-11 15:15:06,236 - INFO - Aplicando stemming.
2024-12-11 15:15:06,887 - INFO - Aplicando lematização.
2024-12-11 15:15:39,051 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 15:15:39,085 - INFO - Classificando sentimentos usando VADER, BERT e TextBlob.
2024-12-11 15:20:57,500 - INFO - Codificando sentimentos.
2024-12-11 15:20:57,500 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 15:20:57,629 - INFO - Bloco 16 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_16.parquet
2024-12-11 15:20:57,860 - INFO - Processando bloco 17 de 20
2024-12-11 15:20:57,860 - INFO - Pré-processando os dados.
2024-12-11 15:21:43,506 - INFO - Normalizando os textos.
2024-12-11 15:22:03,655 - INFO - Tokenizando os textos.
2024-12-11 15:22:42,447 - INFO - Criando bigramas.
2024-12-11 15:22:43,227 - INFO - Removendo stopwords.
2024-12-11 15:22:43,266 - INFO - Aplicando stemming.
2024-12-11 15:22:43,927 - INFO - Aplicando lematização.
2024-12-11 15:23:16,582 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 15:23:16,615 - INFO - Classificando sentimentos usando VADER, BERT e TextBlob.
2024-12-11 15:28:37,446 - INFO - Codificando sentimentos.
2024-12-11 15:28:37,446 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 15:28:37,586 - INFO - Bloco 17 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_17.parquet
2024-12-11 15:28:37,812 - INFO - Processando bloco 18 de 20
2024-12-11 15:28:37,812 - INFO - Pré-processando os dados.
2024-12-11 15:29:23,609 - INFO - Normalizando os textos.
2024-12-11 15:29:43,444 - INFO - Tokenizando os textos.
2024-12-11 15:30:22,111 - INFO - Criando bigramas.
2024-12-11 15:30:22,900 - INFO - Removendo stopwords.
2024-12-11 15:30:22,924 - INFO - Aplicando stemming.
2024-12-11 15:30:23,851 - INFO - Aplicando lematização.
2024-12-11 15:30:56,090 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 15:30:56,124 - INFO - Classificando sentimentos usando VADER, BERT e TextBlob.
2024-12-11 15:36:14,993 - INFO - Codificando sentimentos.
2024-12-11 15:36:14,993 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 15:36:15,129 - INFO - Bloco 18 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_18.parquet
2024-12-11 15:36:15,354 - INFO - Processando bloco 19 de 20
2024-12-11 15:36:15,354 - INFO - Pré-processando os dados.
2024-12-11 15:37:02,160 - INFO - Normalizando os textos.
2024-12-11 15:37:22,010 - INFO - Tokenizando os textos.
2024-12-11 15:38:00,377 - INFO - Criando bigramas.
2024-12-11 15:38:01,157 - INFO - Removendo stopwords.
2024-12-11 15:38:01,179 - INFO - Aplicando stemming.
2024-12-11 15:38:01,824 - INFO - Aplicando lematização.
2024-12-11 15:38:34,092 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 15:38:34,111 - INFO - Classificando sentimentos usando VADER, BERT e TextBlob.
2024-12-11 15:43:52,317 - INFO - Codificando sentimentos.
2024-12-11 15:43:52,320 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 15:43:52,437 - INFO - Bloco 19 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_19.parquet
2024-12-11 15:43:52,681 - INFO - Processando bloco 20 de 20
2024-12-11 15:43:52,681 - INFO - Pré-processando os dados.
2024-12-11 15:44:39,157 - INFO - Normalizando os textos.
2024-12-11 15:44:59,668 - INFO - Tokenizando os textos.
2024-12-11 15:45:38,414 - INFO - Criando bigramas.
2024-12-11 15:45:39,181 - INFO - Removendo stopwords.
2024-12-11 15:45:39,218 - INFO - Aplicando stemming.
2024-12-11 15:45:39,881 - INFO - Aplicando lematização.
2024-12-11 15:46:12,157 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 15:46:12,185 - INFO - Classificando sentimentos usando VADER, BERT e TextBlob.
2024-12-11 15:51:30,668 - INFO - Codificando sentimentos.
2024-12-11 15:51:30,668 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 15:51:30,794 - INFO - Bloco 20 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_20.parquet
2024-12-11 15:51:30,794 - INFO - Tempo médio por bloco (recalculado): 0 horas, 7 minutos, 44.97 segundos
2024-12-11 15:51:30,794 - INFO - Tempo total estimado (recalculado): 2 horas, 34 minutos, 59.34 segundos
2024-12-11 15:51:30,794 - INFO - Salvando dataset processado.
2024-12-11 15:51:32,007 - INFO - Número de linhas com NaN em 'sentimento_codificado' antes da exclusão: 0
2024-12-11 15:51:32,075 - INFO - Número de linhas restantes após a remoção de NaNs: 182333
2024-12-11 15:51:32,075 - INFO - Contando sentimentos positivos, neutros e negativos.
2024-12-11 15:51:32,094 - INFO - Sentimentos positivos: 50099
2024-12-11 15:51:32,094 - INFO - Sentimentos neutros: 53817
2024-12-11 15:51:32,095 - INFO - Sentimentos negativos: 78417
2024-12-11 15:51:32,116 - INFO - Amostra salva com sucesso.
2024-12-11 15:51:58,296 - INFO - Dataset salvo com sucesso.
2024-12-11 15:51:58,407 - INFO - Todos os blocos processados e combinados com sucesso.
2024-12-11 15:51:58,429 - INFO - Gerando relatórios.
2024-12-11 15:51:58,634 - INFO - Relatórios gerados com sucesso.
2024-12-11 17:11:52,376 - INFO - Carregando o dataset bruto.
2024-12-11 17:11:52,408 - INFO - Dataset carregado com sucesso com 200000 linhas.
2024-12-11 17:11:52,408 - INFO - Renomeando colunas.
2024-12-11 17:11:52,674 - INFO - Total de linhas a serem processadas: 200000
2024-12-11 17:11:52,674 - INFO - Total de blocos a serem processados: 20
2024-12-11 17:11:52,909 - INFO - Processando bloco 1 de 20
2024-12-11 17:11:52,909 - INFO - Pré-processando os dados.
2024-12-11 17:12:41,294 - INFO - Normalizando os textos.
2024-12-11 17:13:01,742 - INFO - Tokenizando os textos.
2024-12-11 17:13:44,793 - INFO - Criando bigramas.
2024-12-11 17:13:45,576 - INFO - Removendo stopwords.
2024-12-11 17:13:45,999 - INFO - Aplicando stemming.
2024-12-11 17:13:46,690 - INFO - Aplicando lematização.
2024-12-11 17:14:19,938 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 17:14:19,960 - INFO - Classificando sentimentos usando VADER, BERT e TextBlob.
2024-12-11 17:19:42,744 - INFO - Codificando sentimentos.
2024-12-11 17:19:42,744 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 17:19:42,882 - INFO - Bloco 1 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_1.parquet
2024-12-11 17:19:42,882 - INFO - Tempo médio por bloco: 0 horas, 7 minutos, 50.09 segundos
2024-12-11 17:19:42,882 - INFO - Tempo total estimado: 2 horas, 36 minutos, 41.72 segundos
2024-12-11 17:19:43,105 - INFO - Processando bloco 2 de 20
2024-12-11 17:19:43,105 - INFO - Pré-processando os dados.
2024-12-11 17:20:29,320 - INFO - Normalizando os textos.
2024-12-11 17:20:48,961 - INFO - Tokenizando os textos.
2024-12-11 17:21:28,029 - INFO - Criando bigramas.
2024-12-11 17:21:28,793 - INFO - Removendo stopwords.
2024-12-11 17:21:28,817 - INFO - Aplicando stemming.
2024-12-11 17:21:29,460 - INFO - Aplicando lematização.
2024-12-11 17:22:01,776 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 17:22:01,798 - INFO - Classificando sentimentos usando VADER, BERT e TextBlob.
2024-12-11 17:27:19,251 - INFO - Codificando sentimentos.
2024-12-11 17:27:19,253 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 17:27:19,371 - INFO - Bloco 2 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_2.parquet
2024-12-11 17:27:19,580 - INFO - Processando bloco 3 de 20
2024-12-11 17:27:19,580 - INFO - Pré-processando os dados.
2024-12-11 17:28:05,067 - INFO - Normalizando os textos.
2024-12-11 17:28:24,780 - INFO - Tokenizando os textos.
2024-12-11 17:29:03,857 - INFO - Criando bigramas.
2024-12-11 17:29:04,634 - INFO - Removendo stopwords.
2024-12-11 17:29:04,658 - INFO - Aplicando stemming.
2024-12-11 17:29:05,317 - INFO - Aplicando lematização.
2024-12-11 17:29:37,903 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 17:29:37,933 - INFO - Classificando sentimentos usando VADER, BERT e TextBlob.
2024-12-11 17:34:58,008 - INFO - Codificando sentimentos.
2024-12-11 17:34:58,008 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 17:34:58,144 - INFO - Bloco 3 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_3.parquet
2024-12-11 17:34:58,369 - INFO - Processando bloco 4 de 20
2024-12-11 17:34:58,369 - INFO - Pré-processando os dados.
2024-12-11 17:35:43,708 - INFO - Normalizando os textos.
2024-12-11 17:36:03,438 - INFO - Tokenizando os textos.
2024-12-11 17:36:42,699 - INFO - Criando bigramas.
2024-12-11 17:36:43,457 - INFO - Removendo stopwords.
2024-12-11 17:36:43,490 - INFO - Aplicando stemming.
2024-12-11 17:36:44,441 - INFO - Aplicando lematização.
2024-12-11 17:37:17,269 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 17:37:17,284 - INFO - Classificando sentimentos usando VADER, BERT e TextBlob.
2024-12-11 17:42:38,297 - INFO - Codificando sentimentos.
2024-12-11 17:42:38,313 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 17:42:38,436 - INFO - Bloco 4 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_4.parquet
2024-12-11 17:42:38,662 - INFO - Processando bloco 5 de 20
2024-12-11 17:42:38,662 - INFO - Pré-processando os dados.
2024-12-11 17:43:26,074 - INFO - Normalizando os textos.
2024-12-11 17:43:46,026 - INFO - Tokenizando os textos.
2024-12-11 17:44:25,032 - INFO - Criando bigramas.
2024-12-11 17:44:25,781 - INFO - Removendo stopwords.
2024-12-11 17:44:25,818 - INFO - Aplicando stemming.
2024-12-11 17:44:26,464 - INFO - Aplicando lematização.
2024-12-11 17:44:58,946 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 17:44:58,968 - INFO - Classificando sentimentos usando VADER, BERT e TextBlob.
2024-12-11 17:50:18,722 - INFO - Codificando sentimentos.
2024-12-11 17:50:18,722 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 17:50:18,856 - INFO - Bloco 5 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_5.parquet
2024-12-11 17:50:19,085 - INFO - Processando bloco 6 de 20
2024-12-11 17:50:19,085 - INFO - Pré-processando os dados.
2024-12-11 17:51:04,830 - INFO - Normalizando os textos.
2024-12-11 17:51:24,814 - INFO - Tokenizando os textos.
2024-12-11 17:52:03,989 - INFO - Criando bigramas.
2024-12-11 17:52:04,754 - INFO - Removendo stopwords.
2024-12-11 17:52:04,789 - INFO - Aplicando stemming.
2024-12-11 17:52:05,454 - INFO - Aplicando lematização.
2024-12-11 17:52:38,161 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 17:52:38,180 - INFO - Classificando sentimentos usando VADER, BERT e TextBlob.
2024-12-11 17:57:59,649 - INFO - Codificando sentimentos.
2024-12-11 17:57:59,652 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 17:57:59,764 - INFO - Bloco 6 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_6.parquet
2024-12-11 17:58:00,013 - INFO - Processando bloco 7 de 20
2024-12-11 17:58:00,013 - INFO - Pré-processando os dados.
2024-12-11 17:58:45,806 - INFO - Normalizando os textos.
2024-12-11 17:59:05,416 - INFO - Tokenizando os textos.
2024-12-11 17:59:43,966 - INFO - Criando bigramas.
2024-12-11 17:59:44,728 - INFO - Removendo stopwords.
2024-12-11 17:59:44,763 - INFO - Aplicando stemming.
2024-12-11 17:59:45,445 - INFO - Aplicando lematização.
2024-12-11 18:00:17,915 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 18:00:17,937 - INFO - Classificando sentimentos usando VADER, BERT e TextBlob.
2024-12-11 18:05:34,750 - INFO - Codificando sentimentos.
2024-12-11 18:05:34,750 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 18:05:34,874 - INFO - Bloco 7 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_7.parquet
2024-12-11 18:05:35,096 - INFO - Processando bloco 8 de 20
2024-12-11 18:05:35,096 - INFO - Pré-processando os dados.
2024-12-11 18:06:21,348 - INFO - Normalizando os textos.
2024-12-11 18:06:41,075 - INFO - Tokenizando os textos.
2024-12-11 18:07:20,015 - INFO - Criando bigramas.
2024-12-11 18:07:20,785 - INFO - Removendo stopwords.
2024-12-11 18:07:20,807 - INFO - Aplicando stemming.
2024-12-11 18:07:21,468 - INFO - Aplicando lematização.
2024-12-11 18:07:53,904 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 18:07:53,926 - INFO - Classificando sentimentos usando VADER, BERT e TextBlob.
2024-12-11 18:13:11,851 - INFO - Codificando sentimentos.
2024-12-11 18:13:11,851 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 18:13:11,983 - INFO - Bloco 8 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_8.parquet
2024-12-11 18:13:12,211 - INFO - Processando bloco 9 de 20
2024-12-11 18:13:12,211 - INFO - Pré-processando os dados.
2024-12-11 18:13:58,256 - INFO - Normalizando os textos.
2024-12-11 18:14:19,123 - INFO - Tokenizando os textos.
2024-12-11 18:14:58,240 - INFO - Criando bigramas.
2024-12-11 18:14:59,025 - INFO - Removendo stopwords.
2024-12-11 18:14:59,049 - INFO - Aplicando stemming.
2024-12-11 18:14:59,742 - INFO - Aplicando lematização.
2024-12-11 18:15:32,474 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 18:15:32,496 - INFO - Classificando sentimentos usando VADER, BERT e TextBlob.
2024-12-11 18:20:52,780 - INFO - Codificando sentimentos.
2024-12-11 18:20:52,780 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 18:20:52,910 - INFO - Bloco 9 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_9.parquet
2024-12-11 18:20:53,134 - INFO - Processando bloco 10 de 20
2024-12-11 18:20:53,134 - INFO - Pré-processando os dados.
2024-12-11 18:21:39,747 - INFO - Normalizando os textos.
2024-12-11 18:21:59,949 - INFO - Tokenizando os textos.
2024-12-11 18:22:38,793 - INFO - Criando bigramas.
2024-12-11 18:22:39,566 - INFO - Removendo stopwords.
2024-12-11 18:22:39,601 - INFO - Aplicando stemming.
2024-12-11 18:22:40,265 - INFO - Aplicando lematização.
2024-12-11 18:23:12,934 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 18:23:12,955 - INFO - Classificando sentimentos usando VADER, BERT e TextBlob.
2024-12-11 18:28:31,120 - INFO - Codificando sentimentos.
2024-12-11 18:28:31,120 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 18:28:31,258 - INFO - Bloco 10 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_10.parquet
2024-12-11 18:28:31,469 - INFO - Processando bloco 11 de 20
2024-12-11 18:28:31,485 - INFO - Pré-processando os dados.
2024-12-11 18:29:17,629 - INFO - Normalizando os textos.
2024-12-11 18:29:37,432 - INFO - Tokenizando os textos.
2024-12-11 18:30:16,300 - INFO - Criando bigramas.
2024-12-11 18:30:17,073 - INFO - Removendo stopwords.
2024-12-11 18:30:17,095 - INFO - Aplicando stemming.
2024-12-11 18:30:18,023 - INFO - Aplicando lematização.
2024-12-11 18:30:50,455 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 18:30:50,478 - INFO - Classificando sentimentos usando VADER, BERT e TextBlob.
2024-12-11 18:36:07,393 - INFO - Codificando sentimentos.
2024-12-11 18:36:07,396 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 18:36:07,518 - INFO - Bloco 11 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_11.parquet
2024-12-11 18:36:07,746 - INFO - Processando bloco 12 de 20
2024-12-11 18:36:07,746 - INFO - Pré-processando os dados.
2024-12-11 18:36:53,401 - INFO - Normalizando os textos.
2024-12-11 18:37:13,639 - INFO - Tokenizando os textos.
2024-12-11 18:37:52,408 - INFO - Criando bigramas.
2024-12-11 18:37:53,180 - INFO - Removendo stopwords.
2024-12-11 18:37:53,216 - INFO - Aplicando stemming.
2024-12-11 18:37:53,880 - INFO - Aplicando lematização.
2024-12-11 18:38:26,389 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 18:38:26,419 - INFO - Classificando sentimentos usando VADER, BERT e TextBlob.
2024-12-11 18:43:44,736 - INFO - Codificando sentimentos.
2024-12-11 18:43:44,736 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 18:43:44,859 - INFO - Bloco 12 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_12.parquet
2024-12-11 18:43:45,082 - INFO - Processando bloco 13 de 20
2024-12-11 18:43:45,082 - INFO - Pré-processando os dados.
2024-12-11 18:44:30,888 - INFO - Normalizando os textos.
2024-12-11 18:44:50,552 - INFO - Tokenizando os textos.
2024-12-11 18:45:29,233 - INFO - Criando bigramas.
2024-12-11 18:45:29,991 - INFO - Removendo stopwords.
2024-12-11 18:45:30,028 - INFO - Aplicando stemming.
2024-12-11 18:45:30,687 - INFO - Aplicando lematização.
2024-12-11 18:46:03,182 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 18:46:03,203 - INFO - Classificando sentimentos usando VADER, BERT e TextBlob.
2024-12-11 18:51:21,008 - INFO - Codificando sentimentos.
2024-12-11 18:51:21,008 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 18:51:21,146 - INFO - Bloco 13 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_13.parquet
2024-12-11 18:51:21,388 - INFO - Processando bloco 14 de 20
2024-12-11 18:51:21,388 - INFO - Pré-processando os dados.
2024-12-11 18:52:06,835 - INFO - Normalizando os textos.
2024-12-11 18:52:26,890 - INFO - Tokenizando os textos.
2024-12-11 18:53:05,882 - INFO - Criando bigramas.
2024-12-11 18:53:06,661 - INFO - Removendo stopwords.
2024-12-11 18:53:06,684 - INFO - Aplicando stemming.
2024-12-11 18:53:07,361 - INFO - Aplicando lematização.
2024-12-11 18:53:39,912 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 18:53:39,946 - INFO - Classificando sentimentos usando VADER, BERT e TextBlob.
2024-12-11 18:58:58,937 - INFO - Codificando sentimentos.
2024-12-11 18:58:58,937 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 18:58:59,070 - INFO - Bloco 14 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_14.parquet
2024-12-11 18:58:59,298 - INFO - Processando bloco 15 de 20
2024-12-11 18:58:59,298 - INFO - Pré-processando os dados.
2024-12-11 18:59:44,633 - INFO - Normalizando os textos.
2024-12-11 19:00:05,251 - INFO - Tokenizando os textos.
2024-12-11 19:00:44,763 - INFO - Criando bigramas.
2024-12-11 19:00:45,538 - INFO - Removendo stopwords.
2024-12-11 19:00:45,573 - INFO - Aplicando stemming.
2024-12-11 19:00:46,251 - INFO - Aplicando lematização.
2024-12-11 19:01:19,059 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 19:01:19,090 - INFO - Classificando sentimentos usando VADER, BERT e TextBlob.
2024-12-11 19:06:38,991 - INFO - Codificando sentimentos.
2024-12-11 19:06:38,991 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 19:06:39,130 - INFO - Bloco 15 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_15.parquet
2024-12-11 19:06:39,369 - INFO - Processando bloco 16 de 20
2024-12-11 19:06:39,369 - INFO - Pré-processando os dados.
2024-12-11 19:07:25,332 - INFO - Normalizando os textos.
2024-12-11 19:07:45,418 - INFO - Tokenizando os textos.
2024-12-11 19:08:24,174 - INFO - Criando bigramas.
2024-12-11 19:08:24,925 - INFO - Removendo stopwords.
2024-12-11 19:08:24,964 - INFO - Aplicando stemming.
2024-12-11 19:08:25,624 - INFO - Aplicando lematização.
2024-12-11 19:08:58,018 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 19:08:58,041 - INFO - Classificando sentimentos usando VADER, BERT e TextBlob.
2024-12-11 19:14:14,553 - INFO - Codificando sentimentos.
2024-12-11 19:14:14,553 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 19:14:14,687 - INFO - Bloco 16 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_16.parquet
2024-12-11 19:14:14,917 - INFO - Processando bloco 17 de 20
2024-12-11 19:14:14,917 - INFO - Pré-processando os dados.
2024-12-11 19:15:00,481 - INFO - Normalizando os textos.
2024-12-11 19:15:20,558 - INFO - Tokenizando os textos.
2024-12-11 19:15:59,485 - INFO - Criando bigramas.
2024-12-11 19:16:00,248 - INFO - Removendo stopwords.
2024-12-11 19:16:00,288 - INFO - Aplicando stemming.
2024-12-11 19:16:00,965 - INFO - Aplicando lematização.
2024-12-11 19:16:33,549 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 19:16:33,573 - INFO - Classificando sentimentos usando VADER, BERT e TextBlob.
2024-12-11 19:21:52,207 - INFO - Codificando sentimentos.
2024-12-11 19:21:52,207 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 19:21:52,344 - INFO - Bloco 17 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_17.parquet
2024-12-11 19:21:52,572 - INFO - Processando bloco 18 de 20
2024-12-11 19:21:52,572 - INFO - Pré-processando os dados.
2024-12-11 19:22:38,707 - INFO - Normalizando os textos.
2024-12-11 19:22:58,585 - INFO - Tokenizando os textos.
2024-12-11 19:23:37,315 - INFO - Criando bigramas.
2024-12-11 19:23:38,088 - INFO - Removendo stopwords.
2024-12-11 19:23:38,122 - INFO - Aplicando stemming.
2024-12-11 19:23:39,055 - INFO - Aplicando lematização.
2024-12-11 19:24:11,408 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 19:24:11,440 - INFO - Classificando sentimentos usando VADER, BERT e TextBlob.
2024-12-11 19:29:28,512 - INFO - Codificando sentimentos.
2024-12-11 19:29:28,512 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 19:29:28,651 - INFO - Bloco 18 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_18.parquet
2024-12-11 19:29:28,874 - INFO - Processando bloco 19 de 20
2024-12-11 19:29:28,874 - INFO - Pré-processando os dados.
2024-12-11 19:30:15,027 - INFO - Normalizando os textos.
2024-12-11 19:30:34,790 - INFO - Tokenizando os textos.
2024-12-11 19:31:13,194 - INFO - Criando bigramas.
2024-12-11 19:31:13,946 - INFO - Removendo stopwords.
2024-12-11 19:31:13,980 - INFO - Aplicando stemming.
2024-12-11 19:31:14,629 - INFO - Aplicando lematização.
2024-12-11 19:31:46,789 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 19:31:46,818 - INFO - Classificando sentimentos usando VADER, BERT e TextBlob.
2024-12-11 19:37:02,084 - INFO - Codificando sentimentos.
2024-12-11 19:37:02,084 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 19:37:02,224 - INFO - Bloco 19 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_19.parquet
2024-12-11 19:37:02,464 - INFO - Processando bloco 20 de 20
2024-12-11 19:37:02,464 - INFO - Pré-processando os dados.
2024-12-11 19:37:48,668 - INFO - Normalizando os textos.
2024-12-11 19:38:09,250 - INFO - Tokenizando os textos.
2024-12-11 19:38:48,050 - INFO - Criando bigramas.
2024-12-11 19:38:48,819 - INFO - Removendo stopwords.
2024-12-11 19:38:48,854 - INFO - Aplicando stemming.
2024-12-11 19:38:49,519 - INFO - Aplicando lematização.
2024-12-11 19:39:22,029 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 19:39:22,058 - INFO - Classificando sentimentos usando VADER, BERT e TextBlob.
2024-12-11 19:44:39,494 - INFO - Codificando sentimentos.
2024-12-11 19:44:39,509 - INFO - Removendo documentos vazios ou contendo apenas stop words.
2024-12-11 19:44:39,631 - INFO - Bloco 20 salvo em D:\Github\data-science\projetos\analise-de-sentimentos\nlp\data\processed\temp\bloco_20.parquet
2024-12-11 19:44:39,631 - INFO - Tempo médio por bloco (recalculado): 0 horas, 7 minutos, 38.22 segundos
2024-12-11 19:44:39,631 - INFO - Tempo total estimado (recalculado): 2 horas, 32 minutos, 44.50 segundos
2024-12-11 19:44:39,631 - INFO - Salvando dataset processado.
2024-12-11 19:44:40,829 - INFO - Número de linhas com NaN em 'sentimento_codificado' antes da exclusão: 0
2024-12-11 19:44:40,898 - INFO - Número de linhas restantes após a remoção de NaNs: 182361
2024-12-11 19:44:40,898 - INFO - Contando sentimentos positivos, neutros e negativos.
2024-12-11 19:44:40,922 - INFO - Sentimentos positivos: 49805
2024-12-11 19:44:40,922 - INFO - Sentimentos neutros: 50655
2024-12-11 19:44:40,923 - INFO - Sentimentos negativos: 81901
2024-12-11 19:44:40,938 - INFO - Amostra salva com sucesso.
2024-12-11 19:45:07,023 - INFO - Dataset salvo com sucesso.
2024-12-11 19:45:07,148 - INFO - Todos os blocos processados e combinados com sucesso.
2024-12-11 19:45:07,149 - INFO - Gerando relatórios.
2024-12-11 19:45:07,371 - INFO - Relatórios gerados com sucesso.
2024-12-11 21:58:28,559 - INFO -  * Running on http://127.0.0.1:5000 (Press CTRL+C to quit)
2024-12-11 21:58:28,559 - INFO -  * Restarting with stat
2024-12-11 21:58:37,934 - WARNING -  * Debugger is active!
2024-12-11 21:58:37,950 - INFO -  * Debugger PIN: 708-303-649
2024-12-11 22:00:37,029 - INFO - 127.0.0.1 - - [11/Dec/2024 22:00:37] "GET / HTTP/1.1" 200 -
2024-12-11 22:00:37,042 - INFO - 127.0.0.1 - - [11/Dec/2024 22:00:37] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-11 22:00:37,109 - INFO - 127.0.0.1 - - [11/Dec/2024 22:00:37] "[33mGET /favicon.ico HTTP/1.1[0m" 404 -
2024-12-11 22:00:48,716 - INFO - 127.0.0.1 - - [11/Dec/2024 22:00:48] "POST /predict HTTP/1.1" 200 -
2024-12-11 22:00:48,723 - INFO - 127.0.0.1 - - [11/Dec/2024 22:00:48] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-11 22:00:57,339 - INFO - 127.0.0.1 - - [11/Dec/2024 22:00:57] "POST /predict HTTP/1.1" 200 -
2024-12-11 22:00:57,339 - INFO - 127.0.0.1 - - [11/Dec/2024 22:00:57] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-11 22:01:18,505 - INFO - 127.0.0.1 - - [11/Dec/2024 22:01:18] "POST /predict HTTP/1.1" 200 -
2024-12-11 22:01:18,511 - INFO - 127.0.0.1 - - [11/Dec/2024 22:01:18] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-11 22:01:34,909 - INFO - 127.0.0.1 - - [11/Dec/2024 22:01:34] "POST /predict HTTP/1.1" 200 -
2024-12-11 22:01:34,915 - INFO - 127.0.0.1 - - [11/Dec/2024 22:01:34] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-11 22:01:53,147 - INFO - 127.0.0.1 - - [11/Dec/2024 22:01:53] "POST /predict HTTP/1.1" 200 -
2024-12-11 22:01:53,153 - INFO - 127.0.0.1 - - [11/Dec/2024 22:01:53] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-11 22:02:06,938 - INFO - 127.0.0.1 - - [11/Dec/2024 22:02:06] "POST /predict HTTP/1.1" 200 -
2024-12-11 22:02:06,938 - INFO - 127.0.0.1 - - [11/Dec/2024 22:02:06] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-11 22:02:19,128 - INFO - 127.0.0.1 - - [11/Dec/2024 22:02:19] "POST /predict HTTP/1.1" 200 -
2024-12-11 22:02:19,134 - INFO - 127.0.0.1 - - [11/Dec/2024 22:02:19] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-11 22:02:32,897 - INFO - 127.0.0.1 - - [11/Dec/2024 22:02:32] "POST /predict HTTP/1.1" 200 -
2024-12-11 22:02:32,904 - INFO - 127.0.0.1 - - [11/Dec/2024 22:02:32] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-11 22:02:51,948 - INFO - 127.0.0.1 - - [11/Dec/2024 22:02:51] "POST /predict HTTP/1.1" 200 -
2024-12-11 22:02:51,953 - INFO - 127.0.0.1 - - [11/Dec/2024 22:02:51] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-11 22:07:55,041 - INFO - 127.0.0.1 - - [11/Dec/2024 22:07:55] "POST /predict HTTP/1.1" 200 -
2024-12-11 22:07:55,047 - INFO - 127.0.0.1 - - [11/Dec/2024 22:07:55] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-11 22:09:19,445 - INFO - 127.0.0.1 - - [11/Dec/2024 22:09:19] "POST /predict HTTP/1.1" 200 -
2024-12-11 22:09:19,445 - INFO - 127.0.0.1 - - [11/Dec/2024 22:09:19] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-11 22:10:47,368 - INFO - 127.0.0.1 - - [11/Dec/2024 22:10:47] "POST /predict HTTP/1.1" 200 -
2024-12-11 22:10:47,376 - INFO - 127.0.0.1 - - [11/Dec/2024 22:10:47] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-11 22:11:04,088 - INFO - 127.0.0.1 - - [11/Dec/2024 22:11:04] "POST /predict HTTP/1.1" 200 -
2024-12-11 22:11:04,093 - INFO - 127.0.0.1 - - [11/Dec/2024 22:11:04] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-11 22:11:23,174 - INFO - 127.0.0.1 - - [11/Dec/2024 22:11:23] "POST /predict HTTP/1.1" 200 -
2024-12-11 22:11:23,182 - INFO - 127.0.0.1 - - [11/Dec/2024 22:11:23] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-11 22:11:37,594 - INFO - 127.0.0.1 - - [11/Dec/2024 22:11:37] "POST /predict HTTP/1.1" 200 -
2024-12-11 22:11:37,594 - INFO - 127.0.0.1 - - [11/Dec/2024 22:11:37] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-11 22:11:57,425 - INFO - 127.0.0.1 - - [11/Dec/2024 22:11:57] "POST /predict HTTP/1.1" 200 -
2024-12-11 22:11:57,426 - INFO - 127.0.0.1 - - [11/Dec/2024 22:11:57] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-11 22:12:11,119 - INFO - 127.0.0.1 - - [11/Dec/2024 22:12:11] "POST /predict HTTP/1.1" 200 -
2024-12-11 22:12:11,125 - INFO - 127.0.0.1 - - [11/Dec/2024 22:12:11] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-11 22:13:02,618 - INFO - 127.0.0.1 - - [11/Dec/2024 22:13:02] "POST /predict HTTP/1.1" 200 -
2024-12-11 22:13:02,624 - INFO - 127.0.0.1 - - [11/Dec/2024 22:13:02] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-11 22:14:24,235 - INFO - 127.0.0.1 - - [11/Dec/2024 22:14:24] "POST /predict HTTP/1.1" 200 -
2024-12-11 22:14:24,239 - INFO - 127.0.0.1 - - [11/Dec/2024 22:14:24] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-11 22:14:57,075 - INFO - 127.0.0.1 - - [11/Dec/2024 22:14:57] "POST /predict HTTP/1.1" 200 -
2024-12-11 22:14:57,081 - INFO - 127.0.0.1 - - [11/Dec/2024 22:14:57] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-11 22:15:55,813 - INFO - 127.0.0.1 - - [11/Dec/2024 22:15:55] "POST /predict HTTP/1.1" 200 -
2024-12-11 22:15:55,820 - INFO - 127.0.0.1 - - [11/Dec/2024 22:15:55] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-11 22:16:34,455 - INFO - 127.0.0.1 - - [11/Dec/2024 22:16:34] "POST /predict HTTP/1.1" 200 -
2024-12-11 22:16:34,462 - INFO - 127.0.0.1 - - [11/Dec/2024 22:16:34] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-11 22:17:26,898 - INFO - 127.0.0.1 - - [11/Dec/2024 22:17:26] "POST /predict HTTP/1.1" 200 -
2024-12-11 22:17:26,901 - INFO - 127.0.0.1 - - [11/Dec/2024 22:17:26] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-11 22:17:27,087 - INFO - 127.0.0.1 - - [11/Dec/2024 22:17:27] "POST /predict HTTP/1.1" 200 -
2024-12-11 22:17:27,096 - INFO - 127.0.0.1 - - [11/Dec/2024 22:17:27] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-11 22:17:32,568 - INFO - 127.0.0.1 - - [11/Dec/2024 22:17:32] "POST /predict HTTP/1.1" 200 -
2024-12-11 22:17:32,568 - INFO - 127.0.0.1 - - [11/Dec/2024 22:17:32] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-11 22:18:26,050 - INFO - 127.0.0.1 - - [11/Dec/2024 22:18:26] "POST /predict HTTP/1.1" 200 -
2024-12-11 22:18:26,066 - INFO - 127.0.0.1 - - [11/Dec/2024 22:18:26] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
2024-12-11 22:19:09,388 - INFO - 127.0.0.1 - - [11/Dec/2024 22:19:09] "POST /predict HTTP/1.1" 200 -
2024-12-11 22:19:09,391 - INFO - 127.0.0.1 - - [11/Dec/2024 22:19:09] "[36mGET /static/style.css HTTP/1.1[0m" 304 -
