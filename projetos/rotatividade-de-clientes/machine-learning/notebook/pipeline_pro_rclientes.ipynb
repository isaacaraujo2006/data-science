{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65cbdf4f-9b16-4bb9-930e-9deb2d05f823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Pré-processamento: data_preprocessing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23e47e3d-5aab-4e5a-b05c-2ffb6efafe8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Configuração carregada com sucesso.\n",
      "INFO:__main__:Dataset bruto carregado de: D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/data/raw/rclientes.csv\n",
      "INFO:__main__:Todas as colunas necessárias estão presentes.\n",
      "INFO:__main__:Verificando dados ausentes...\n",
      "INFO:__main__:Valores ausentes por coluna:\n",
      "Series([], dtype: int64)\n",
      "INFO:__main__:Valores ausentes na coluna 'Balance' substituídos pela média: 76485.889288.\n",
      "INFO:__main__:Valores ausentes na coluna 'Age' substituídos pela média: 38.9218.\n",
      "INFO:__main__:Valores ausentes na coluna 'CreditScore' substituídos pela média: 650.5288.\n",
      "INFO:__main__:Valores ausentes na coluna 'Tenure' substituídos pela média: 5.0128.\n",
      "INFO:__main__:Valores ausentes na coluna 'EstimatedSalary' substituídos pela média: 100090.239881.\n",
      "INFO:__main__:Verificando duplicados...\n",
      "INFO:__main__:Número de duplicados encontrados: 0\n",
      "INFO:__main__:Dados tratados salvos em: D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/data/processed/rclientes_dados_tratados.csv\n",
      "INFO:__main__:Pré-processamento concluído.\n",
      "INFO:__main__:Aplicando SMOTE para balanceamento de classes...\n",
      "INFO:__main__:Balanceamento de classes concluído.\n",
      "INFO:__main__:Nova distribuição de classes:\n",
      "Exited\n",
      "1    7963\n",
      "0    7963\n",
      "Name: count, dtype: int64\n",
      "INFO:__main__:Pré-processador salvo em: D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/preprocessors/preprocessor.joblib\n",
      "INFO:__main__:Gerando gráficos...\n",
      "INFO:matplotlib.category:Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
      "INFO:matplotlib.category:Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
      "INFO:__main__:Gráficos gerados e salvos com sucesso.\n",
      "INFO:__main__:Dataset processado salvo em: D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/data/processed/rclientes_preprocessado.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Primeiras 5 linhas do dataset processado:\n",
      "     Balance       Age  CreditScore    Tenure  EstimatedSalary  Exited\n",
      "0 -1.225848  0.293517    -0.326221 -1.041760         0.021886       1\n",
      "1  0.117350  0.198164    -0.440036 -1.387538         0.216534       0\n",
      "2  1.333053  0.293517    -1.536794  1.032908         0.240687       1\n",
      "3 -1.225848  0.007457     0.501521 -1.387538        -0.108918       0\n",
      "4  0.785728  0.388871     2.063884 -1.041760        -0.365276       0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import yaml\n",
    "import os\n",
    "import logging\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Configurar logger\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def carregar_configuracao(config_path='D:\\\\Github\\\\data-science\\\\projetos\\\\rotatividade-de-clientes\\\\machine-learning\\\\config\\\\config.yaml'):\n",
    "    \"\"\"\n",
    "    Carregar configurações de um arquivo YAML.\n",
    "\n",
    "    Parameters:\n",
    "    config_path (str): O caminho para o arquivo de configuração YAML.\n",
    "\n",
    "    Returns:\n",
    "    dict: Um dicionário contendo as configurações carregadas do arquivo.\n",
    "\n",
    "    Raises:\n",
    "    FileNotFoundError: Se o arquivo de configuração não for encontrado.\n",
    "    YAMLError: Se houver um erro ao ler o arquivo YAML.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(config_path, 'r') as file:\n",
    "            config = yaml.safe_load(file)\n",
    "        logger.info(\"Configuração carregada com sucesso.\")\n",
    "        return config\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"Arquivo de configuração não encontrado: {config_path}\")\n",
    "        raise\n",
    "    except yaml.YAMLError as e:\n",
    "        logger.error(f\"Erro ao ler o arquivo de configuração: {e}\")\n",
    "        raise\n",
    "\n",
    "def validar_colunas(df, cols):\n",
    "    \"\"\"\n",
    "    Valida se as colunas necessárias estão presentes no DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): O DataFrame a ser validado.\n",
    "    cols (list): Lista de colunas necessárias.\n",
    "\n",
    "    Raises:\n",
    "    ValueError: Se alguma coluna necessária estiver ausente no DataFrame.\n",
    "    \"\"\"\n",
    "    missing_cols = [col for col in cols if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        logger.error(f\"Colunas ausentes no dataset: {missing_cols}\")\n",
    "        raise ValueError(f\"Colunas ausentes: {missing_cols}\")\n",
    "    logger.info(\"Todas as colunas necessárias estão presentes.\")\n",
    "\n",
    "def carregar_dados(config):\n",
    "    \"\"\"\n",
    "    Carregar dados a partir do caminho especificado no arquivo de configuração.\n",
    "\n",
    "    Parameters:\n",
    "    config (dict): Dicionário contendo as configurações do projeto, incluindo o caminho dos dados.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame contendo os dados carregados.\n",
    "\n",
    "    Raises:\n",
    "    Exception: Se houver um erro ao carregar os dados.\n",
    "    \"\"\"\n",
    "    raw_data_path = config['data']['raw']\n",
    "    try:\n",
    "        df = pd.read_csv(raw_data_path)\n",
    "        logger.info(f'Dataset bruto carregado de: {raw_data_path}')\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao carregar o dataset bruto: {e}\")\n",
    "        raise\n",
    "\n",
    "def tratar_dados(df, num_cols, config):\n",
    "    \"\"\"\n",
    "    Tratar valores ausentes e duplicados no dataset e salvar os dados tratados em um arquivo CSV.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame contendo os dados brutos.\n",
    "    num_cols (list): Lista de colunas numéricas que precisam ser tratadas.\n",
    "    config (dict): Dicionário contendo as configurações do projeto, incluindo o caminho para salvar os dados tratados.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame com valores ausentes tratados e duplicados removidos.\n",
    "    \"\"\"\n",
    "    # Tratar valores ausentes\n",
    "    logger.info(\"Verificando dados ausentes...\")\n",
    "    missing_values = df.isnull().sum()\n",
    "    logger.info(f\"Valores ausentes por coluna:\\n{missing_values[missing_values > 0]}\")\n",
    "\n",
    "    for col in num_cols:\n",
    "        if col in df.columns:\n",
    "            mean_value = df[col].mean()\n",
    "            df[col] = df[col].fillna(mean_value)\n",
    "            logger.info(f\"Valores ausentes na coluna '{col}' substituídos pela média: {mean_value}.\")\n",
    "        else:\n",
    "            logger.warning(f\"Coluna '{col}' não encontrada no dataset.\")\n",
    "\n",
    "    # Verificar e remover duplicados\n",
    "    logger.info(\"Verificando duplicados...\")\n",
    "    duplicates = df.duplicated().sum()\n",
    "    logger.info(f\"Número de duplicados encontrados: {duplicates}\")\n",
    "    if duplicates > 0:\n",
    "        df = df.drop_duplicates()\n",
    "        logger.info(\"Duplicados removidos.\")\n",
    "    \n",
    "    # Salvar dados tratados em um arquivo CSV\n",
    "    processed_data_path = config['data']['data_processed']\n",
    "    df.to_csv(processed_data_path, index=False)\n",
    "    logger.info(f\"Dados tratados salvos em: {processed_data_path}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def criar_preprocessador(num_cols):\n",
    "    \"\"\"\n",
    "    Criar um pré-processador para colunas numéricas.\n",
    "\n",
    "    Parameters:\n",
    "    num_cols (list): Lista de colunas numéricas para normalização.\n",
    "\n",
    "    Returns:\n",
    "    ColumnTransformer: Um objeto ColumnTransformer configurado para normalização das colunas numéricas.\n",
    "    \"\"\"\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), num_cols)  # Normalização das colunas numéricas\n",
    "        ]\n",
    "    )\n",
    "    return preprocessor\n",
    "\n",
    "def aplicar_smote(X, y):\n",
    "    \"\"\"\n",
    "    Aplicar SMOTE para balanceamento de classes.\n",
    "\n",
    "    Parameters:\n",
    "    X (pd.DataFrame): DataFrame com as características (features) dos dados.\n",
    "    y (pd.Series): Série com as etiquetas (labels) dos dados.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame, pd.Series: DataFrame e Série balanceados.\n",
    "    \"\"\"\n",
    "    logger.info(\"Aplicando SMOTE para balanceamento de classes...\")\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "    logger.info(\"Balanceamento de classes concluído.\")\n",
    "    logger.info(f\"Nova distribuição de classes:\\n{pd.Series(y_resampled).value_counts()}\")\n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "def salvar_preprocessador(preprocessor, preprocessor_path):\n",
    "    \"\"\"\n",
    "    Salvar o pré-processador.\n",
    "\n",
    "    Parameters:\n",
    "    preprocessor (ColumnTransformer): O pré-processador a ser salvo.\n",
    "    preprocessor_path (str): O caminho onde o pré-processador será salvo.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        joblib.dump(preprocessor, preprocessor_path)\n",
    "        logger.info(f'Pré-processador salvo em: {preprocessor_path}')\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao salvar o pré-processador: {e}\")\n",
    "        raise\n",
    "\n",
    "def obter_nomes_colunas(preprocessor, num_cols):\n",
    "    \"\"\"\n",
    "    Obter os nomes das colunas originais após a aplicação do pré-processador.\n",
    "\n",
    "    Parameters:\n",
    "    preprocessor (ColumnTransformer): O pré-processador aplicado.\n",
    "    num_cols (list): Lista de colunas numéricas originais.\n",
    "\n",
    "    Returns:\n",
    "    list: Lista de nomes de colunas originais.\n",
    "    \"\"\"\n",
    "    return num_cols\n",
    "\n",
    "def salvar_dataset_processado(X, y, processed_path, original_cols):\n",
    "    \"\"\"\n",
    "    Salvar o dataset processado em um arquivo CSV e imprimir as primeiras 5 linhas no console.\n",
    "\n",
    "    Parameters:\n",
    "    X (pd.DataFrame): DataFrame contendo as características (features) dos dados.\n",
    "    y (pd.Series): Série contendo as etiquetas (labels) dos dados.\n",
    "    processed_path (str): Caminho onde o dataset processado será salvo.\n",
    "    original_cols (list): Lista de nomes das colunas originais.\n",
    "\n",
    "    Raises:\n",
    "    Exception: Se houver um erro ao salvar o dataset processado.\n",
    "    \"\"\"\n",
    "    df_resampled = pd.concat([pd.DataFrame(X, columns=original_cols), pd.Series(y, name='Exited')], axis=1)\n",
    "    try:\n",
    "        df_resampled.to_csv(processed_path, index=False)\n",
    "        logger.info(f'Dataset processado salvo em: {processed_path}')\n",
    "        print(\"\\nPrimeiras 5 linhas do dataset processado:\\n\", df_resampled.head())\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao salvar o dataset processado: {e}\")\n",
    "        raise\n",
    "\n",
    "def gerar_graficos(df, output_dir):\n",
    "    \"\"\"\n",
    "    Gerar gráficos do dataset preprocessado e salvar no diretório especificado.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame contendo os dados preprocessados.\n",
    "    output_dir (str): Diretório onde os gráficos serão salvos.\n",
    "\n",
    "    Raises:\n",
    "    Exception: Se houver um erro ao salvar os gráficos.\n",
    "    \"\"\"\n",
    "    logger.info(\"Gerando gráficos...\")\n",
    "\n",
    "    # Verificar se o diretório existe, se não, criar\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # Histograma de Idades\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(df['Age'], kde=True)\n",
    "    plt.title('Distribuição de Idades')\n",
    "    plt.xlabel('Idade')\n",
    "    plt.ylabel('Frequência')\n",
    "    plt.savefig(os.path.join(output_dir, 'distribuicao_idades.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Box Plot de EstimatedSalary por Exited\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x='Exited', y='EstimatedSalary', data=df)\n",
    "    plt.title('Salário Estimado vs. Exited')\n",
    "    plt.xlabel('Exited')\n",
    "    plt.ylabel('Salário Estimado')\n",
    "    plt.savefig(os.path.join(output_dir, 'salario_vs_exited.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Scatter Plot de Idade vs. Saldo\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.scatterplot(x='Age', y='Balance', hue='Exited', data=df)\n",
    "    plt.title('Idade vs. Saldo')\n",
    "    plt.xlabel('Idade')\n",
    "    plt.ylabel('Saldo')\n",
    "    plt.savefig(os.path.join(output_dir, 'scatter_idade_vs_saldo.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Gráfico de Linha de Saldo ao Longo dos Anos\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(x='Tenure', y='Balance', hue='Exited', data=df)\n",
    "    plt.title('Saldo ao Longo dos Anos de Permanência')\n",
    "    plt.xlabel('Anos de Permanência')\n",
    "    plt.ylabel('Saldo')\n",
    "    plt.savefig(os.path.join(output_dir, 'line_saldo_anos.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Heatmap de Correlação\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    correlation_matrix = df.corr()\n",
    "    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "    plt.title('Mapa de Calor de Correlação')\n",
    "    plt.savefig(os.path.join(output_dir, 'heatmap_correlacao.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Histograma de Distribuição do Score de Crédito\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(df['CreditScore'], kde=True)\n",
    "    plt.title('Distribuição do Score de Crédito')\n",
    "    plt.xlabel('Score de Crédito')\n",
    "    plt.ylabel('Frequência')\n",
    "    plt.savefig(os.path.join(output_dir, 'distribuicao_credit_score.png'))\n",
    "    plt.close()\n",
    "\n",
    "    # Pairplot das Variáveis com Hue para Exited\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.pairplot(df[['Balance', 'Age', 'CreditScore', 'Tenure', 'EstimatedSalary', 'Exited']], hue='Exited', diag_kind='kde')\n",
    "    plt.savefig(os.path.join(output_dir, 'pairplot_com_hue.png'))\n",
    "    plt.close()\n",
    "\n",
    "    logger.info(\"Gráficos gerados e salvos com sucesso.\")\n",
    "\n",
    "def preprocessamento_dados():\n",
    "    \"\"\"\n",
    "    Função principal para preprocessar dados.\n",
    "\n",
    "    Este pipeline inclui as seguintes etapas:\n",
    "    1. Carregar configurações do arquivo YAML.\n",
    "    2. Carregar o dataset bruto.\n",
    "    3. Validar a presença de colunas necessárias.\n",
    "    4. Tratar valores ausentes e duplicados.\n",
    "    5. Criar e aplicar o pré-processador para normalização das colunas numéricas.\n",
    "    6. Aplicar SMOTE para balanceamento de classes.\n",
    "    7. Salvar o pré-processador.\n",
    "    8. Gerar gráficos detalhados do dataset preprocessado.\n",
    "    9. Salvar o dataset processado em um arquivo CSV e imprimir as primeiras 5 linhas.\n",
    "\n",
    "    Raises:\n",
    "    Exception: Se houver um erro em qualquer etapa do processamento.\n",
    "    \"\"\"\n",
    "    config = carregar_configuracao()\n",
    "    \n",
    "    # Carregar o dataset bruto\n",
    "    df = carregar_dados(config)\n",
    "\n",
    "    # Definir colunas numéricas\n",
    "    num_cols = ['Balance', 'Age', 'CreditScore', 'Tenure', 'EstimatedSalary']\n",
    "    required_cols = num_cols + ['Exited']\n",
    "\n",
    "    # Validar colunas\n",
    "    validar_colunas(df, required_cols)\n",
    "\n",
    "    # Tratar dados\n",
    "    df = tratar_dados(df, num_cols, config)\n",
    "\n",
    "    # Criar e aplicar o pré-processador\n",
    "    preprocessor = criar_preprocessador(num_cols)\n",
    "    X = df.drop('Exited', axis=1)\n",
    "    y = df['Exited']\n",
    "    X_transformed = preprocessor.fit_transform(X)\n",
    "    logger.info(\"Pré-processamento concluído.\")\n",
    "\n",
    "    # Obter nomes das colunas após o pré-processamento\n",
    "    colunas_originais = obter_nomes_colunas(preprocessor, num_cols)\n",
    "\n",
    "    # Aplicar SMOTE para balanceamento de classes\n",
    "    X_resampled, y_resampled = aplicar_smote(X_transformed, y)\n",
    "\n",
    "    # Salvar o pré-processador\n",
    "    salvar_preprocessador(preprocessor, config['preprocessors']['path'])\n",
    "\n",
    "    # Gerar gráficos com o dataset pré-processado\n",
    "    df_resampled = pd.concat([pd.DataFrame(X_resampled, columns=colunas_originais), pd.Series(y_resampled, name='Exited')], axis=1)\n",
    "    gerar_graficos(df_resampled, config['reports']['figures_dir'])\n",
    "\n",
    "    # Salvar o dataset processado e imprimir as primeiras 5 linhas\n",
    "    salvar_dataset_processado(X_resampled, y_resampled, config['data']['processed'], colunas_originais)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    preprocessamento_dados()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "203d04b2-6ce2-4f47-8692-5255e090f3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Treinamento do Modelo: model_training.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9363a30-12ef-4cc9-86cf-e182feec422e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Configuração carregada com sucesso.\n",
      "INFO:__main__:Iniciando a execução do script...\n",
      "INFO:__main__:Dados carregados a partir de D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/data/processed/rclientes_preprocessado.csv com 15926 linhas e 6 colunas.\n",
      "INFO:__main__:Pré-processamento dos dados concluído.\n",
      "INFO:__main__:Treinando o modelo: Gradient Boosting...\n",
      "INFO:__main__:Treinando o modelo: XGBoost...\n",
      "INFO:__main__:Treinando o modelo: Logistic Regression...\n",
      "INFO:__main__:Melhor modelo: XGBoost com F1-Score: 0.9309\n",
      "INFO:__main__:Relatório de classificação para o modelo XGBoost salvo em: D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/reports/XGBoost_relatorio_classificacao.txt\n",
      "INFO:__main__:Relatório de classificação detalhado dos modelos treinados salvo em: D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/reports/relatorio_modelos_treinados.txt\n",
      "C:\\Users\\alanjoffre\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:320: UserWarning: The total space of parameters 48 is smaller than n_iter=100. Running 48 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Melhores hiperparâmetros: {'n_estimators': 300, 'max_depth': 10, 'learning_rate': 0.2}\n",
      "INFO:__main__:Melhores hiperparâmetros salvos em: D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/reports/melhores_hiperparametros.txt\n",
      "INFO:__main__:Relatório de classificação para o modelo XGBoost_ajustado salvo em: D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/reports/XGBoost_ajustado_relatorio_classificacao.txt\n",
      "INFO:__main__:Validação cruzada F1-Score: 0.8505 ± 0.0086\n",
      "INFO:__main__:Resultado da validação cruzada salvo em: D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/reports/validacao_cruzada.txt\n",
      "INFO:__main__:Melhor threshold: 0.5162981152534485 com AUC: 0.9331980572930569\n",
      "INFO:__main__:Relatório de threshold salvo em: D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/reports/melhor_threshold.txt\n",
      "INFO:__main__:Relatório de classificação após aplicar threshold salvo em: D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/reports/relatorio_threshold.txt\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import classification_report, roc_curve, auc, f1_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Configurar o logger\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def carregar_configuracao(config_path='D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/config/config.yaml'):\n",
    "    \"\"\"\n",
    "    Carregar configurações de um arquivo YAML.\n",
    "\n",
    "    Parameters:\n",
    "    config_path (str): O caminho para o arquivo de configuração YAML.\n",
    "\n",
    "    Returns:\n",
    "    dict: Um dicionário contendo as configurações carregadas do arquivo.\n",
    "\n",
    "    Raises:\n",
    "    Exception: Se houver um erro ao carregar as configurações.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(config_path, 'r') as file:\n",
    "            config = yaml.safe_load(file)\n",
    "        logger.info(\"Configuração carregada com sucesso.\")\n",
    "        return config\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao carregar configuração: {e}\")\n",
    "        raise\n",
    "\n",
    "def carregar_dados(config):\n",
    "    \"\"\"\n",
    "    Carregar dados a partir do caminho especificado no arquivo de configuração.\n",
    "\n",
    "    Parameters:\n",
    "    config (dict): Dicionário contendo as configurações do projeto, incluindo o caminho dos dados.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame contendo os dados carregados.\n",
    "\n",
    "    Raises:\n",
    "    Exception: Se houver um erro ao carregar os dados.\n",
    "    \"\"\"\n",
    "    processed_data_path = config['data']['processed']\n",
    "    try:\n",
    "        df = pd.read_csv(processed_data_path)\n",
    "        logger.info(f\"Dados carregados a partir de {processed_data_path} com {df.shape[0]} linhas e {df.shape[1]} colunas.\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao carregar dados: {e}\")\n",
    "        raise\n",
    "\n",
    "def preprocessar_dados(df):\n",
    "    \"\"\"\n",
    "    Preprocessar dados (codificação de variáveis categóricas).\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame contendo os dados brutos.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame com variáveis categóricas codificadas.\n",
    "\n",
    "    Raises:\n",
    "    Exception: Se houver um erro durante o pré-processamento.\n",
    "    \"\"\"\n",
    "    df = pd.get_dummies(df, drop_first=True)\n",
    "    logger.info(\"Pré-processamento dos dados concluído.\")\n",
    "    return df\n",
    "\n",
    "def dividir_dados(df):\n",
    "    \"\"\"\n",
    "    Dividir dados em conjunto de treino e teste.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame contendo os dados preprocessados.\n",
    "\n",
    "    Returns:\n",
    "    tuple: Conjuntos de treino e teste (X_train, X_test, y_train, y_test).\n",
    "\n",
    "    Raises:\n",
    "    Exception: Se houver um erro durante a divisão dos dados.\n",
    "    \"\"\"\n",
    "    X = df.drop('Exited', axis=1)\n",
    "    y = df['Exited']\n",
    "    return train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "def treinar_modelos(X_train, y_train):\n",
    "    \"\"\"\n",
    "    Treinar diferentes modelos de machine learning e retornar o melhor modelo.\n",
    "\n",
    "    Parameters:\n",
    "    X_train (pd.DataFrame): Conjunto de características de treino.\n",
    "    y_train (pd.Series): Conjunto de etiquetas de treino.\n",
    "\n",
    "    Returns:\n",
    "    tuple: O melhor modelo treinado, o nome do melhor modelo, e os resultados de F1-Score para cada modelo.\n",
    "\n",
    "    Raises:\n",
    "    Exception: Se houver um erro durante o treinamento dos modelos.\n",
    "    \"\"\"\n",
    "    modelos = {\n",
    "        \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "        \"XGBoost\": XGBClassifier(eval_metric='logloss'),\n",
    "        \"Logistic Regression\": LogisticRegression(max_iter=1000)\n",
    "    }\n",
    "\n",
    "    melhor_modelo = None\n",
    "    melhor_f1 = 0\n",
    "    resultados = {}\n",
    "\n",
    "    for nome, modelo in modelos.items():\n",
    "        logger.info(f\"Treinando o modelo: {nome}...\")\n",
    "        modelo.fit(X_train, y_train)\n",
    "        y_pred = modelo.predict(X_train)\n",
    "        f1 = f1_score(y_train, y_pred)\n",
    "        resultados[nome] = f1\n",
    "\n",
    "        if f1 > melhor_f1:\n",
    "            melhor_f1 = f1\n",
    "            melhor_modelo = modelo\n",
    "            melhor_nome = nome\n",
    "\n",
    "    logger.info(f\"Melhor modelo: {melhor_nome} com F1-Score: {melhor_f1:.4f}\")\n",
    "    return melhor_modelo, melhor_nome, resultados\n",
    "\n",
    "def ajustar_hiperparametros(modelo, X_train, y_train, config):\n",
    "    \"\"\"\n",
    "    Ajustar hiperparâmetros do modelo usando RandomizedSearchCV.\n",
    "\n",
    "    Parameters:\n",
    "    modelo (object): O modelo de machine learning a ser ajustado.\n",
    "    X_train (pd.DataFrame): Conjunto de características de treino.\n",
    "    y_train (pd.Series): Conjunto de etiquetas de treino.\n",
    "    config (dict): Dicionário contendo as configurações do projeto.\n",
    "\n",
    "    Returns:\n",
    "    object: O melhor modelo ajustado com os hiperparâmetros otimizados.\n",
    "\n",
    "    Raises:\n",
    "    Exception: Se houver um erro durante o ajuste dos hiperparâmetros.\n",
    "    \"\"\"\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200, 300],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'max_depth': [3, 5, 7, 10]\n",
    "    }\n",
    "\n",
    "    randomized_search = RandomizedSearchCV(estimator=modelo, param_distributions=param_grid, n_iter=100, scoring='f1', cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "    try:\n",
    "        randomized_search.fit(X_train, y_train)\n",
    "\n",
    "        # Salvar melhores hiperparâmetros em um arquivo\n",
    "        melhores_hyperparams_path = os.path.join(config['reports']['directory'], \"melhores_hiperparametros.txt\")\n",
    "        with open(melhores_hyperparams_path, 'w') as f:\n",
    "            f.write(str(randomized_search.best_params_))\n",
    "\n",
    "        logger.info(f\"Melhores hiperparâmetros: {randomized_search.best_params_}\")\n",
    "        logger.info(f\"Melhores hiperparâmetros salvos em: {melhores_hyperparams_path}\")\n",
    "        return randomized_search.best_estimator_\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao ajustar hiperparâmetros: {e}\")\n",
    "        raise\n",
    "\n",
    "def avaliar_modelo(modelo, X_test, y_test, nome_modelo, config):\n",
    "    \"\"\"\n",
    "    Avaliar o modelo e gerar relatório de classificação detalhado.\n",
    "\n",
    "    Parameters:\n",
    "    modelo (object): O modelo treinado a ser avaliado.\n",
    "    X_test (pd.DataFrame): Conjunto de características de teste.\n",
    "    y_test (pd.Series): Conjunto de etiquetas de teste.\n",
    "    nome_modelo (str): Nome do modelo treinado.\n",
    "    config (dict): Dicionário contendo as configurações do projeto.\n",
    "\n",
    "    Returns:\n",
    "    str: Relatório de classificação detalhado.\n",
    "\n",
    "    Raises:\n",
    "    Exception: Se houver um erro durante a avaliação do modelo.\n",
    "    \"\"\"\n",
    "    y_pred = modelo.predict(X_test)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "\n",
    "    # Salvar relatório em TXT\n",
    "    report_path = os.path.join(config['reports']['directory'], f\"{nome_modelo}_relatorio_classificacao.txt\")\n",
    "    try:\n",
    "        with open(report_path, 'w') as f:\n",
    "            f.write(report)\n",
    "        logger.info(f\"Relatório de classificação para o modelo {nome_modelo} salvo em: {report_path}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao salvar relatório de classificação: {e}\")\n",
    "        raise\n",
    "\n",
    "    return report\n",
    "\n",
    "def aplicar_threshold(y_prob, optimal_threshold):\n",
    "    \"\"\"\n",
    "    Aplicar o melhor threshold e retornar as previsões ajustadas.\n",
    "\n",
    "    Parameters:\n",
    "    y_prob (np.ndarray): Probabilidades previstas pelo modelo.\n",
    "    optimal_threshold (float): Melhor threshold identificado.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: Previsões ajustadas com o threshold aplicado.\n",
    "\n",
    "    Raises:\n",
    "    Exception: Se houver um erro ao aplicar o threshold.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return (y_prob >= optimal_threshold).astype(int)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao aplicar o threshold: {e}\")\n",
    "        raise\n",
    "\n",
    "def validar_modelo(modelo, X, y, config):\n",
    "    \"\"\"\n",
    "    Efetuar validação cruzada e retornar o resultado.\n",
    "\n",
    "    Parameters:\n",
    "    modelo (object): O modelo de machine learning a ser validado.\n",
    "    X (pd.DataFrame): Conjunto de características.\n",
    "    y (pd.Series): Conjunto de etiquetas.\n",
    "    config (dict): Dicionário contendo as configurações do projeto.\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: Scores de F1-Score da validação cruzada.\n",
    "\n",
    "    Raises:\n",
    "    Exception: Se houver um erro durante a validação cruzada.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        scores = cross_val_score(modelo, X, y, cv=5, scoring='f1')\n",
    "        logger.info(f\"Validação cruzada F1-Score: {scores.mean():.4f} ± {scores.std():.4f}\")\n",
    "\n",
    "        # Salvar resultado da validação cruzada em um arquivo\n",
    "        validacao_cruzada_path = os.path.join(config['reports']['directory'], \"validacao_cruzada.txt\")\n",
    "        with open(validacao_cruzada_path, 'w') as f:\n",
    "            f.write(f\"Validação cruzada F1-Score: {scores.mean():.4f} ± {scores.std():.4f}\")\n",
    "\n",
    "        logger.info(f\"Resultado da validação cruzada salvo em: {validacao_cruzada_path}\")\n",
    "        return scores\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro durante a validação cruzada: {e}\")\n",
    "        raise\n",
    "\n",
    "def identificar_threshold(y_test, y_prob, config):\n",
    "    \"\"\"\n",
    "    Identificar o melhor threshold usando a curva ROC.\n",
    "\n",
    "    Parameters:\n",
    "    y_test (pd.Series): Conjunto de etiquetas de teste.\n",
    "    y_prob (np.ndarray): Probabilidades previstas pelo modelo.\n",
    "    config (dict): Dicionário contendo as configurações do projeto.\n",
    "\n",
    "    Returns:\n",
    "    float: Melhor threshold identificado.\n",
    "\n",
    "    Raises:\n",
    "    Exception: Se houver um erro ao identificar o threshold.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        optimal_idx = np.argmax(tpr - fpr)\n",
    "        optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "        # Salvar resultado em um arquivo\n",
    "        threshold_report_path = os.path.join(config['reports']['directory'], \"melhor_threshold.txt\")\n",
    "        with open(threshold_report_path, 'w') as f:\n",
    "            f.write(f\"Melhor threshold: {optimal_threshold}\\nAUC: {roc_auc}\\n\")\n",
    "\n",
    "        logger.info(f\"Melhor threshold: {optimal_threshold} com AUC: {roc_auc}\")\n",
    "        logger.info(f\"Relatório de threshold salvo em: {threshold_report_path}\")\n",
    "        return optimal_threshold\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao identificar o melhor threshold: {e}\")\n",
    "        raise\n",
    "\n",
    "def salvar_modelo(modelo, model_path):\n",
    "    \"\"\"\n",
    "    Salvar o modelo treinado em um arquivo.\n",
    "\n",
    "    Parameters:\n",
    "    modelo (object): O modelo de machine learning treinado.\n",
    "    model_path (str): O caminho onde o modelo será salvo.\n",
    "\n",
    "    Raises:\n",
    "    Exception: Se houver um erro ao salvar o modelo.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        joblib.dump(modelo, model_path)\n",
    "        logger.info(f\"Modelo final salvo em: {model_path}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao salvar o modelo: {e}\")\n",
    "        raise\n",
    "\n",
    "def executar_treinamento(config):\n",
    "    \"\"\"\n",
    "    Função principal para executar o treinamento, ajuste de hiperparâmetros e avaliação do modelo.\n",
    "\n",
    "    Parameters:\n",
    "    config (dict): Dicionário contendo as configurações do projeto.\n",
    "\n",
    "    Returns:\n",
    "    object: O melhor modelo ajustado com os hiperparâmetros otimizados.\n",
    "    \"\"\"\n",
    "    logger.info(\"Iniciando a execução do script...\")\n",
    "    df = carregar_dados(config)\n",
    "\n",
    "    # Pré-processar os dados\n",
    "    df = preprocessar_dados(df)\n",
    "\n",
    "    # Dividir os dados em conjuntos de treino e teste\n",
    "    X_train, X_test, y_train, y_test = dividir_dados(df)\n",
    "\n",
    "    # Treinar os modelos e obter o melhor modelo\n",
    "    melhor_modelo, melhor_nome, resultados_modelos = treinar_modelos(X_train, y_train)\n",
    "\n",
    "    # Avaliar o melhor modelo\n",
    "    relatorio_inicial = avaliar_modelo(melhor_modelo, X_test, y_test, melhor_nome, config)\n",
    "\n",
    "    # Gerar relatório detalhado dos modelos treinados\n",
    "    modelos_report_path = os.path.join(config['reports']['directory'], \"relatorio_modelos_treinados.txt\")\n",
    "    with open(modelos_report_path, 'w') as f:\n",
    "        for nome, f1 in resultados_modelos.items():\n",
    "            f.write(f\"Modelo: {nome}, F1-Score: {f1:.4f}\\n\")\n",
    "    logger.info(f\"Relatório de classificação detalhado dos modelos treinados salvo em: {modelos_report_path}\")\n",
    "\n",
    "    # Ajustar hiperparâmetros do melhor modelo\n",
    "    melhor_modelo_ajustado = ajustar_hiperparametros(melhor_modelo, X_train, y_train, config)\n",
    "\n",
    "    # Avaliar o modelo ajustado com hiperparâmetros otimizados\n",
    "    relatorio_ajustado = avaliar_modelo(melhor_modelo_ajustado, X_test, y_test, f\"{melhor_nome}_ajustado\", config)\n",
    "\n",
    "    # Validar o modelo ajustado\n",
    "    validar_modelo(melhor_modelo_ajustado, X_train, y_train, config)\n",
    "\n",
    "    # Identificar o melhor threshold com ROC\n",
    "    y_prob = melhor_modelo_ajustado.predict_proba(X_test)[:, 1]\n",
    "    optimal_threshold = identificar_threshold(y_test, y_prob, config)\n",
    "\n",
    "    # Aplicar o melhor threshold\n",
    "    y_pred_aplicado = aplicar_threshold(y_prob, optimal_threshold)\n",
    "\n",
    "    # Relatório de classificação após aplicar threshold\n",
    "    relatorio_threshold = classification_report(y_test, y_pred_aplicado)\n",
    "    threshold_report_path = os.path.join(config['reports']['directory'], \"relatorio_threshold.txt\")\n",
    "    with open(threshold_report_path, 'w') as f:\n",
    "        f.write(relatorio_threshold)\n",
    "    logger.info(f\"Relatório de classificação após aplicar threshold salvo em: {threshold_report_path}\")\n",
    "\n",
    "    # Retornar o modelo final ajustado\n",
    "    return melhor_modelo_ajustado\n",
    "\n",
    "def main(config_path='D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/config/config.yaml'):\n",
    "    \"\"\"\n",
    "    Função principal para carregar a configuração e executar o treinamento do modelo.\n",
    "\n",
    "    Parameters:\n",
    "    config_path (str): O caminho para o arquivo de configuração YAML.\n",
    "    \"\"\"\n",
    "    config = carregar_configuracao(config_path)\n",
    "    modelo = executar_treinamento(config)\n",
    "    return modelo\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5712dca-9410-471b-a6bb-c9326a68900e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. pipeline.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3fb33aa0-76b1-46b1-bb3b-e0bc85f03e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 13:54:00,282 - INFO - Iniciando a execução do pipeline.\n",
      "2024-11-11 13:54:00,282 - INFO - Iniciando a execução do pipeline.\n",
      "INFO:__main__:Iniciando a execução do pipeline.\n",
      "2024-11-11 13:54:00,288 - INFO - Configuração carregada com sucesso.\n",
      "2024-11-11 13:54:00,288 - INFO - Configuração carregada com sucesso.\n",
      "INFO:__main__:Configuração carregada com sucesso.\n",
      "2024-11-11 13:54:00,291 - INFO - Iniciando o pipeline de pré-processamento...\n",
      "2024-11-11 13:54:00,291 - INFO - Iniciando o pipeline de pré-processamento...\n",
      "INFO:__main__:Iniciando o pipeline de pré-processamento...\n",
      "2024-11-11 13:54:01,295 - INFO - [Pré-processamento (início)] Uso de CPU: 0.6%\n",
      "2024-11-11 13:54:01,295 - INFO - [Pré-processamento (início)] Uso de CPU: 0.6%\n",
      "INFO:__main__:[Pré-processamento (início)] Uso de CPU: 0.6%\n",
      "2024-11-11 13:54:01,296 - INFO - [Pré-processamento (início)] Uso de memória: 59.0%\n",
      "2024-11-11 13:54:01,296 - INFO - [Pré-processamento (início)] Uso de memória: 59.0%\n",
      "INFO:__main__:[Pré-processamento (início)] Uso de memória: 59.0%\n",
      "2024-11-11 13:54:02,323 - INFO - [Pré-processamento (fim)] Uso de CPU: 1.6%\n",
      "2024-11-11 13:54:02,323 - INFO - [Pré-processamento (fim)] Uso de CPU: 1.6%\n",
      "INFO:__main__:[Pré-processamento (fim)] Uso de CPU: 1.6%\n",
      "2024-11-11 13:54:02,325 - INFO - [Pré-processamento (fim)] Uso de memória: 58.4%\n",
      "2024-11-11 13:54:02,325 - INFO - [Pré-processamento (fim)] Uso de memória: 58.4%\n",
      "INFO:__main__:[Pré-processamento (fim)] Uso de memória: 58.4%\n",
      "2024-11-11 13:54:02,327 - INFO - Iniciando o treinamento do modelo...\n",
      "2024-11-11 13:54:02,327 - INFO - Iniciando o treinamento do modelo...\n",
      "INFO:__main__:Iniciando o treinamento do modelo...\n",
      "2024-11-11 13:54:03,330 - INFO - [Treinamento (início)] Uso de CPU: 2.3%\n",
      "2024-11-11 13:54:03,330 - INFO - [Treinamento (início)] Uso de CPU: 2.3%\n",
      "INFO:__main__:[Treinamento (início)] Uso de CPU: 2.3%\n",
      "2024-11-11 13:54:03,332 - INFO - [Treinamento (início)] Uso de memória: 58.3%\n",
      "2024-11-11 13:54:03,332 - INFO - [Treinamento (início)] Uso de memória: 58.3%\n",
      "INFO:__main__:[Treinamento (início)] Uso de memória: 58.3%\n",
      "2024-11-11 13:54:04,419 - INFO - [Treinamento (fim)] Uso de CPU: 8.8%\n",
      "2024-11-11 13:54:04,419 - INFO - [Treinamento (fim)] Uso de CPU: 8.8%\n",
      "INFO:__main__:[Treinamento (fim)] Uso de CPU: 8.8%\n",
      "2024-11-11 13:54:04,421 - INFO - [Treinamento (fim)] Uso de memória: 58.3%\n",
      "2024-11-11 13:54:04,421 - INFO - [Treinamento (fim)] Uso de memória: 58.3%\n",
      "INFO:__main__:[Treinamento (fim)] Uso de memória: 58.3%\n",
      "2024-11-11 13:54:04,423 - INFO - Avaliando o modelo...\n",
      "2024-11-11 13:54:04,423 - INFO - Avaliando o modelo...\n",
      "INFO:__main__:Avaliando o modelo...\n",
      "2024-11-11 13:54:04,449 - INFO - Métricas de desempenho do modelo:\n",
      "2024-11-11 13:54:04,449 - INFO - Métricas de desempenho do modelo:\n",
      "INFO:__main__:Métricas de desempenho do modelo:\n",
      "2024-11-11 13:54:04,452 - INFO - Acurácia: 0.8437\n",
      "2024-11-11 13:54:04,452 - INFO - Acurácia: 0.8437\n",
      "INFO:__main__:Acurácia: 0.8437\n",
      "2024-11-11 13:54:04,453 - INFO - Recall: 0.8075\n",
      "2024-11-11 13:54:04,453 - INFO - Recall: 0.8075\n",
      "INFO:__main__:Recall: 0.8075\n",
      "2024-11-11 13:54:04,455 - INFO - Precisão: 0.8630\n",
      "2024-11-11 13:54:04,455 - INFO - Precisão: 0.8630\n",
      "INFO:__main__:Precisão: 0.8630\n",
      "2024-11-11 13:54:04,456 - INFO - F1-Score: 0.8343\n",
      "2024-11-11 13:54:04,456 - INFO - F1-Score: 0.8343\n",
      "INFO:__main__:F1-Score: 0.8343\n",
      "2024-11-11 13:54:04,457 - INFO - AUC: 0.9229\n",
      "2024-11-11 13:54:04,457 - INFO - AUC: 0.9229\n",
      "INFO:__main__:AUC: 0.9229\n",
      "2024-11-11 13:54:04,459 - INFO - Salvando o modelo...\n",
      "2024-11-11 13:54:04,459 - INFO - Salvando o modelo...\n",
      "INFO:__main__:Salvando o modelo...\n",
      "2024-11-11 13:54:04,464 - INFO - Modelo salvo com sucesso em D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/models/final_model.joblib.\n",
      "2024-11-11 13:54:04,464 - INFO - Modelo salvo com sucesso em D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/models/final_model.joblib.\n",
      "INFO:__main__:Modelo salvo com sucesso em D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/models/final_model.joblib.\n",
      "2024-11-11 13:54:04,467 - INFO - Pipeline concluído com sucesso.\n",
      "2024-11-11 13:54:04,467 - INFO - Pipeline concluído com sucesso.\n",
      "INFO:__main__:Pipeline concluído com sucesso.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import psutil\n",
    "import logging\n",
    "import yaml\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd  # Importando pandas para carregar os dados\n",
    "\n",
    "# Adicionar o diretório 'src' ao sys.path\n",
    "sys.path.append(os.path.join('D:\\\\Github\\\\data-science\\\\projetos\\\\rotatividade-de-clientes\\\\machine-learning\\\\src'))\n",
    "\n",
    "# Definir o diretório de logs e o nome do arquivo de log com data e hora da execução\n",
    "log_dir = 'D:\\\\Github\\\\data-science\\\\projetos\\\\rotatividade-de-clientes\\\\machine-learning\\\\logs'\n",
    "log_file_path = os.path.join(log_dir, f\"pipeline_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\")\n",
    "\n",
    "# Garantir que o diretório de logs exista\n",
    "if not os.path.exists(log_dir):\n",
    "    os.makedirs(log_dir)\n",
    "\n",
    "# Configuração do logger\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Configurar o FileHandler para o arquivo de log e o StreamHandler para o console\n",
    "file_handler = logging.FileHandler(log_file_path, mode='a')\n",
    "file_handler.setLevel(logging.INFO)\n",
    "console_handler = logging.StreamHandler()\n",
    "console_handler.setLevel(logging.INFO)\n",
    "\n",
    "# Definir o formato dos logs\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "file_handler.setFormatter(formatter)\n",
    "console_handler.setFormatter(formatter)\n",
    "\n",
    "# Adicionar os handlers ao logger\n",
    "logger.addHandler(file_handler)\n",
    "logger.addHandler(console_handler)\n",
    "\n",
    "# Função para monitorar a latência e o uso de recursos\n",
    "def monitorar_performance(etapa):\n",
    "    \"\"\"Monitora o uso de recursos do sistema (CPU e memória).\"\"\"\n",
    "    try:\n",
    "        cpu_usage = psutil.cpu_percent(interval=1)\n",
    "        memory_usage = psutil.virtual_memory().percent\n",
    "        logger.info(f\"[{etapa}] Uso de CPU: {cpu_usage}%\")\n",
    "        logger.info(f\"[{etapa}] Uso de memória: {memory_usage}%\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao monitorar performance na etapa {etapa}: {e}\")\n",
    "\n",
    "# Função para calcular e registrar as métricas de performance do modelo\n",
    "def avaliar_modelo(modelo, X_test, y_test):\n",
    "    \"\"\"Avalia o modelo usando métricas de classificação e registra as métricas no log.\"\"\"\n",
    "    try:\n",
    "        # Fazer predições\n",
    "        y_pred = modelo.predict(X_test)\n",
    "        y_prob = modelo.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Calcular métricas\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "        # Registrar as métricas no log\n",
    "        logger.info(f\"Métricas de desempenho do modelo:\")\n",
    "        logger.info(f\"Acurácia: {accuracy:.4f}\")\n",
    "        logger.info(f\"Recall: {recall:.4f}\")\n",
    "        logger.info(f\"Precisão: {precision:.4f}\")\n",
    "        logger.info(f\"F1-Score: {f1:.4f}\")\n",
    "        logger.info(f\"AUC: {auc:.4f}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao avaliar o modelo: {e}\")\n",
    "\n",
    "# Função para carregar a configuração do arquivo YAML\n",
    "def carregar_configuracao(config_path='D:\\\\Github\\\\data-science\\\\projetos\\\\rotatividade-de-clientes\\\\machine-learning\\\\config\\\\config.yaml'):\n",
    "    \"\"\"Carregar configurações de um arquivo YAML.\"\"\"\n",
    "    try:\n",
    "        with open(config_path, 'r') as file:\n",
    "            config = yaml.safe_load(file)\n",
    "        logger.info(\"Configuração carregada com sucesso.\")\n",
    "        return config\n",
    "    except FileNotFoundError:\n",
    "        logger.error(f\"Arquivo de configuração não encontrado: {config_path}\")\n",
    "        raise\n",
    "    except yaml.YAMLError as e:\n",
    "        logger.error(f\"Erro ao ler o arquivo de configuração: {e}\")\n",
    "        raise\n",
    "\n",
    "# Função de pré-processamento de dados\n",
    "def preprocessamento_dados():\n",
    "    \"\"\"Processa os dados e retorna X_train, X_test, y_train e y_test.\"\"\"\n",
    "    try:\n",
    "        # Carregar dados e realizar o pré-processamento\n",
    "        dados = pd.read_csv('D:\\\\Github\\\\data-science\\\\projetos\\\\rotatividade-de-clientes\\\\machine-learning\\\\data\\\\processed\\\\rclientes_preprocessado.csv')\n",
    "\n",
    "        # Separar as variáveis independentes (X) e dependentes (y)\n",
    "        X = dados.drop('Exited', axis=1)  # Ajuste conforme seu dataset\n",
    "        y = dados['Exited']  # Ajuste conforme seu dataset\n",
    "\n",
    "        # Dividir os dados em treino e teste\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "        return X_train, X_test, y_train, y_test\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao processar os dados: {e}\")\n",
    "        raise\n",
    "\n",
    "# Função para treinar o modelo\n",
    "def treinar_modelo(X_train, y_train):\n",
    "    \"\"\"Treina o modelo XGBoost e retorna o modelo treinado.\"\"\"\n",
    "    try:\n",
    "        # Treinamento do modelo\n",
    "        modelo = XGBClassifier()\n",
    "        modelo.fit(X_train, y_train)\n",
    "        return modelo\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao treinar o modelo: {e}\")\n",
    "        raise\n",
    "\n",
    "# Função para salvar o modelo treinado\n",
    "def salvar_modelo(modelo, caminho):\n",
    "    \"\"\"Salva o modelo treinado em um arquivo.\"\"\"\n",
    "    try:\n",
    "        joblib.dump(modelo, caminho)\n",
    "        logger.info(f\"Modelo salvo com sucesso em {caminho}.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao salvar o modelo: {e}\")\n",
    "        raise\n",
    "\n",
    "# Função para executar o pipeline\n",
    "def executar_pipeline():\n",
    "    \"\"\"Executar o pipeline de pré-processamento, treinamento e avaliação do modelo.\"\"\"\n",
    "    try:\n",
    "        # Carregar configuração\n",
    "        config = carregar_configuracao()\n",
    "        \n",
    "        # Iniciar pré-processamento\n",
    "        logger.info(\"Iniciando o pipeline de pré-processamento...\")\n",
    "        monitorar_performance(\"Pré-processamento (início)\")\n",
    "        X_train, X_test, y_train, y_test = preprocessamento_dados()  # Chama a função de pré-processamento\n",
    "        monitorar_performance(\"Pré-processamento (fim)\")\n",
    "\n",
    "        # Iniciar treinamento do modelo\n",
    "        logger.info(\"Iniciando o treinamento do modelo...\")\n",
    "        monitorar_performance(\"Treinamento (início)\")\n",
    "        modelo = treinar_modelo(X_train, y_train)  # Chama a função de treinamento e obtém o modelo\n",
    "        monitorar_performance(\"Treinamento (fim)\")\n",
    "\n",
    "        # Avaliar e registrar as métricas de performance do modelo\n",
    "        logger.info(\"Avaliando o modelo...\")\n",
    "        avaliar_modelo(modelo, X_test, y_test)\n",
    "\n",
    "        # Salvando o modelo treinado\n",
    "        logger.info(\"Salvando o modelo...\")\n",
    "        salvar_modelo(modelo, config['models']['final_model'])\n",
    "\n",
    "        logger.info(\"Pipeline concluído com sucesso.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro durante a execução do pipeline: {e}\", exc_info=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    logger.info(\"Iniciando a execução do pipeline.\")\n",
    "    \n",
    "    executar_pipeline()\n",
    "\n",
    "    # Remover handlers e fechar o FileHandler para garantir a gravação no arquivo\n",
    "    logger.removeHandler(file_handler)\n",
    "    file_handler.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3315e7d-b52d-4433-9444-8e0847744f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Avaliação: evaluation.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a908392-e611-4136-a94c-ab370b38dc3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 13:54:18,302 - INFO - Configuração carregada com sucesso.\n",
      "2024-11-11 13:54:18,302 - INFO - Configuração carregada com sucesso.\n",
      "INFO:__main__:Configuração carregada com sucesso.\n",
      "2024-11-11 13:54:18,329 - INFO - Dados e modelo carregados com sucesso.\n",
      "2024-11-11 13:54:18,329 - INFO - Dados e modelo carregados com sucesso.\n",
      "INFO:__main__:Dados e modelo carregados com sucesso.\n",
      "2024-11-11 13:54:18,360 - INFO - Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.85      1633\n",
      "           1       0.86      0.81      0.83      1553\n",
      "\n",
      "    accuracy                           0.84      3186\n",
      "   macro avg       0.85      0.84      0.84      3186\n",
      "weighted avg       0.84      0.84      0.84      3186\n",
      "\n",
      "2024-11-11 13:54:18,360 - INFO - Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.85      1633\n",
      "           1       0.86      0.81      0.83      1553\n",
      "\n",
      "    accuracy                           0.84      3186\n",
      "   macro avg       0.85      0.84      0.84      3186\n",
      "weighted avg       0.84      0.84      0.84      3186\n",
      "\n",
      "INFO:__main__:Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.85      1633\n",
      "           1       0.86      0.81      0.83      1553\n",
      "\n",
      "    accuracy                           0.84      3186\n",
      "   macro avg       0.85      0.84      0.84      3186\n",
      "weighted avg       0.84      0.84      0.84      3186\n",
      "\n",
      "2024-11-11 13:54:18,363 - INFO - Relatório de classificação salvo em: D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/reports/classification_final.txt\n",
      "2024-11-11 13:54:18,363 - INFO - Relatório de classificação salvo em: D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/reports/classification_final.txt\n",
      "INFO:__main__:Relatório de classificação salvo em: D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/reports/classification_final.txt\n",
      "2024-11-11 13:54:18,369 - INFO - AUC da curva ROC: 0.9229\n",
      "2024-11-11 13:54:18,369 - INFO - AUC da curva ROC: 0.9229\n",
      "INFO:__main__:AUC da curva ROC: 0.9229\n",
      "2024-11-11 13:54:18,370 - INFO - Melhor threshold encontrado: 0.5376\n",
      "2024-11-11 13:54:18,370 - INFO - Melhor threshold encontrado: 0.5376\n",
      "INFO:__main__:Melhor threshold encontrado: 0.5376\n",
      "2024-11-11 13:54:18,386 - INFO - Relatório com Threshold Otimizado:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.91      0.86      1633\n",
      "           1       0.89      0.79      0.84      1553\n",
      "\n",
      "    accuracy                           0.85      3186\n",
      "   macro avg       0.85      0.85      0.85      3186\n",
      "weighted avg       0.85      0.85      0.85      3186\n",
      "\n",
      "2024-11-11 13:54:18,386 - INFO - Relatório com Threshold Otimizado:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.91      0.86      1633\n",
      "           1       0.89      0.79      0.84      1553\n",
      "\n",
      "    accuracy                           0.85      3186\n",
      "   macro avg       0.85      0.85      0.85      3186\n",
      "weighted avg       0.85      0.85      0.85      3186\n",
      "\n",
      "INFO:__main__:Relatório com Threshold Otimizado:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.91      0.86      1633\n",
      "           1       0.89      0.79      0.84      1553\n",
      "\n",
      "    accuracy                           0.85      3186\n",
      "   macro avg       0.85      0.85      0.85      3186\n",
      "weighted avg       0.85      0.85      0.85      3186\n",
      "\n",
      "2024-11-11 13:54:18,389 - INFO - Relatório de classificação com threshold otimizado salvo em: D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/reports/classification_threshold.txt\n",
      "2024-11-11 13:54:18,389 - INFO - Relatório de classificação com threshold otimizado salvo em: D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/reports/classification_threshold.txt\n",
      "INFO:__main__:Relatório de classificação com threshold otimizado salvo em: D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/reports/classification_threshold.txt\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import logging\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, roc_curve, auc, accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Configurar o logger\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def carregar_configuracao(config_path='D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/config/config.yaml'):\n",
    "    \"\"\"\n",
    "    Carregar configurações de um arquivo YAML.\n",
    "\n",
    "    Parameters:\n",
    "    config_path (str): O caminho para o arquivo de configuração YAML.\n",
    "\n",
    "    Returns:\n",
    "    dict: Um dicionário contendo as configurações carregadas do arquivo.\n",
    "\n",
    "    Raises:\n",
    "    Exception: Se houver um erro ao carregar as configurações.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(config_path, 'r') as file:\n",
    "            config = yaml.safe_load(file)\n",
    "        logger.info(\"Configuração carregada com sucesso.\")\n",
    "        return config\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao carregar configuração: {e}\")\n",
    "        raise\n",
    "\n",
    "def carregar_dados_e_modelo(config):\n",
    "    \"\"\"\n",
    "    Carregar dados e modelo treinado a partir dos caminhos especificados no arquivo de configuração.\n",
    "\n",
    "    Parameters:\n",
    "    config (dict): Dicionário contendo as configurações do projeto, incluindo os caminhos dos dados processados e do modelo treinado.\n",
    "\n",
    "    Returns:\n",
    "    tuple: DataFrame contendo os dados carregados e o modelo treinado.\n",
    "\n",
    "    Raises:\n",
    "    Exception: Se houver um erro ao carregar os dados ou o modelo.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(config['data']['processed'])\n",
    "        model = joblib.load(config['models']['final_model'])\n",
    "        logger.info(\"Dados e modelo carregados com sucesso.\")\n",
    "        return df, model\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao carregar dados ou modelo: {e}\")\n",
    "        raise\n",
    "\n",
    "def avaliar_modelo(model, X_test, y_test, config):\n",
    "    \"\"\"\n",
    "    Avaliar o modelo usando métricas de classificação e salvar os resultados.\n",
    "\n",
    "    Parameters:\n",
    "    model (object): O modelo treinado a ser avaliado.\n",
    "    X_test (pd.DataFrame): Conjunto de características de teste.\n",
    "    y_test (pd.Series): Conjunto de etiquetas de teste.\n",
    "    config (dict): Dicionário contendo as configurações do projeto, incluindo os caminhos para salvar os relatórios.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "\n",
    "    Raises:\n",
    "    Exception: Se houver um erro durante a avaliação do modelo.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        report = classification_report(y_test, y_pred)\n",
    "        logger.info(\"Relatório de Classificação:\\n%s\", report)\n",
    "\n",
    "        # Salvar relatório em TXT\n",
    "        report_path = config['reports']['classification_final']\n",
    "        with open(report_path, 'w') as f:\n",
    "            f.write(report)\n",
    "        logger.info(f\"Relatório de classificação salvo em: {report_path}\")\n",
    "\n",
    "        fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        optimal_idx = np.argmax(tpr - fpr)\n",
    "        optimal_threshold = thresholds[optimal_idx]\n",
    "        logger.info(f\"AUC da curva ROC: {roc_auc:.4f}\")\n",
    "        logger.info(f\"Melhor threshold encontrado: {optimal_threshold:.4f}\")\n",
    "\n",
    "        y_pred_optimal = (y_prob >= optimal_threshold).astype(int)\n",
    "        report_optimal = classification_report(y_test, y_pred_optimal)\n",
    "        logger.info(\"Relatório com Threshold Otimizado:\\n%s\", report_optimal)\n",
    "\n",
    "        report_threshold_path = config['reports']['classification_threshold']\n",
    "        with open(report_threshold_path, 'w') as f:\n",
    "            f.write(report_optimal)\n",
    "        logger.info(f\"Relatório de classificação com threshold otimizado salvo em: {report_threshold_path}\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao avaliar o modelo: {e}\")\n",
    "        raise\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Função principal para executar a avaliação do modelo.\n",
    "\n",
    "    Esta função executa as seguintes etapas:\n",
    "    1. Carrega as configurações do arquivo YAML.\n",
    "    2. Carrega os dados processados e o modelo treinado.\n",
    "    3. Divide os dados em conjuntos de treino e teste.\n",
    "    4. Avalia o modelo usando métricas de classificação e salva os resultados.\n",
    "\n",
    "    Raises:\n",
    "    Exception: Se houver um erro em qualquer etapa da avaliação.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        config = carregar_configuracao()\n",
    "        df, model = carregar_dados_e_modelo(config)\n",
    "        \n",
    "        # Dividir os dados em conjuntos de treino e teste\n",
    "        X = df.drop('Exited', axis=1)\n",
    "        y = df['Exited']\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "        \n",
    "        # Avaliar o modelo\n",
    "        avaliar_modelo(model, X_test, y_test, config)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro durante a execução do script: {e}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66269839-04ea-487e-86f8-38c01bed8c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. KPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3648604-8b33-48e9-b0f6-cf7eb7572019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 0.84\n",
      "Precisão: 0.86\n",
      "Revocação: 0.81\n",
      "F1-Score: 0.83\n",
      "AUC-ROC: 0.92\n",
      "Matriz de Confusão:\n",
      "[[1434  199]\n",
      " [ 299 1254]]\n",
      "\n",
      "KPIs Adicionais:\n",
      "Taxa de Falsos Positivos (FPR): 0.12\n",
      "Taxa de Falsos Negativos (FNR): 0.19\n",
      "Acurácia Balanceada: 0.84\n",
      "Matriz de Confusão Normalizada:\n",
      "[[0.8781384  0.1218616 ]\n",
      " [0.19253059 0.80746941]]\n",
      "Kappa de Cohen: 0.69\n",
      "Índice de Gini: 0.85\n",
      "Lift: 0.80\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# Passo 1: Carregar o arquivo pré-processado\n",
    "file_path = 'D:\\\\Github\\\\data-science\\\\projetos\\\\rotatividade-de-clientes\\\\machine-learning\\\\data\\\\processed\\\\rclientes_preprocessado.csv'\n",
    "clientes_df = pd.read_csv(file_path)\n",
    "\n",
    "# Passo 2: Separar as variáveis independentes (X) e a variável alvo (y)\n",
    "X = clientes_df.drop(columns=['Exited'])  # Supondo que 'Exited' seja a coluna de saída\n",
    "y = clientes_df['Exited']\n",
    "\n",
    "# Passo 3: Dividir os dados em conjunto de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Passo 4: Carregar o modelo XGBoost treinado\n",
    "modelo_path = 'D:\\\\Github\\\\data-science\\\\projetos\\\\rotatividade-de-clientes\\\\machine-learning\\\\models\\\\final_model.joblib'\n",
    "modelo = joblib.load(modelo_path)\n",
    "\n",
    "# Passo 5: Realizar previsões\n",
    "y_pred = modelo.predict(X_test)\n",
    "y_pred_proba = modelo.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Passo 6: Calcular os KPIs\n",
    "\n",
    "# Acurácia, Precisão, Revocação, F1-Score, AUC-ROC\n",
    "acuracia = accuracy_score(y_test, y_pred)\n",
    "precisao = precision_score(y_test, y_pred)\n",
    "revocacao = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
    "matriz_confusao = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# 1. Taxa de Falsos Positivos (FPR)\n",
    "TN, FP, FN, TP = matriz_confusao.ravel()\n",
    "FPR = FP / (FP + TN)\n",
    "\n",
    "# 2. Taxa de Falsos Negativos (FNR)\n",
    "FNR = FN / (FN + TP)\n",
    "\n",
    "# 3. Acurácia Balanceada\n",
    "TPR = TP / (TP + FN)  # Revocação (Sensibilidade)\n",
    "TNR = TN / (TN + FP)  # Especificidade\n",
    "balanced_accuracy = (TPR + TNR) / 2\n",
    "\n",
    "# 4. Matriz de Confusão Normalizada\n",
    "cm_normalized = matriz_confusao.astype('float') / matriz_confusao.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# 5. Kappa de Cohen\n",
    "accuracy_observed = (TP + TN) / (TP + TN + FP + FN)\n",
    "accuracy_expected = ((TP + FP) / (TP + TN + FP + FN)) * ((TP + FN) / (TP + TN + FP + FN)) + ((TN + FN) / (TP + TN + FP + FN)) * ((TN + FP) / (TP + TN + FP + FN))\n",
    "kappa = (accuracy_observed - accuracy_expected) / (1 - accuracy_expected)\n",
    "\n",
    "# 6. Gini Coefficient\n",
    "gini = 2 * auc_roc - 1\n",
    "\n",
    "# 7. Lift (usando probabilidades de previsão)\n",
    "def lift_function(y_true, y_pred_probs):\n",
    "    data = pd.DataFrame({'y_true': y_true, 'y_pred_probs': y_pred_probs})\n",
    "    data = data.sort_values(by='y_pred_probs', ascending=False)\n",
    "    data['cumulative_true'] = data['y_true'].cumsum()\n",
    "    data['cumulative_total'] = np.arange(1, len(data) + 1)\n",
    "    return data['cumulative_true'] / data['cumulative_total']\n",
    "\n",
    "lift = lift_function(y_test, y_pred_proba).mean()\n",
    "\n",
    "# Passo 7: Exibir os resultados\n",
    "print(f'Acurácia: {acuracia:.2f}')\n",
    "print(f'Precisão: {precisao:.2f}')\n",
    "print(f'Revocação: {revocacao:.2f}')\n",
    "print(f'F1-Score: {f1:.2f}')\n",
    "print(f'AUC-ROC: {auc_roc:.2f}')\n",
    "print(f'Matriz de Confusão:\\n{matriz_confusao}')\n",
    "\n",
    "print(f'\\nKPIs Adicionais:')\n",
    "print(f'Taxa de Falsos Positivos (FPR): {FPR:.2f}')\n",
    "print(f'Taxa de Falsos Negativos (FNR): {FNR:.2f}')\n",
    "print(f'Acurácia Balanceada: {balanced_accuracy:.2f}')\n",
    "print(f'Matriz de Confusão Normalizada:\\n{cm_normalized}')\n",
    "print(f'Kappa de Cohen: {kappa:.2f}')\n",
    "print(f'Índice de Gini: {gini:.2f}')\n",
    "print(f'Lift: {lift:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c326f52-b09c-403d-bec1-624259ef76c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Inferência.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3fa9b71a-9098-408b-bb77-17bf81dbd39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 13:56:18,525 - INFO - Configurações carregadas de: D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/config/config.yaml\n",
      "2024-11-11 13:56:18,525 - INFO - Configurações carregadas de: D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/config/config.yaml\n",
      "INFO:__main__:Configurações carregadas de: D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/config/config.yaml\n",
      "2024-11-11 13:56:18,530 - INFO - Dados de entrada carregados de: D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/data/new_data.csv\n",
      "2024-11-11 13:56:18,530 - INFO - Dados de entrada carregados de: D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/data/new_data.csv\n",
      "INFO:__main__:Dados de entrada carregados de: D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/data/new_data.csv\n",
      "2024-11-11 13:56:18,534 - INFO - Modelo carregado de: D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/models/final_model.joblib\n",
      "2024-11-11 13:56:18,534 - INFO - Modelo carregado de: D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/models/final_model.joblib\n",
      "INFO:__main__:Modelo carregado de: D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/models/final_model.joblib\n",
      "2024-11-11 13:56:18,538 - INFO - Pré-processador carregado de: D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/preprocessors/preprocessor.joblib\n",
      "2024-11-11 13:56:18,538 - INFO - Pré-processador carregado de: D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/preprocessors/preprocessor.joblib\n",
      "INFO:__main__:Pré-processador carregado de: D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/preprocessors/preprocessor.joblib\n",
      "2024-11-11 13:56:18,544 - INFO - Inferência concluída com sucesso.\n",
      "2024-11-11 13:56:18,544 - INFO - Inferência concluída com sucesso.\n",
      "INFO:__main__:Inferência concluída com sucesso.\n",
      "2024-11-11 13:56:18,549 - INFO - Resultados da inferência salvos em: D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/predictions/resultados_inferencia.csv\n",
      "2024-11-11 13:56:18,549 - INFO - Resultados da inferência salvos em: D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/predictions/resultados_inferencia.csv\n",
      "INFO:__main__:Resultados da inferência salvos em: D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/predictions/resultados_inferencia.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import logging\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "# Configurar logger\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def carregar_configuracoes(config_path):\n",
    "    \"\"\"Carrega as configurações do arquivo YAML.\"\"\"\n",
    "    try:\n",
    "        with open(config_path, 'r') as file:\n",
    "            config = yaml.safe_load(file)\n",
    "            logger.info(f\"Configurações carregadas de: {config_path}\")\n",
    "            return config\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao carregar o arquivo de configurações: {e}\")\n",
    "        raise\n",
    "\n",
    "def carregar_modelo(model_path):\n",
    "    \"\"\"Carrega o modelo salvo.\"\"\"\n",
    "    try:\n",
    "        modelo = joblib.load(model_path)\n",
    "        logger.info(f\"Modelo carregado de: {model_path}\")\n",
    "        return modelo\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao carregar o modelo: {e}\")\n",
    "        raise\n",
    "\n",
    "def carregar_preprocessador(preprocessor_path):\n",
    "    \"\"\"Carrega o pré-processador salvo.\"\"\"\n",
    "    try:\n",
    "        preprocessor = joblib.load(preprocessor_path)\n",
    "        logger.info(f\"Pré-processador carregado de: {preprocessor_path}\")\n",
    "        return preprocessor\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao carregar o pré-processador: {e}\")\n",
    "        raise\n",
    "\n",
    "def fazer_inferencia(data_path, model_path, preprocessor_path):\n",
    "    \"\"\"Faz a inferência utilizando o modelo e pré-processador carregados.\"\"\"\n",
    "    # Carregar dados de entrada\n",
    "    try:\n",
    "        df = pd.read_csv(data_path)\n",
    "        logger.info(f'Dados de entrada carregados de: {data_path}')\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao carregar os dados de entrada: {e}\")\n",
    "        raise\n",
    "\n",
    "    # Carregar modelo e pré-processador\n",
    "    modelo = carregar_modelo(model_path)\n",
    "    preprocessor = carregar_preprocessador(preprocessor_path)\n",
    "\n",
    "    # Preprocessar os dados\n",
    "    X = df.drop('Exited', axis=1) if 'Exited' in df.columns else df\n",
    "    X_transformed = preprocessor.transform(X)\n",
    "\n",
    "    # Fazer previsão\n",
    "    try:\n",
    "        previsoes = modelo.predict(X_transformed)\n",
    "        df['Predicao'] = previsoes\n",
    "        logger.info(\"Inferência concluída com sucesso.\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao fazer a inferência: {e}\")\n",
    "        raise\n",
    "\n",
    "    # Salvar resultados\n",
    "    resultados_path = os.path.join(config['predictions']['directory'], 'resultados_inferencia.csv')\n",
    "    try:\n",
    "        df.to_csv(resultados_path, index=False)\n",
    "        logger.info(f'Resultados da inferência salvos em: {resultados_path}')\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao salvar os resultados da inferência: {e}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config_path = os.path.join('D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/config/config.yaml')\n",
    "    config = carregar_configuracoes(config_path)\n",
    "\n",
    "    fazer_inferencia(\n",
    "        data_path=config['data']['new_data'],  # Usando o caminho de dados novos\n",
    "        model_path=config['models']['final_model'],\n",
    "        preprocessor_path=config['preprocessors']['path']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce667462-aa4d-4c9e-9a00-075706296cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.Inferência_input.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34096b60-c05b-40ad-bd3c-9d5213c9f208",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 13:58:01,398 - INFO - Configurações carregadas de: D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/config/config.yaml\n",
      "2024-11-11 13:58:01,398 - INFO - Configurações carregadas de: D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/config/config.yaml\n",
      "INFO:__main__:Configurações carregadas de: D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/config/config.yaml\n",
      "2024-11-11 13:58:01,403 - INFO - Modelo carregado de: D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/models/final_model.joblib\n",
      "2024-11-11 13:58:01,403 - INFO - Modelo carregado de: D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/models/final_model.joblib\n",
      "INFO:__main__:Modelo carregado de: D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/models/final_model.joblib\n",
      "2024-11-11 13:58:01,407 - INFO - Pré-processador carregado de: D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/preprocessors/preprocessor.joblib\n",
      "2024-11-11 13:58:01,407 - INFO - Pré-processador carregado de: D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/preprocessors/preprocessor.joblib\n",
      "INFO:__main__:Pré-processador carregado de: D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/preprocessors/preprocessor.joblib\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Digite o Credit Score:  850\n",
      "Digite a Geografia:  Spain\n",
      "Digite o Gênero (Male/Female):  Male\n",
      "Digite a Idade:  56\n",
      "Digite o Tempo de Permanência:  8\n",
      "Digite o Saldo:  200000.00\n",
      "Digite o Número de Produtos:  3\n",
      "Possui Cartão de Crédito? (1-Sim, 0-Não):  1\n",
      "É Membro Ativo? (1-Sim, 0-Não):  1\n",
      "Digite o Salário Estimado:  200000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-11 13:58:34,305 - INFO - Inferência concluída com sucesso.\n",
      "2024-11-11 13:58:34,305 - INFO - Inferência concluída com sucesso.\n",
      "INFO:__main__:Inferência concluída com sucesso.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado da previsão:    Predicao\n",
      "0         1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import logging\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "# Configurar logger\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Carregar configurações do arquivo YAML\n",
    "def carregar_configuracoes(config_path):\n",
    "    \"\"\"Carrega as configurações do arquivo YAML.\"\"\"\n",
    "    try:\n",
    "        with open(config_path, 'r') as file:\n",
    "            config = yaml.safe_load(file)\n",
    "            logger.info(f\"Configurações carregadas de: {config_path}\")\n",
    "            return config\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao carregar o arquivo de configurações: {e}\")\n",
    "        raise\n",
    "\n",
    "def carregar_modelo(model_path):\n",
    "    \"\"\"Carrega o modelo salvo.\"\"\"\n",
    "    try:\n",
    "        modelo = joblib.load(model_path)\n",
    "        logger.info(f\"Modelo carregado de: {model_path}\")\n",
    "        return modelo\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao carregar o modelo: {e}\")\n",
    "        raise\n",
    "\n",
    "def carregar_preprocessador(preprocessor_path):\n",
    "    \"\"\"Carrega o pré-processador salvo.\"\"\"\n",
    "    try:\n",
    "        preprocessor = joblib.load(preprocessor_path)\n",
    "        logger.info(f\"Pré-processador carregado de: {preprocessor_path}\")\n",
    "        return preprocessor\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao carregar o pré-processador: {e}\")\n",
    "        raise\n",
    "\n",
    "def coletar_dados_cliente():\n",
    "    \"\"\"Coleta dados do cliente via entrada do usuário.\"\"\"\n",
    "    dados = {}\n",
    "    dados['CreditScore'] = float(input(\"Digite o Credit Score: \"))\n",
    "    dados['Geography'] = input(\"Digite a Geografia: \")\n",
    "    dados['Gender'] = input(\"Digite o Gênero (Male/Female): \")\n",
    "    dados['Age'] = int(input(\"Digite a Idade: \"))\n",
    "    dados['Tenure'] = int(input(\"Digite o Tempo de Permanência: \"))\n",
    "    dados['Balance'] = float(input(\"Digite o Saldo: \"))\n",
    "    dados['NumOfProducts'] = int(input(\"Digite o Número de Produtos: \"))\n",
    "    dados['HasCrCard'] = int(input(\"Possui Cartão de Crédito? (1-Sim, 0-Não): \"))\n",
    "    dados['IsActiveMember'] = int(input(\"É Membro Ativo? (1-Sim, 0-Não): \"))\n",
    "    dados['EstimatedSalary'] = float(input(\"Digite o Salário Estimado: \"))\n",
    "    return pd.DataFrame([dados])\n",
    "\n",
    "def fazer_inferencia():\n",
    "    \"\"\"Faz a inferência utilizando o modelo e pré-processador carregados.\"\"\"\n",
    "    # Carregar modelo e pré-processador\n",
    "    modelo = carregar_modelo(config['models']['final_model'])\n",
    "    preprocessor = carregar_preprocessador(config['preprocessors']['path'])\n",
    "\n",
    "    # Coletar dados do cliente\n",
    "    df_cliente = coletar_dados_cliente()\n",
    "\n",
    "    # Preprocessar os dados\n",
    "    X_transformed = preprocessor.transform(df_cliente)\n",
    "\n",
    "    # Fazer previsão\n",
    "    try:\n",
    "        previsoes = modelo.predict(X_transformed)\n",
    "        df_cliente['Predicao'] = previsoes\n",
    "        logger.info(\"Inferência concluída com sucesso.\")\n",
    "        print(\"Resultado da previsão:\", df_cliente[['Predicao']])\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Erro ao fazer a inferência: {e}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    config_path = os.path.join('D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/config/config.yaml')\n",
    "    config = carregar_configuracoes(config_path)\n",
    "    fazer_inferencia()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ec212e4-061a-4748-ad18-8857eae278c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. config.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de77e849-2715-4e96-8dc1-c39075400599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações de Diretórios para o Projeto\n",
    "paths:\n",
    "  config_dir: 'D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/config/'\n",
    "  logs_dir: 'D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/logs/'\n",
    "  notebook_dir: 'D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/notebook/'\n",
    "  src_dir: 'D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/src/'\n",
    "\n",
    "# Caminhos para o Armazenamento de Modelos\n",
    "models:\n",
    "  directory: 'D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/models/'\n",
    "  scaler: 'D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/models/scaler.joblib'\n",
    "  final_model: 'D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/models/final_model.joblib'\n",
    "\n",
    "# Caminhos para Pré-processadores\n",
    "preprocessors:\n",
    "  path: 'D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/preprocessors/preprocessor.joblib'\n",
    "  input_features:  # Adicionado para a inferência\n",
    "    - CreditScore\n",
    "    - Age\n",
    "    - Tenure\n",
    "    - Balance\n",
    "    - NumOfProducts\n",
    "    - HasCrCard\n",
    "    - IsActiveMember\n",
    "    - EstimatedSalary\n",
    "    - Geography_France\n",
    "    - Geography_Germany\n",
    "    - Geography_Spain\n",
    "    - Gender_Female\n",
    "    - Gender_Male\n",
    "\n",
    "# Caminhos para os Dados\n",
    "data:\n",
    "  raw: 'D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/data/raw/rclientes.csv'\n",
    "  data_processed: 'D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/data/processed/rclientes_dados_tratados.csv'\n",
    "  processed: 'D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/data/processed/rclientes_preprocessado.csv'\n",
    "  new_data: 'D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/data/new_data.csv'\n",
    "\n",
    "# Configurações de Relatórios\n",
    "reports:\n",
    "  directory: 'D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/reports/'\n",
    "  figures_dir: 'D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/reports/figures/'\n",
    "  classification_initial: 'D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/reports/classification_initial.txt'\n",
    "  classification_final: 'D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/reports/classification_final.txt'\n",
    "  classification_threshold: 'D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/reports/classification_threshold.txt'\n",
    "\n",
    "# Configurações de Pré-processamento\n",
    "preprocessing:\n",
    "  numeric_features: [\"CreditScore\", \"Age\", \"Tenure\", \"Balance\", \"EstimatedSalary\"]\n",
    "  categorical_features: [\"Geography\", \"Gender\", \"HasCrCard\", \"IsActiveMember\"]\n",
    "\n",
    "# Configurações de Previsões\n",
    "predictions:\n",
    "  output: 'D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/predictions/predictions.csv'\n",
    "  directory: 'D:/Github/data-science/projetos/rotatividade-de-clientes/machine-learning/predictions/'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
